{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Seth/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "2016-11-02 07:16:55.055678\n",
      "finished loading packages after 1.67580318451 seconds\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jul 19 16:14:43 2016\n",
    "\n",
    "@author: nmvenuti\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jun  2 15:23:11 2016\n",
    "\n",
    "@author: nmvenuti\n",
    "\"\"\"\n",
    "import time\n",
    "start=time.time()\n",
    "import sys, os\n",
    "\n",
    "os.chdir('/Users/Seth/Documents/DSI/Capstone/DSI-Religion-2017')\n",
    "#from joblib import Parallel, delayed\n",
    "#import multiprocessing as mp\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "sys.path.append('./prototype_python/')\n",
    "import lingual as la\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "end=time.time()\n",
    "#sys.stdout = open(\"output.txt\", \"a\")\n",
    "print(str(datetime.now()))\n",
    "print('finished loading packages after '+str(end-start)+' seconds')\n",
    "sys.stdout.flush()\n",
    "\n",
    "#\n",
    "import getNewDocs as gnd\n",
    "\n",
    "stemmer = nltk.stem.snowball.EnglishStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "41\n",
      "[['DorothyDay', 'test0'], ['DorothyDay', 'test3'], ['Bahai', 'test4'], ['DorothyDay', 'test2'], ['Bahai', 'test5'], ['DorothyDay', 'test5'], ['Bahai', 'test6'], ['DorothyDay', 'test4'], ['Bahai', 'test7'], ['DorothyDay', 'test7'], ['Bahai', 'test0'], ['DorothyDay', 'test6'], ['Bahai', 'test1'], ['Bahai', 'test2'], ['DorothyDay', 'test8'], ['Bahai', 'test8'], ['Bahai', 'test3'], ['Bahai', 'test9'], ['DorothyDay', 'test1']]\n",
      "%%%%%\n",
      "length of subgroupList is 19\n"
     ]
    }
   ],
   "source": [
    "fileDF=gnd.newDocsToDF('./data_dsicap/', bin=5) ################################### WHERE THE NEW FILES ARE\n",
    "\n",
    "fileList=fileDF.values.tolist()\n",
    "\n",
    "fileList=[[fileList[i][0],fileList[i][1],fileList[i][2]] for i in range(len(fileList))]\n",
    "\n",
    "\n",
    "#Get set of subgroups\n",
    "subgroupList=[ list(y) for y in set((x[0],x[2]) for x in fileList) ]\n",
    "print(subgroupList)\n",
    "print('%%%%%\\nlength of subgroupList is ' + str(len(subgroupList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawPath = './data_dsicap/' ###############change this eventually\n",
    "runDirectory='./modelOutput/'\n",
    "#groupList=['DorothyDay','JohnPiper','MehrBaba','NaumanKhan','PastorAnderson',\n",
    "#   'Rabbinic','Shepherd','Unitarian','WBC']\n",
    "#groupList=['DorothyDay','NaumanKhan','Rabbinic','NawDawg','SeaShepherds','IntegralYoga','Bahai']\n",
    "#cocoWindow=int(sys.argv[1])\n",
    "#cvWindow=int(sys.argv[2])\n",
    "#startCount=int(sys.argv[3])\n",
    "#netAngle=int(sys.argv[4])\n",
    "cocoWindow=3\n",
    "cvWindow=3\n",
    "startCount=0\n",
    "netAngle=30\n",
    "groupSize=10\n",
    "#testSplit=.3\n",
    "targetWordCount=10\n",
    "svdInt=50\n",
    "simCount=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "#Create paramList\n",
    "paramList=[[x,fileList,targetWordCount,cocoWindow,svdInt,cvWindow,simCount,startCount,netAngle] for x in subgroupList]\n",
    "print(len(paramList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run calculation \n",
    "#masterOutput=[textAnalysis(x) for x in paramList]  ### INSTEAD OF THIS, WE MAKE THE OBJECT\n",
    "paramPick = paramList[0] ### instead of looping through, we just pick one\n",
    "#print(paramPick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DorothyDay', 'test0']\n"
     ]
    }
   ],
   "source": [
    "#def textAnalysis(paramPick):\n",
    "startTime=time.time()\n",
    "groupId=paramPick[0]\n",
    "fileList=paramPick[1]\n",
    "targetWordCount=paramPick[2]\n",
    "cocoWindow=paramPick[3]\n",
    "svdInt=paramPick[4]\n",
    "cvWindow=paramPick[5]\n",
    "simCount=paramPick[6]\n",
    "startCount=paramPick[7]\n",
    "netAngle=paramPick[8]    \n",
    "\n",
    "print(groupId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['./data_dsicap/DorothyDay/raw/148.html.txt', './data_dsicap/DorothyDay/raw/150.html.txt', './data_dsicap/DorothyDay/raw/161.html.txt', './data_dsicap/DorothyDay/raw/173.html.txt', './data_dsicap/DorothyDay/raw/178.html.txt']\n"
     ]
    }
   ],
   "source": [
    "#Get list of subfiles\n",
    "subFileList=[x[1] for x in fileList if x[0]==groupId[0] and x[2]==groupId[1]]\n",
    "print(len(subFileList))\n",
    "print(subFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################\n",
    "#Create lingual object\n",
    "loTest=la.lingualObject(subFileList)\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### LOOK AT LIST OF TOKENS FOR FILE\n",
    "#print(subFileList[0])\n",
    "#loTest.tokens[subFileList[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%\n",
      "cocoDict, length 2204\n",
      "---the first ten keys:\n",
      "['', u'four', u'sleep', u'maid', u'consider', u'whose', u'accus', u'undef', u'stationeri', u'fruitsthes']\n",
      "---the first entry:\n",
      "\n",
      "{u'and': 2, u'all': 1, u'often': 1, u'pope': 1, u'direct': 1, u'one': 2, u'not': 1, u'have': 1, u'corrupt': 1, u'her': 1, u'alway': 1, u'pronounc': 1, u'father': 1, u'pius': 1, u'littl': 1, u'write': 1, u'also': 1, u'reader': 1, 'we': 1, u'his': 1, u'them': 1, u'believ': 1, u'ask': 1, u'recent': 1, 'on': 1, u'sister': 1, u'this': 1, 'of': 2, u'favorit': 1, 'i': 1, u'while': 1, u'can': 1, u'degrad': 1}\n"
     ]
    }
   ],
   "source": [
    "#Get coco\n",
    "loTest.getCoco(cocoWindow)\n",
    "\n",
    "#        self.cocoWindow=k\n",
    "#        self.cocoDict={}\n",
    "#        self.TF={}\n",
    "#        self.docTF={}\n",
    "\n",
    "print('%%%%\\ncocoDict, length ' + str(len(loTest.cocoDict)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.cocoDict.keys()[:10])\n",
    "print('---the first entry:')\n",
    "key1 = loTest.cocoDict.keys()[0]\n",
    "print(key1)\n",
    "print(loTest.cocoDict[key1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loTest.svdK: 50\n",
      "%%%%\n",
      "DSM, length 2204\n",
      "---the first ten keys:\n",
      "['', u'four', u'sleep', u'forget', u'whose', u'accus', u'undef', u'stationeri', u'fruitsthes', u'messi']\n",
      "---the first entry:\n",
      "{0: 2.250030726824928, 1: -1.6625018991590188, 2: 0.33959243374647519, 3: -0.65423069715429683, 4: 0.63097381705044087, 5: -0.77170979123689398, 6: -0.80568757270759117, 7: 0.38710367861832806, 8: 0.25050585298016792, 9: -0.041514994028513136, 10: -0.23189680204328039, 11: 0.67749896114374075, 12: -0.76674798734494731, 13: -0.60353229278840936, 14: 0.4173730924903542, 15: 0.020219434731801437, 16: -0.42413192654984083, 17: -0.15095375726082993, 18: -1.0209453414165417, 19: 0.14271549227933167, 20: 0.35107263667184369, 21: -0.019734265698426231, 22: -0.03053779001664671, 23: 0.45512673103756973, 24: 0.41960278882803054, 25: -0.39895717278697457, 26: 0.024747933995976492, 27: 0.061895361420451371, 28: -0.021608557388601034, 29: 1.0131785965367117, 30: -0.21298024703134727, 31: -0.52597836470181358, 32: 0.17258088201413638, 33: 0.62491140061972661, 34: -0.3902692404175081, 35: 0.48227286895672711, 36: 0.010121591977520539, 37: -0.23174191510514794, 38: 0.24503337880768061, 39: 0.22515754744020558, 40: 0.95149254266623207, 41: -0.31823680230256479, 42: 0.37869610821842453, 43: -0.35603011091765452, 44: 0.018090544208068875, 45: -0.25568503760983624, 46: -0.096659711587884195, 47: 0.021567956959243698, 48: -0.6663565443833217, 49: 0.58701869022925046}\n"
     ]
    }
   ],
   "source": [
    "#Get DSM\n",
    "loTest.getDSM(svdInt)\n",
    "print('loTest.svdK: ' + str(loTest.svdK))\n",
    "\n",
    "print('%%%%\\nDSM, length ' + str(len(loTest.DSM)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.DSM.keys()[:10])\n",
    "print('---the first entry:')\n",
    "print(loTest.DSM[loTest.DSM.keys()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the old way\n",
    "##### adjadv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'not', u'more', u'when', u'onli', u'good', u'how', 'so', u'poor', u'mani', u'veri']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./prototype_python/lingual.py:437: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  targetDF.sort(['count'],inplace=True,ascending=False)\n"
     ]
    }
   ],
   "source": [
    "#Set keywords\n",
    "loTest.setKeywords('adjAdv',targetWordCount,startCount)\n",
    "print(loTest.keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# the new way\n",
    "#### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', u'our', u'talk', u'get', 'my', u'worker', u'maurin', u'poverti', u'you', u'love']\n"
     ]
    }
   ],
   "source": [
    "loTest.setKeywords('tfidf',targetWordCount,startCount)\n",
    "print(loTest.keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### the guts of the new way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>four</td>\n",
       "      <td>91</td>\n",
       "      <td>9.164835</td>\n",
       "      <td>2.215374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cyprus</td>\n",
       "      <td>8</td>\n",
       "      <td>104.250000</td>\n",
       "      <td>4.646792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lord</td>\n",
       "      <td>15</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>4.018183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digit</td>\n",
       "      <td>9</td>\n",
       "      <td>92.666667</td>\n",
       "      <td>4.529009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prize</td>\n",
       "      <td>18</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>3.835862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     term  freq         idf    logidf\n",
       "0    four    91    9.164835  2.215374\n",
       "1  cyprus     8  104.250000  4.646792\n",
       "2    lord    15   55.600000  4.018183\n",
       "3   digit     9   92.666667  4.529009\n",
       "4   prize    18   46.333333  3.835862"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfFile = 'wiki-test-5-IDF.csv'\n",
    "idf = pd.read_csv('./wiki-IDF/' + idfFile)\n",
    "idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2612.000000</td>\n",
       "      <td>2612.000000</td>\n",
       "      <td>2612.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.557427</td>\n",
       "      <td>65.961852</td>\n",
       "      <td>3.847418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>83.011571</td>\n",
       "      <td>43.172716</td>\n",
       "      <td>0.989037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>3.325036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>59.571429</td>\n",
       "      <td>4.087176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>104.250000</td>\n",
       "      <td>4.646792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>834.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              freq          idf       logidf\n",
       "count  2612.000000  2612.000000  2612.000000\n",
       "mean     36.557427    65.961852     3.847418\n",
       "std      83.011571    43.172716     0.989037\n",
       "min       6.000000     1.000000     0.000000\n",
       "25%       8.000000    27.800000     3.325036\n",
       "50%      14.000000    59.571429     4.087176\n",
       "75%      30.000000   104.250000     4.646792\n",
       "max     834.000000   139.000000     4.934474"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#idf.ix[loTest.keywords[0]]\n",
    "#loTest.keywords[0]\n",
    "idf = idf.set_index('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senat</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abolish</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mph</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milk</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excess</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gordon</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gone</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minnesota</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seventeenth</th>\n",
       "      <td>6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             freq    idf    logidf\n",
       "term                              \n",
       "threat          6  139.0  4.934474\n",
       "senat           6  139.0  4.934474\n",
       "abolish         6  139.0  4.934474\n",
       "mph             6  139.0  4.934474\n",
       "milk            6  139.0  4.934474\n",
       "excess          6  139.0  4.934474\n",
       "gordon          6  139.0  4.934474\n",
       "gone            6  139.0  4.934474\n",
       "minnesota       6  139.0  4.934474\n",
       "seventeenth     6  139.0  4.934474"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.sort_values(by='idf', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linknum:num</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>833</td>\n",
       "      <td>1.001200</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>831</td>\n",
       "      <td>1.003610</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>815</td>\n",
       "      <td>1.023313</td>\n",
       "      <td>0.023045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>804</td>\n",
       "      <td>1.037313</td>\n",
       "      <td>0.036634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             freq       idf    logidf\n",
       "term                                 \n",
       "of            834  1.000000  0.000000\n",
       ",             834  1.000000  0.000000\n",
       ":             834  1.000000  0.000000\n",
       "linknum:num   834  1.000000  0.000000\n",
       ".             834  1.000000  0.000000\n",
       "the           834  1.000000  0.000000\n",
       "and           833  1.001200  0.001200\n",
       "in            831  1.003610  0.003604\n",
       "a             815  1.023313  0.023045\n",
       "to            804  1.037313  0.036634"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.sort_values(by='idf', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "freq        6.000000\n",
       "idf       139.000000\n",
       "logidf      4.934474\n",
       "Name: milk, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#idf.head()\n",
    "idf.ix['milk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "freq      202.000000\n",
       "idf         4.128713\n",
       "logidf      1.417966\n",
       "Name: not, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(loTest.keywords[0])\n",
    "idf.ix[loTest.keywords[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4179657049599999"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.ix[loTest.keywords[0]].tolist()\n",
    "idf.ix[loTest.keywords[0]][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not\n",
      "freq      202.000000\n",
      "idf         4.128713\n",
      "logidf      1.417966\n",
      "Name: not, dtype: float64\n",
      "when\n",
      "freq      155.000000\n",
      "idf         5.380645\n",
      "logidf      1.682808\n",
      "Name: when, dtype: float64\n",
      "so\n",
      "freq      45.000000\n",
      "idf       18.533333\n",
      "logidf     2.919571\n",
      "Name: so, dtype: float64\n",
      "poor\n",
      "freq      15.000000\n",
      "idf       55.600000\n",
      "logidf     4.018183\n",
      "Name: poor, dtype: float64\n",
      "onli\n",
      "freq      155.000000\n",
      "idf         5.380645\n",
      "logidf      1.682808\n",
      "Name: onli, dtype: float64\n",
      "other\n",
      "freq      321.000000\n",
      "idf         2.598131\n",
      "logidf      0.954792\n",
      "Name: other, dtype: float64\n",
      "good\n",
      "freq      24.00000\n",
      "idf       34.75000\n",
      "logidf     3.54818\n",
      "Name: good, dtype: float64\n",
      "where\n",
      "freq      78.000000\n",
      "idf       10.692308\n",
      "logidf     2.369525\n",
      "Name: where, dtype: float64\n",
      "last\n",
      "freq      80.000000\n",
      "idf       10.425000\n",
      "logidf     2.344207\n",
      "Name: last, dtype: float64\n",
      "own\n",
      "freq      59.000000\n",
      "idf       14.135593\n",
      "logidf     2.648696\n",
      "Name: own, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for keyword in loTest.keywords:\n",
    "    try:\n",
    "        print(keyword)\n",
    "        print(idf.ix[keyword])\n",
    "    except:\n",
    "        print(keyword)\n",
    "        print('NOT FOUND')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loTest.rawText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10781\n",
      "[u'the', u'cathol', u'worker', u'june', u'num', u'num', u'summari', u'societ', u'structur', u'need', 'to', 'be', u'built', 'so', u'that', 'it', u'will', 'be', u'easi', 'to']\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "#[all_words + toke for toke in loTest.tokens.values()]\n",
    "for toke in loTest.tokens.values():\n",
    "    all_words = all_words + toke\n",
    "\n",
    "print(len(all_words))\n",
    "print(all_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqDF (2053, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>msgr</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatr</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protest</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldest</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         freq\n",
       "term         \n",
       "msgr        3\n",
       "hatr        1\n",
       "four        4\n",
       "protest     6\n",
       "oldest      1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "freq = FreqDist(all_words) ## create FreqDist object with word frequencies\n",
    "#\n",
    "columns_obj = [\"term\", \"freq\"]\n",
    "freqDF = pd.DataFrame(freq.items(), columns=columns_obj) # convert it to a data frame\n",
    "freqDF = freqDF.set_index('term')\n",
    "print('freqDF ' + str(freqDF.shape))\n",
    "freqDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqit (2053, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>msgr</th>\n",
       "      <td>3</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatr</th>\n",
       "      <td>1</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>4</td>\n",
       "      <td>9.164835</td>\n",
       "      <td>2.215374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protest</th>\n",
       "      <td>6</td>\n",
       "      <td>49.058824</td>\n",
       "      <td>3.893020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldest</th>\n",
       "      <td>1</td>\n",
       "      <td>25.272727</td>\n",
       "      <td>3.229726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         freq         idf    logidf\n",
       "term                               \n",
       "msgr        3  139.000000  4.934474\n",
       "hatr        1  139.000000  4.934474\n",
       "four        4    9.164835  2.215374\n",
       "protest     6   49.058824  3.893020\n",
       "oldest      1   25.272727  3.229726"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#freqit = pd.concat([freqDF, idf])\n",
    "freqit = freqDF.join(idf[['idf', 'logidf']])\n",
    "# replace null values with max\n",
    "maxidf = max(freqit['idf'].dropna())\n",
    "maxlogidf = max(freqit['logidf'].dropna())\n",
    "freqit.loc[pd.isnull(freqit['idf']), 'idf'] = maxidf\n",
    "freqit.loc[pd.isnull(freqit['logidf']), 'logidf'] = maxlogidf\n",
    "\n",
    "\n",
    "print('freqit ' + str(freqit.shape))\n",
    "freqit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [freq, idf, logidf]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# should be empty, if the above cell has worked correctly\n",
    "print(freqit[pd.isnull(freqit['idf'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freqit['tfidf'] = freqit['freq'] * freqit['idf']\n",
    "freqit['logtfidf'] = freqit['freq'] * freqit['logidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2053, 5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#freqit = freqit.dropna(subset=['freq'], how='all')\n",
    "freqit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>idf</th>\n",
       "      <th>logidf</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>logtfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>132</td>\n",
       "      <td>75.818182</td>\n",
       "      <td>4.328338</td>\n",
       "      <td>10008.000000</td>\n",
       "      <td>571.340633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker</th>\n",
       "      <td>56</td>\n",
       "      <td>92.666667</td>\n",
       "      <td>4.529009</td>\n",
       "      <td>5189.333333</td>\n",
       "      <td>253.624494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>our</th>\n",
       "      <td>60</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>4.018183</td>\n",
       "      <td>3336.000000</td>\n",
       "      <td>241.090992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>23</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>3197.000000</td>\n",
       "      <td>113.492900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>39</td>\n",
       "      <td>64.153846</td>\n",
       "      <td>4.161284</td>\n",
       "      <td>2502.000000</td>\n",
       "      <td>162.290078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>29</td>\n",
       "      <td>75.818182</td>\n",
       "      <td>4.328338</td>\n",
       "      <td>2198.727273</td>\n",
       "      <td>125.521806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communism</th>\n",
       "      <td>17</td>\n",
       "      <td>119.142857</td>\n",
       "      <td>4.780323</td>\n",
       "      <td>2025.428571</td>\n",
       "      <td>81.265495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>17</td>\n",
       "      <td>119.142857</td>\n",
       "      <td>4.780323</td>\n",
       "      <td>2025.428571</td>\n",
       "      <td>81.265495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>16</td>\n",
       "      <td>119.142857</td>\n",
       "      <td>4.780323</td>\n",
       "      <td>1906.285714</td>\n",
       "      <td>76.485172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communist</th>\n",
       "      <td>39</td>\n",
       "      <td>43.894737</td>\n",
       "      <td>3.781794</td>\n",
       "      <td>1711.894737</td>\n",
       "      <td>147.489983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>picket</th>\n",
       "      <td>12</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>59.213687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cathol</th>\n",
       "      <td>50</td>\n",
       "      <td>33.360000</td>\n",
       "      <td>3.507358</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>175.367879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tri</th>\n",
       "      <td>12</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>59.213687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>19</td>\n",
       "      <td>83.400000</td>\n",
       "      <td>4.423648</td>\n",
       "      <td>1584.600000</td>\n",
       "      <td>84.049318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>28</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>4.018183</td>\n",
       "      <td>1556.800000</td>\n",
       "      <td>112.509130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chapter</th>\n",
       "      <td>13</td>\n",
       "      <td>119.142857</td>\n",
       "      <td>4.780323</td>\n",
       "      <td>1548.857143</td>\n",
       "      <td>62.144202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me</th>\n",
       "      <td>11</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1529.000000</td>\n",
       "      <td>54.279213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk</th>\n",
       "      <td>10</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1390.000000</td>\n",
       "      <td>49.344739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dont</th>\n",
       "      <td>10</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1390.000000</td>\n",
       "      <td>49.344739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christ</th>\n",
       "      <td>13</td>\n",
       "      <td>104.250000</td>\n",
       "      <td>4.646792</td>\n",
       "      <td>1355.250000</td>\n",
       "      <td>60.408294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <td>55</td>\n",
       "      <td>23.828571</td>\n",
       "      <td>3.170885</td>\n",
       "      <td>1310.571429</td>\n",
       "      <td>174.398694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felt</th>\n",
       "      <td>9</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1251.000000</td>\n",
       "      <td>44.410265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pray</th>\n",
       "      <td>9</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1251.000000</td>\n",
       "      <td>44.410265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1251.000000</td>\n",
       "      <td>44.410265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evil</th>\n",
       "      <td>9</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>1251.000000</td>\n",
       "      <td>44.410265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>21</td>\n",
       "      <td>59.571429</td>\n",
       "      <td>4.087176</td>\n",
       "      <td>1251.000000</td>\n",
       "      <td>85.830698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>10</td>\n",
       "      <td>119.142857</td>\n",
       "      <td>4.780323</td>\n",
       "      <td>1191.428571</td>\n",
       "      <td>47.803233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strike</th>\n",
       "      <td>10</td>\n",
       "      <td>119.142857</td>\n",
       "      <td>4.780323</td>\n",
       "      <td>1191.428571</td>\n",
       "      <td>47.803233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cooper</th>\n",
       "      <td>11</td>\n",
       "      <td>104.250000</td>\n",
       "      <td>4.646792</td>\n",
       "      <td>1146.750000</td>\n",
       "      <td>51.114710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>must</th>\n",
       "      <td>19</td>\n",
       "      <td>59.571429</td>\n",
       "      <td>4.087176</td>\n",
       "      <td>1131.857143</td>\n",
       "      <td>77.656345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>influenc</th>\n",
       "      <td>1</td>\n",
       "      <td>10.425000</td>\n",
       "      <td>2.344207</td>\n",
       "      <td>10.425000</td>\n",
       "      <td>2.344207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>known</th>\n",
       "      <td>4</td>\n",
       "      <td>2.542683</td>\n",
       "      <td>0.933220</td>\n",
       "      <td>10.170732</td>\n",
       "      <td>3.732879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offici</th>\n",
       "      <td>2</td>\n",
       "      <td>5.085366</td>\n",
       "      <td>1.626367</td>\n",
       "      <td>10.170732</td>\n",
       "      <td>3.252734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>led</th>\n",
       "      <td>1</td>\n",
       "      <td>9.928571</td>\n",
       "      <td>2.295417</td>\n",
       "      <td>9.928571</td>\n",
       "      <td>2.295417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>produc</th>\n",
       "      <td>1</td>\n",
       "      <td>9.811765</td>\n",
       "      <td>2.283582</td>\n",
       "      <td>9.811765</td>\n",
       "      <td>2.283582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main</th>\n",
       "      <td>1</td>\n",
       "      <td>9.811765</td>\n",
       "      <td>2.283582</td>\n",
       "      <td>9.811765</td>\n",
       "      <td>2.283582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>1</td>\n",
       "      <td>9.477273</td>\n",
       "      <td>2.248897</td>\n",
       "      <td>9.477273</td>\n",
       "      <td>2.248897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creat</th>\n",
       "      <td>1</td>\n",
       "      <td>9.477273</td>\n",
       "      <td>2.248897</td>\n",
       "      <td>9.477273</td>\n",
       "      <td>2.248897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>center</th>\n",
       "      <td>1</td>\n",
       "      <td>8.872340</td>\n",
       "      <td>2.182939</td>\n",
       "      <td>8.872340</td>\n",
       "      <td>2.182939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>establish</th>\n",
       "      <td>1</td>\n",
       "      <td>8.687500</td>\n",
       "      <td>2.161885</td>\n",
       "      <td>8.687500</td>\n",
       "      <td>2.161885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>form</th>\n",
       "      <td>2</td>\n",
       "      <td>4.298969</td>\n",
       "      <td>1.458375</td>\n",
       "      <td>8.597938</td>\n",
       "      <td>2.916750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near</th>\n",
       "      <td>1</td>\n",
       "      <td>8.424242</td>\n",
       "      <td>2.131114</td>\n",
       "      <td>8.424242</td>\n",
       "      <td>2.131114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kingdom</th>\n",
       "      <td>1</td>\n",
       "      <td>8.340000</td>\n",
       "      <td>2.121063</td>\n",
       "      <td>8.340000</td>\n",
       "      <td>2.121063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most</th>\n",
       "      <td>4</td>\n",
       "      <td>2.079800</td>\n",
       "      <td>0.732272</td>\n",
       "      <td>8.319202</td>\n",
       "      <td>2.929088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under</th>\n",
       "      <td>1</td>\n",
       "      <td>7.867925</td>\n",
       "      <td>2.062794</td>\n",
       "      <td>7.867925</td>\n",
       "      <td>2.062794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>larg</th>\n",
       "      <td>1</td>\n",
       "      <td>7.722222</td>\n",
       "      <td>2.044102</td>\n",
       "      <td>7.722222</td>\n",
       "      <td>2.044102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>western</th>\n",
       "      <td>1</td>\n",
       "      <td>7.722222</td>\n",
       "      <td>2.044102</td>\n",
       "      <td>7.722222</td>\n",
       "      <td>2.044102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>until</th>\n",
       "      <td>1</td>\n",
       "      <td>7.581818</td>\n",
       "      <td>2.025753</td>\n",
       "      <td>7.581818</td>\n",
       "      <td>2.025753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citi</th>\n",
       "      <td>2</td>\n",
       "      <td>3.626087</td>\n",
       "      <td>1.288154</td>\n",
       "      <td>7.252174</td>\n",
       "      <td>2.576308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>1</td>\n",
       "      <td>7.067797</td>\n",
       "      <td>1.955549</td>\n",
       "      <td>7.067797</td>\n",
       "      <td>1.955549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numth</th>\n",
       "      <td>2</td>\n",
       "      <td>3.418033</td>\n",
       "      <td>1.229065</td>\n",
       "      <td>6.836066</td>\n",
       "      <td>2.458130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intern</th>\n",
       "      <td>1</td>\n",
       "      <td>6.780488</td>\n",
       "      <td>1.914049</td>\n",
       "      <td>6.780488</td>\n",
       "      <td>1.914049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>includ</th>\n",
       "      <td>2</td>\n",
       "      <td>2.808081</td>\n",
       "      <td>1.032501</td>\n",
       "      <td>5.616162</td>\n",
       "      <td>2.065003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>although</th>\n",
       "      <td>1</td>\n",
       "      <td>5.380645</td>\n",
       "      <td>1.682808</td>\n",
       "      <td>5.380645</td>\n",
       "      <td>1.682808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>becam</th>\n",
       "      <td>1</td>\n",
       "      <td>5.180124</td>\n",
       "      <td>1.644829</td>\n",
       "      <td>5.180124</td>\n",
       "      <td>1.644829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>develop</th>\n",
       "      <td>1</td>\n",
       "      <td>5.180124</td>\n",
       "      <td>1.644829</td>\n",
       "      <td>5.180124</td>\n",
       "      <td>1.644829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>million</th>\n",
       "      <td>1</td>\n",
       "      <td>4.848837</td>\n",
       "      <td>1.578739</td>\n",
       "      <td>4.848837</td>\n",
       "      <td>1.578739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>east</th>\n",
       "      <td>1</td>\n",
       "      <td>4.711864</td>\n",
       "      <td>1.550084</td>\n",
       "      <td>4.711864</td>\n",
       "      <td>1.550084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cultur</th>\n",
       "      <td>1</td>\n",
       "      <td>4.483871</td>\n",
       "      <td>1.500487</td>\n",
       "      <td>4.483871</td>\n",
       "      <td>1.500487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>1</td>\n",
       "      <td>3.195402</td>\n",
       "      <td>1.161713</td>\n",
       "      <td>3.195402</td>\n",
       "      <td>1.161713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2053 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           freq         idf    logidf         tfidf    logtfidf\n",
       "term                                                           \n",
       "we          132   75.818182  4.328338  10008.000000  571.340633\n",
       "worker       56   92.666667  4.529009   5189.333333  253.624494\n",
       "our          60   55.600000  4.018183   3336.000000  241.090992\n",
       "get          23  139.000000  4.934474   3197.000000  113.492900\n",
       "love         39   64.153846  4.161284   2502.000000  162.290078\n",
       "say          29   75.818182  4.328338   2198.727273  125.521806\n",
       "communism    17  119.142857  4.780323   2025.428571   81.265495\n",
       "want         17  119.142857  4.780323   2025.428571   81.265495\n",
       "my           16  119.142857  4.780323   1906.285714   76.485172\n",
       "communist    39   43.894737  3.781794   1711.894737  147.489983\n",
       "picket       12  139.000000  4.934474   1668.000000   59.213687\n",
       "cathol       50   33.360000  3.507358   1668.000000  175.367879\n",
       "tri          12  139.000000  4.934474   1668.000000   59.213687\n",
       "know         19   83.400000  4.423648   1584.600000   84.049318\n",
       "poor         28   55.600000  4.018183   1556.800000  112.509130\n",
       "chapter      13  119.142857  4.780323   1548.857143   62.144202\n",
       "me           11  139.000000  4.934474   1529.000000   54.279213\n",
       "talk         10  139.000000  4.934474   1390.000000   49.344739\n",
       "dont         10  139.000000  4.934474   1390.000000   49.344739\n",
       "christ       13  104.250000  4.646792   1355.250000   60.408294\n",
       "her          55   23.828571  3.170885   1310.571429  174.398694\n",
       "felt          9  139.000000  4.934474   1251.000000   44.410265\n",
       "pray          9  139.000000  4.934474   1251.000000   44.410265\n",
       "fr            9  139.000000  4.934474   1251.000000   44.410265\n",
       "evil          9  139.000000  4.934474   1251.000000   44.410265\n",
       "go           21   59.571429  4.087176   1251.000000   85.830698\n",
       "too          10  119.142857  4.780323   1191.428571   47.803233\n",
       "strike       10  119.142857  4.780323   1191.428571   47.803233\n",
       "cooper       11  104.250000  4.646792   1146.750000   51.114710\n",
       "must         19   59.571429  4.087176   1131.857143   77.656345\n",
       "...         ...         ...       ...           ...         ...\n",
       "influenc      1   10.425000  2.344207     10.425000    2.344207\n",
       "known         4    2.542683  0.933220     10.170732    3.732879\n",
       "offici        2    5.085366  1.626367     10.170732    3.252734\n",
       "led           1    9.928571  2.295417      9.928571    2.295417\n",
       "produc        1    9.811765  2.283582      9.811765    2.283582\n",
       "main          1    9.811765  2.283582      9.811765    2.283582\n",
       "base          1    9.477273  2.248897      9.477273    2.248897\n",
       "creat         1    9.477273  2.248897      9.477273    2.248897\n",
       "center        1    8.872340  2.182939      8.872340    2.182939\n",
       "establish     1    8.687500  2.161885      8.687500    2.161885\n",
       "form          2    4.298969  1.458375      8.597938    2.916750\n",
       "near          1    8.424242  2.131114      8.424242    2.131114\n",
       "kingdom       1    8.340000  2.121063      8.340000    2.121063\n",
       "most          4    2.079800  0.732272      8.319202    2.929088\n",
       "under         1    7.867925  2.062794      7.867925    2.062794\n",
       "larg          1    7.722222  2.044102      7.722222    2.044102\n",
       "western       1    7.722222  2.044102      7.722222    2.044102\n",
       "until         1    7.581818  2.025753      7.581818    2.025753\n",
       "citi          2    3.626087  1.288154      7.252174    2.576308\n",
       "follow        1    7.067797  1.955549      7.067797    1.955549\n",
       "numth         2    3.418033  1.229065      6.836066    2.458130\n",
       "intern        1    6.780488  1.914049      6.780488    1.914049\n",
       "includ        2    2.808081  1.032501      5.616162    2.065003\n",
       "although      1    5.380645  1.682808      5.380645    1.682808\n",
       "becam         1    5.180124  1.644829      5.180124    1.644829\n",
       "develop       1    5.180124  1.644829      5.180124    1.644829\n",
       "million       1    4.848837  1.578739      4.848837    1.578739\n",
       "east          1    4.711864  1.550084      4.711864    1.550084\n",
       "cultur        1    4.483871  1.500487      4.483871    1.500487\n",
       "name          1    3.195402  1.161713      3.195402    1.161713\n",
       "\n",
       "[2053 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqit = freqit.sort_values(by='tfidf', ascending=False) \n",
    "freqit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we',\n",
       " u'worker',\n",
       " u'our',\n",
       " u'get',\n",
       " u'love',\n",
       " u'say',\n",
       " u'communism',\n",
       " u'want',\n",
       " 'my',\n",
       " u'communist']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startCount=0\n",
    "wordCount=10\n",
    "freqit.iloc[startCount:wordCount+startCount].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doing a little exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not: 94\n",
      "when: 67\n",
      "so: 58\n",
      "onli: 28\n",
      "where: 28\n",
      "mani: 23\n",
      "then: 23\n",
      "good: 24\n",
      "more: 23\n",
      "back: 22\n"
     ]
    }
   ],
   "source": [
    "for word in loTest.keywords:\n",
    "    print(word + ': ' + str(freq[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%\n",
      "not: freq      262.000000\n",
      "idf       803.729008\n",
      "logidf      6.689262\n",
      "Name: not, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "when not found in IDF\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "so not found in IDF\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "onli not found in IDF\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "where: freq      390.000000\n",
      "idf       539.941026\n",
      "logidf      6.291460\n",
      "Name: where, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "mani: freq      103808.000000\n",
      "idf            2.028524\n",
      "logidf         0.707308\n",
      "Name: mani, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "then not found in IDF\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "good: freq      43387.000000\n",
      "idf           4.853458\n",
      "logidf        1.579692\n",
      "Name: good, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "more: freq      458.000000\n",
      "idf       459.775109\n",
      "logidf      6.130737\n",
      "Name: more, dtype: float64\n",
      "%%%%%%%%\n",
      "%%%%%%%%\n",
      "back: freq      61096.000000\n",
      "idf           3.446658\n",
      "logidf        1.237405\n",
      "Name: back, dtype: float64\n",
      "%%%%%%%%\n"
     ]
    }
   ],
   "source": [
    "for word in loTest.keywords:\n",
    "    try:\n",
    "        print('%%%%%%%%\\n' + word + ': ' + str(idf.ix[word]) + '\\n%%%%%%%%')\n",
    "    except:\n",
    "        print('%%%%%%%%\\n' + word + ' not found in IDF\\n%%%%%%%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vermin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>four</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>protest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mansion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oldest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>whose</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>accus</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>under</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lord</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hedg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sway</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>worth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hatr</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>everi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>newburgh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rise</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vase</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>arous</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>govern</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>enslav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>scholar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>commonw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mancent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>straight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>fritter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>enjoy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>probabl</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>diego</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>diplomat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>jocist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>detail</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>book</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>arama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>rememb</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>varieti</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>u</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>repeat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>monday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>uncomprehend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>class</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>june</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>stay</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>thoreau</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>quotat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>ghost</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>experienc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>atheist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>drbaker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>encycl</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>rule</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>syllabl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>influenc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>craft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>rural</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>decemb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>confess</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2235 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              term  freq\n",
       "0                      5\n",
       "1           vermin     2\n",
       "2             four     7\n",
       "3          protest     1\n",
       "4            sleep     5\n",
       "5          mansion     2\n",
       "6           oldest     1\n",
       "7             hate     3\n",
       "8            whose     4\n",
       "9            accus     4\n",
       "10           under     5\n",
       "11            lord     6\n",
       "12            hedg     1\n",
       "13            sway     1\n",
       "14           worth     1\n",
       "15            hatr     2\n",
       "16           everi     3\n",
       "17        newburgh     1\n",
       "18            rise     2\n",
       "19            vase     1\n",
       "20           arous     1\n",
       "21          govern     3\n",
       "22          enslav     2\n",
       "23          school     2\n",
       "24         scholar     2\n",
       "25         commonw     1\n",
       "26         mancent     1\n",
       "27        straight     1\n",
       "28         fritter     1\n",
       "29           enjoy     3\n",
       "...            ...   ...\n",
       "2205       probabl     5\n",
       "2206         diego     1\n",
       "2207      diplomat     1\n",
       "2208        jocist     1\n",
       "2209        detail     1\n",
       "2210          book    18\n",
       "2211         arama     1\n",
       "2212        rememb     4\n",
       "2213       varieti     3\n",
       "2214             u     2\n",
       "2215        repeat     1\n",
       "2216        monday     1\n",
       "2217  uncomprehend     1\n",
       "2218         class     5\n",
       "2219          june     1\n",
       "2220          stay     7\n",
       "2221       thoreau     2\n",
       "2222        quotat     1\n",
       "2223         ghost     2\n",
       "2224     experienc     1\n",
       "2225       atheist     1\n",
       "2226       drbaker     1\n",
       "2227        encycl     8\n",
       "2228          rule     1\n",
       "2229       syllabl     1\n",
       "2230      influenc     2\n",
       "2231         craft     1\n",
       "2232         rural     5\n",
       "2233        decemb     1\n",
       "2234       confess     1\n",
       "\n",
       "[2235 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # term_frequency is a dict which structure is like:\n",
    "    # {\n",
    "    #     'path_to_file': \n",
    "    #         {'term': 13.4, 'another_term': 15}, \n",
    "    #     'another_file': \n",
    "    #         {'term2': 12, 'foo': 15}\n",
    "    #  } \n",
    "    for term in freq.keys():\n",
    "        if isintance(term_frequency[text], dict):\n",
    "            term_frequency[text][term] = freq[term]/numbers_of_words\n",
    "        else:\n",
    "            term_frequency[text] = {term: freq[term]/numbers_of_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'not', u'good', u'then', u'even', u'when', 'so', u'here', u'other', u'also', u'differ']\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "#stemmer = nltk.stem.snowball.EnglishStemmer()\n",
    "#stemkeywords=[stemmer.stem(word) for word in loTest.keywords]\n",
    "#print(stemkeywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%\n",
      "not\n",
      "{u'all': 2, u'distanc': 1, u'they': 2, u'just': 2, u'queen': 1, u'sage': 1, u'becaus': 3, u'violent': 1, u'go': 1, u'chair': 1, u'still': 1, u'find': 1, u'help': 1, u'fit': 1, u'readabl': 1, u'should': 2, 'to': 11, u'book': 1, u'factor': 1, u'sens': 2, u'delici': 1, u'has': 1, u'might': 1, u'real': 1, 'do': 3, u'good': 1, u'everi': 1, u'read': 2, u'dessert': 1, u'somebodi': 1, u'know': 1, u'codecerror': 11, u'veri': 1, u'one': 1, u'school': 1, u'anyth': 5, u'smell': 1, u'drop': 1, u'these': 1, u'bad': 2, u'contain': 1, u'plank': 1, u'enjoy': 1, u'the': 23, u'right': 2, u'mental': 1, u'natur': 1, u'mind': 3, u'realli': 1, u'see': 1, u'are': 16, u'seeabl': 1, u'cold': 1, u'infinit': 1, u'serv': 1, u'what': 1, u'said': 1, u'for': 3, u'bhagavad': 1, u'someth': 1, u'abl': 2, u'uniform': 1, u'doer': 1, u'experi': 1, 'be': 6, 'we': 3, u'who': 1, u'led': 1, u'isol': 1, u'here': 1, u'bodi': 3, u'ask': 1, u'eye': 1, u'come': 1, 'by': 2, u'faith': 2, 'of': 2, u'could': 1, u'vidyalayam': 1, u'thing': 1, u'outsid': 1, u'share': 1, 'or': 4, u'gita': 1, u'feel': 1, u'guidelin': 2, u'yourself': 1, u'open': 1, u'your': 5, u'use': 2, u'from': 2, u'log': 1, u'there': 5, u'happi': 2, u'start': 1, u'live': 1, u'way': 2, u'spring': 1, u'scope': 1, u'was': 1, u'that': 7, u'forc': 1, u'peopl': 2, u'but': 8, u'drown': 1, u'hear': 2, u'compani': 1, u'with': 2, u'eat': 2, 'he': 2, 'me': 1, u'made': 1, u'word': 1, u'look': 1, u'perceiv': 1, u'this': 3, u'work': 1, 'us': 1, u'can': 13, u'problem': 1, u'everyon': 1, u'expect': 2, u'and': 8, u'give': 2, u'certain': 1, 'is': 12, 'am': 2, 'it': 6, 'an': 1, u'say': 1, u'his': 1, u'exist': 2, 'at': 1, u'have': 4, 'in': 5, u'disappear': 1, 'if': 3, u'result': 1, u'selfish': 1, u'sit': 1, u'anoth': 1, u'when': 1, u'same': 4, u'intellect': 1, u'alway': 1, u'other': 1, u'rememb': 1, u'you': 19, u'simpl': 1, u'shall': 1, u'may': 1, u'object': 3, u'moment': 1, u'fruit': 1, u'whether': 1, u'water': 1, u'extern': 1, u'peac': 1, u'man': 1, 'a': 5, u'essenti': 1, 'i': 3, u'bind': 1, u'proud': 1, u'doe': 3, u'thought': 1, u'part': 1, u'adam': 1, u'allow': 1, u'everyth': 4}\n",
      "%%%%%\n",
      "good\n",
      "{u'and': 2, u'all': 1, u'have': 2, u'creat': 1, u'they': 1, u'feel': 1, u'natur': 1, 'is': 5, u'hard': 1, u'disciplin': 2, u'not': 1, 'as': 1, u'are': 4, u'want': 1, 'in': 1, u'proper': 1, u'home': 1, u'find': 1, u'might': 1, u'what': 3, u'nonsmok': 1, u'televis': 1, u'get': 1, u'yogi': 1, u'been': 1, 'to': 3, u'program': 1, u'call': 1, u'build': 1, u'environ': 1, u'you': 4, 'if': 1, u'codecerror': 3, u'noth': 1, 'do': 1, u'good': 2, u'that': 2, u'some': 1, u'after': 1, u'pave': 1, u'befor': 1, u'know': 1, u'satsang': 2, u'veri': 1, u'yoga': 1, u'compani': 9, u'grow': 1, u'those': 1, u'must': 1, 'a': 1, 'on': 2, u'join': 3, u'this': 1, 'of': 1, 'up': 1, u'charact': 3, u'will': 1, u'thing': 2, u'place': 1, u'the': 11, u'manner': 2}\n",
      "%%%%%\n",
      "then\n",
      "{u'and': 7, u'codecerror': 1, u'guidelin': 1, 'is': 4, u'becaus': 1, u'yourself': 2, u'alway': 1, 'as': 1, u'are': 4, u'tabl': 2, u'ship': 1, u'yes': 1, u'even': 1, u'decid': 1, u'ash': 1, u'depend': 1, u'guest': 1, u'suprem': 1, 'to': 1, u'relax': 1, u'sometim': 1, u'been': 1, u'plank': 3, u'their': 1, u'wood': 3, u'call': 1, u'sens': 1, u'you': 4, u'immedi': 1, u'until': 1, 'be': 1, u'finish': 1, u'see': 1, u'though': 2, u'may': 1, u'tree': 1, u'time': 1, u'piec': 1, 'it': 2, u'how': 1, u'chair': 1, u'made': 1, u'they': 1, u'delici': 1, u'now': 1, u'burnt': 1, u'the': 9, u'log': 2, 'a': 1, u'experi': 1, u'practic': 1, u'never': 1, u'conscious': 1, u'whether': 1, 'of': 3, u'into': 1, u'sit': 1, u'alon': 1, u'remain': 2, 'us': 1, u'benefit': 1, u'were': 1, u'chang': 1, u'principl': 1, 'my': 1, 'or': 1, u'for': 1}\n",
      "%%%%%\n",
      "even\n",
      "{u'blind': 1, u'vedanta': 1, u'all': 1, u'help': 1, 'be': 1, u'give': 2, u'natur': 1, 'it': 2, u'down': 1, u'perpetu': 1, u'dazzl': 1, u'want': 1, 'in': 5, u'go': 1, u'our': 1, u'ship': 1, u'faith': 1, u'your': 3, 'if': 2, u'awar': 1, u'use': 1, u'spiritu': 1, u'daytoday': 1, u'with': 1, u'sometim': 1, u'littl': 1, 'to': 2, u'again': 1, u'seeker': 1, u'lot': 1, u'you': 3, u'codecerror': 1, u'more': 1, u'then': 1, u'them': 1, u'which': 1, u'though': 3, u'may': 1, u'shallow': 2, u'here': 1, u'hand': 1, u'water': 2, u'fruit': 1, u'they': 1, u'compani': 1, u'nobodi': 1, u'effort': 1, u'longer': 1, 'a': 3, u'also': 1, u'room': 1, u'anyth': 1, u'this': 1, 'of': 1, u'bother': 1, 'no': 1, 'up': 1, 'or': 1, u'will': 3, u'without': 1, u'grain': 1, u'smoke': 1, u'push': 1, u'field': 1, u'the': 3, u'think': 1, u'daili': 1, 'at': 1}\n",
      "%%%%%\n",
      "when\n",
      "{u'and': 2, u'old': 1, u'help': 1, u'activ': 1, 'is': 4, u'emot': 1, u'one': 2, u'say': 1, u'are': 3, u'slip': 1, 'in': 1, 'go': 1, u'forget': 1, u'your': 2, u'stage': 1, u'fill': 1, u'selfish': 1, u'onli': 2, u'ear': 1, u'built': 1, u'daytoday': 1, u'someth': 2, u'there': 1, u'seat': 1, u'young': 1, u'eat': 1, 'to': 2, u'other': 2, u'analyz': 1, u'you': 10, u'deafen': 1, u'codecerror': 2, 'be': 1, u'that': 2, u'forc': 1, u'absorb': 1, u'never': 1, u'reach': 1, u'use': 1, u'but': 1, u'bodi': 1, u'know': 1, u'they': 1, u'not': 1, u'affect': 1, u'now': 1, u'with': 1, u'day': 1, u'like': 1, 'on': 1, u'went': 1, u'avoid': 1, 'i': 2, 'of': 1, u'thing': 1, u'each': 1, u'the': 2, u'think': 1, u'expect': 1}\n",
      "%%%%%\n",
      "so\n",
      "{u'our': 2, u'and': 1, u'all': 1, u'they': 3, 'be': 1, u'feel': 1, u'guidelin': 1, 'is': 2, 'in': 2, u'mind': 1, u'becaus': 1, u'capac': 1, u'see': 1, u'are': 5, u'want': 1, u'someth': 1, u'seen': 1, u'your': 1, 'as': 2, 'if': 1, u'caus': 1, u'differ': 1, u'said': 1, u'end': 1, 'i': 1, u'also': 1, u'section': 1, u'there': 2, u'bowl': 1, u'thank': 1, u'long': 1, u'should': 1, 'to': 6, u'other': 1, u'health': 1, u'too': 1, u'natur': 2, u'sens': 1, u'you': 5, u'man': 1, u'gave': 1, 'do': 3, 'we': 1, u'his': 1, u'return': 1, u'truth': 1, u'that': 4, u'mess': 1, u'peopl': 1, u'who': 1, u'watch': 1, u'hand': 1, u'vomit': 1, u'codecerror': 2, u'share': 1, u'shun': 1, u'compani': 1, u'with': 1, u'chang': 1, u'physic': 1, u'must': 1, 'a': 2, u'experienc': 1, u'this': 1, 'of': 1, 'up': 1, u'separ': 1, u'collect': 1, u'achiev': 1, u'can': 1, u'smoke': 1, u'mani': 1, u'the': 5, u'purpos': 1, 'or': 1, u'say': 1}\n",
      "%%%%%\n",
      "here\n",
      "{u'and': 3, u'old': 1, u'guidelin': 2, u'over': 1, 'it': 1, u'born': 2, 'as': 2, u'are': 2, u'have': 1, 'in': 3, u'our': 1, u'your': 1, u'communiti': 1, 'if': 2, u'even': 1, u'yogavill': 2, u'harmoni': 1, 'no': 2, u'ruin': 1, u'littl': 1, u'should': 1, 'to': 1, u'live': 1, u'you': 5, u'main': 1, 'is': 2, u'more': 1, 'be': 4, u'vibrat': 1, u'that': 1, u'shallow': 1, u'but': 1, u'codecerror': 3, u'refin': 1, u'not': 1, u'come': 2, 'by': 1, 'a': 1, 'i': 1, 'of': 2, u'benefit': 1, u'follow': 3, u'can': 1, u'wild': 1, u'mani': 1, u'the': 6, u'purpos': 1, u'similar': 1}\n",
      "%%%%%\n",
      "other\n",
      "{u'and': 2, u'right': 1, u'help': 2, u'ten': 1, u'speci': 1, 'is': 1, u'share': 1, u'becaus': 1, u'one': 2, u'offer': 1, u'kill': 1, u'are': 3, u'slip': 1, u'find': 1, 'if': 1, u'said': 1, u'group': 1, u'appear': 1, u'for': 1, u'also': 1, u'with': 1, u'there': 2, u'when': 2, u'same': 1, u'should': 1, 'to': 4, u'live': 1, u'chamber': 1, 'it': 2, 'so': 1, u'you': 2, u'codecerror': 1, 'be': 1, 'we': 1, u'that': 1, u'may': 1, u'peopl': 1, u'innermost': 1, u'hand': 3, u'somebodi': 1, u'togeth': 2, u'they': 3, u'not': 1, u'from': 2, 'on': 4, u'come': 1, u'peac': 1, u'gregorian': 1, 'a': 2, u'pull': 1, u'protect': 1, u'lead': 1, u'chant': 1, 'no': 1, u'well': 1, 'as': 1, u'know': 1, u'thing': 1, u'environ': 1, u'can': 2, u'each': 4, 'at': 1, u'the': 10, u'view': 2, u'silver': 1, u'ourselv': 1}\n",
      "%%%%%\n",
      "also\n",
      "{u'and': 2, u'natur': 1, 'is': 1, u'accord': 1, u'annihil': 1, u'are': 4, u'children': 1, u'even': 1, u'spiritu': 2, u'realm': 1, u'for': 1, 'to': 1, u'highest': 1, u'there': 1, u'same': 1, u'field': 1, u'book': 1, u'you': 2, u'experi': 2, 'we': 2, u'truth': 1, u'that': 2, u'but': 1, u'bodi': 1, u'part': 1, u'know': 1, u'ash': 1, u'ident': 1, 'of': 1, 'so': 1, u'can': 3, u'though': 1, u'the': 9, u'other': 1, u'adult': 1}\n",
      "%%%%%\n",
      "differ\n",
      "{u'and': 3, u'all': 1, u'identifi': 1, u'feel': 1, 'is': 3, u'mind': 1, u'are': 3, u'have': 2, 'in': 2, u'total': 1, u'your': 3, u'given': 1, u'from': 2, u'etc': 1, u'there': 2, u'capac': 2, 'to': 2, u'seeker': 1, u'suppos': 1, u'suit': 1, u'got': 2, u'you': 2, u'therefor': 1, u'method': 1, u'real': 1, u'that': 3, u'peopl': 3, u'men': 2, u'differ': 2, u'but': 1, u'bodi': 2, u'reason': 1, u'understand': 1, u'know': 1, u'codecerror': 1, u'such': 1, 'by': 1, u'present': 1, 'a': 1, u'these': 1, 'of': 6, u'facet': 1, 'i': 1, 'so': 1, u'she': 1, u'abov': 1, u'grasp': 1, u'opinion': 1, u'the': 5, u'view': 1}\n",
      "{u'respond': 2, u'faith': 1, u'ultim': 1, 'is': 1, 'to': 2, u'codecerror': 1, u'the': 3, u'essenc': 1}\n"
     ]
    }
   ],
   "source": [
    "for key in loTest.keywords: ### get context vectors for keywords...\n",
    "    print('%%%%%\\n' + key)\n",
    "    print(loTest.cocoDict[key]) # fails on 'only' and then again on 'spiritual'\n",
    "\n",
    "#print(loTest.cocoDict['spiritual'])\n",
    "print(loTest.cocoDict['spirit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for key in stemkeywords: ### get context vectors for keywords...\n",
    "#    print('%%%%%\\n' + key)\n",
    "#    print(loTest.cocoDict[key]) # fails on 'only' and then again on 'spiritual'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV05.txt\n",
      "not\n",
      "good\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "here\n",
      "other\n",
      "also\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt\n",
      "not\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n"
     ]
    }
   ],
   "source": [
    "## keywords in each file\n",
    "for thisfile in subFileList:\n",
    "    print(thisfile)\n",
    "    filetokens = loTest.tokens[thisfile]\n",
    "    for keyword in loTest.keywords:\n",
    "         if keyword in filetokens:\n",
    "                print(keyword)\n",
    "#    if 'spirtual' in filetokens:\n",
    "#        print(\"UAL!\")\n",
    "#    if 'spirit' in filetokens:\n",
    "#        print(\"SPIRIT!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV05.txt\n",
      "not\n",
      "good\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "here\n",
      "other\n",
      "also\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt\n",
      "not\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt\n",
      "not\n",
      "then\n",
      "even\n",
      "when\n",
      "so\n",
      "other\n",
      "also\n",
      "differ\n"
     ]
    }
   ],
   "source": [
    "## STEM keywords in each file\n",
    "for thisfile in subFileList:\n",
    "    print(thisfile)\n",
    "    filetokens = loTest.tokens[thisfile]\n",
    "    for keyword in stemkeywords:\n",
    "         if keyword in filetokens:\n",
    "                print(keyword)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loTest.cvWindow: 3\n",
      "%%%%\n",
      "cvDict, length 4\n",
      "---the first ten keys:\n",
      "['./data_dsicap/IntegralYoga/raw/YV58.txt', './data_dsicap/IntegralYoga/raw/YV48.txt', './data_dsicap/IntegralYoga/raw/YV54.txt', './data_dsicap/IntegralYoga/raw/YV05.txt']\n",
      "---the keywords each file:\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt: [u'not', u'even', u'when', u'other', 'so']\n",
      "./data_dsicap/IntegralYoga/raw/YV05.txt: [u'even', u'then', u'good', u'when', u'here', u'also', u'other', 'so', u'not']\n",
      "%%%%%%%\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt (8 keys):\n",
      "---keys: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 5 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "---------length of thisfile[even][2]: 50\n",
      "---------length of thisfile[even][3]: 50\n",
      "---------length of thisfile[even][4]: 50\n",
      "---------length of thisfile[even][5]: 50\n",
      "------thisfile[then]:\n",
      "-------length: \"then\" appears 10 times in this file.\n",
      "---------length of thisfile[then][1]: 50\n",
      "---------length of thisfile[then][2]: 50\n",
      "---------length of thisfile[then][3]: 50\n",
      "---------length of thisfile[then][4]: 50\n",
      "---------length of thisfile[then][5]: 50\n",
      "---------length of thisfile[then][6]: 50\n",
      "---------length of thisfile[then][7]: 50\n",
      "---------length of thisfile[then][8]: 50\n",
      "---------length of thisfile[then][9]: 50\n",
      "---------length of thisfile[then][10]: 50\n",
      "------thisfile[differ]:\n",
      "-------length: \"differ\" appears 9 times in this file.\n",
      "---------length of thisfile[differ][1]: 50\n",
      "---------length of thisfile[differ][2]: 50\n",
      "---------length of thisfile[differ][3]: 50\n",
      "---------length of thisfile[differ][4]: 50\n",
      "---------length of thisfile[differ][5]: 50\n",
      "---------length of thisfile[differ][6]: 50\n",
      "---------length of thisfile[differ][7]: 50\n",
      "---------length of thisfile[differ][8]: 50\n",
      "---------length of thisfile[differ][9]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 3 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "------thisfile[also]:\n",
      "-------length: \"also\" appears 5 times in this file.\n",
      "---------length of thisfile[also][1]: 50\n",
      "---------length of thisfile[also][2]: 50\n",
      "---------length of thisfile[also][3]: 50\n",
      "---------length of thisfile[also][4]: 50\n",
      "---------length of thisfile[also][5]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 4 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "---------length of thisfile[other][4]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 6 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "---------length of thisfile[so][4]: 50\n",
      "---------length of thisfile[so][5]: 50\n",
      "---------length of thisfile[so][6]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 24 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "---------length of thisfile[not][9]: 50\n",
      "---------length of thisfile[not][10]: 50\n",
      "---------length of thisfile[not][11]: 50\n",
      "---------length of thisfile[not][12]: 50\n",
      "---------length of thisfile[not][13]: 50\n",
      "---------length of thisfile[not][14]: 50\n",
      "---------length of thisfile[not][15]: 50\n",
      "---------length of thisfile[not][16]: 50\n",
      "---------length of thisfile[not][17]: 50\n",
      "---------length of thisfile[not][18]: 50\n",
      "---------length of thisfile[not][19]: 50\n",
      "---------length of thisfile[not][20]: 50\n",
      "---------length of thisfile[not][21]: 50\n",
      "---------length of thisfile[not][22]: 50\n",
      "---------length of thisfile[not][23]: 50\n",
      "---------length of thisfile[not][24]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt (8 keys):\n",
      "---keys: [u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 1 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "------thisfile[then]:\n",
      "-------length: \"then\" appears 1 times in this file.\n",
      "---------length of thisfile[then][1]: 50\n",
      "------thisfile[differ]:\n",
      "-------length: \"differ\" appears 5 times in this file.\n",
      "---------length of thisfile[differ][1]: 50\n",
      "---------length of thisfile[differ][2]: 50\n",
      "---------length of thisfile[differ][3]: 50\n",
      "---------length of thisfile[differ][4]: 50\n",
      "---------length of thisfile[differ][5]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 4 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "---------length of thisfile[when][4]: 50\n",
      "------thisfile[also]:\n",
      "-------length: \"also\" appears 2 times in this file.\n",
      "---------length of thisfile[also][1]: 50\n",
      "---------length of thisfile[also][2]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 2 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 2 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 11 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "---------length of thisfile[not][9]: 50\n",
      "---------length of thisfile[not][10]: 50\n",
      "---------length of thisfile[not][11]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt (5 keys):\n",
      "---keys: [u'not', u'even', u'when', u'other', 'so']\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 8 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 1 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 1 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 3 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 2 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "%%%%%\n",
      "./data_dsicap/IntegralYoga/raw/YV05.txt (9 keys):\n",
      "---keys: [u'even', u'then', u'good', u'when', u'here', u'also', u'other', 'so', u'not']\n",
      "------thisfile[even]:\n",
      "-------length: \"even\" appears 8 times in this file.\n",
      "---------length of thisfile[even][1]: 50\n",
      "---------length of thisfile[even][2]: 50\n",
      "---------length of thisfile[even][3]: 50\n",
      "---------length of thisfile[even][4]: 50\n",
      "---------length of thisfile[even][5]: 50\n",
      "---------length of thisfile[even][6]: 50\n",
      "---------length of thisfile[even][7]: 50\n",
      "---------length of thisfile[even][8]: 50\n",
      "------thisfile[then]:\n",
      "-------length: \"then\" appears 6 times in this file.\n",
      "---------length of thisfile[then][1]: 50\n",
      "---------length of thisfile[then][2]: 50\n",
      "---------length of thisfile[then][3]: 50\n",
      "---------length of thisfile[then][4]: 50\n",
      "---------length of thisfile[then][5]: 50\n",
      "---------length of thisfile[then][6]: 50\n",
      "------thisfile[good]:\n",
      "-------length: \"good\" appears 18 times in this file.\n",
      "---------length of thisfile[good][1]: 50\n",
      "---------length of thisfile[good][2]: 50\n",
      "---------length of thisfile[good][3]: 50\n",
      "---------length of thisfile[good][4]: 50\n",
      "---------length of thisfile[good][5]: 50\n",
      "---------length of thisfile[good][6]: 50\n",
      "---------length of thisfile[good][7]: 50\n",
      "---------length of thisfile[good][8]: 50\n",
      "---------length of thisfile[good][9]: 50\n",
      "---------length of thisfile[good][10]: 50\n",
      "---------length of thisfile[good][11]: 50\n",
      "---------length of thisfile[good][12]: 50\n",
      "---------length of thisfile[good][13]: 50\n",
      "---------length of thisfile[good][14]: 50\n",
      "---------length of thisfile[good][15]: 50\n",
      "---------length of thisfile[good][16]: 50\n",
      "---------length of thisfile[good][17]: 50\n",
      "---------length of thisfile[good][18]: 50\n",
      "------thisfile[when]:\n",
      "-------length: \"when\" appears 6 times in this file.\n",
      "---------length of thisfile[when][1]: 50\n",
      "---------length of thisfile[when][2]: 50\n",
      "---------length of thisfile[when][3]: 50\n",
      "---------length of thisfile[when][4]: 50\n",
      "---------length of thisfile[when][5]: 50\n",
      "---------length of thisfile[when][6]: 50\n",
      "------thisfile[here]:\n",
      "-------length: \"here\" appears 13 times in this file.\n",
      "---------length of thisfile[here][1]: 50\n",
      "---------length of thisfile[here][2]: 50\n",
      "---------length of thisfile[here][3]: 50\n",
      "---------length of thisfile[here][4]: 50\n",
      "---------length of thisfile[here][5]: 50\n",
      "---------length of thisfile[here][6]: 50\n",
      "---------length of thisfile[here][7]: 50\n",
      "---------length of thisfile[here][8]: 50\n",
      "---------length of thisfile[here][9]: 50\n",
      "---------length of thisfile[here][10]: 50\n",
      "---------length of thisfile[here][11]: 50\n",
      "---------length of thisfile[here][12]: 50\n",
      "---------length of thisfile[here][13]: 50\n",
      "------thisfile[also]:\n",
      "-------length: \"also\" appears 2 times in this file.\n",
      "---------length of thisfile[also][1]: 50\n",
      "---------length of thisfile[also][2]: 50\n",
      "------thisfile[other]:\n",
      "-------length: \"other\" appears 8 times in this file.\n",
      "---------length of thisfile[other][1]: 50\n",
      "---------length of thisfile[other][2]: 50\n",
      "---------length of thisfile[other][3]: 50\n",
      "---------length of thisfile[other][4]: 50\n",
      "---------length of thisfile[other][5]: 50\n",
      "---------length of thisfile[other][6]: 50\n",
      "---------length of thisfile[other][7]: 50\n",
      "---------length of thisfile[other][8]: 50\n",
      "------thisfile[so]:\n",
      "-------length: \"so\" appears 8 times in this file.\n",
      "---------length of thisfile[so][1]: 50\n",
      "---------length of thisfile[so][2]: 50\n",
      "---------length of thisfile[so][3]: 50\n",
      "---------length of thisfile[so][4]: 50\n",
      "---------length of thisfile[so][5]: 50\n",
      "---------length of thisfile[so][6]: 50\n",
      "---------length of thisfile[so][7]: 50\n",
      "---------length of thisfile[so][8]: 50\n",
      "------thisfile[not]:\n",
      "-------length: \"not\" appears 20 times in this file.\n",
      "---------length of thisfile[not][1]: 50\n",
      "---------length of thisfile[not][2]: 50\n",
      "---------length of thisfile[not][3]: 50\n",
      "---------length of thisfile[not][4]: 50\n",
      "---------length of thisfile[not][5]: 50\n",
      "---------length of thisfile[not][6]: 50\n",
      "---------length of thisfile[not][7]: 50\n",
      "---------length of thisfile[not][8]: 50\n",
      "---------length of thisfile[not][9]: 50\n",
      "---------length of thisfile[not][10]: 50\n",
      "---------length of thisfile[not][11]: 50\n",
      "---------length of thisfile[not][12]: 50\n",
      "---------length of thisfile[not][13]: 50\n",
      "---------length of thisfile[not][14]: 50\n",
      "---------length of thisfile[not][15]: 50\n",
      "---------length of thisfile[not][16]: 50\n",
      "---------length of thisfile[not][17]: 50\n",
      "---------length of thisfile[not][18]: 50\n",
      "---------length of thisfile[not][19]: 50\n",
      "---------length of thisfile[not][20]: 50\n"
     ]
    }
   ],
   "source": [
    "#######################            \n",
    "###Semantic analysis###\n",
    "#######################\n",
    "\n",
    "#Get context vectors\n",
    "loTest.getContextVectors(cvWindow)\n",
    "print('loTest.cvWindow: ' + str(loTest.cvWindow))\n",
    "\n",
    "#        self.cvWindow=k\n",
    "#        self.cvDict={}\n",
    "\n",
    "print('%%%%\\ncvDict, length ' + str(len(loTest.cvDict)))\n",
    "print('---the first ten keys:')\n",
    "print(loTest.cvDict.keys()[:10])\n",
    "print('---the keywords each file:')\n",
    "for key in loTest.cvDict.keys():\n",
    "    print(key + ': ' + str(loTest.cvDict[key].keys()))\n",
    "print('%%%%%%%')\n",
    "#file1 = loTest.cvDict.keys()[0] #'./data_dsicap/IntegralYoga/raw/YV38.txt'\n",
    "    \n",
    "for file1 in loTest.cvDict.keys():    \n",
    "    first = loTest.cvDict[file1]\n",
    "    #print('---the first entry (length ' + str(len(first[first.keys()[0]])) + '):')\n",
    "    print('%%%%%\\n' + file1 + ' (' + str(len(first.keys())) + ' keys):')\n",
    "    print('---keys: ' + str(first.keys()))\n",
    "    for wordkey in first.keys():\n",
    "        print('------thisfile[' + wordkey + ']:')\n",
    "        tftk = first[wordkey]\n",
    "        print('-------length: \"' + wordkey + '\" appears ' + str(len(tftk.keys())) + ' times in this file.')\n",
    "        for numkey in tftk.keys():\n",
    "            print('---------length of thisfile[' + wordkey +'][' + str(numkey) + ']: ' + str(len(tftk[numkey])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_dsicap/IntegralYoga/raw/YV05.txt\n",
      "[u'even', u'then', u'good', u'when', u'here', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV48.txt\n",
      "[u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "./data_dsicap/IntegralYoga/raw/YV54.txt\n",
      "[u'not', u'even', u'when', u'other', 'so']\n",
      "./data_dsicap/IntegralYoga/raw/YV58.txt\n",
      "[u'even', u'then', u'differ', u'when', u'also', u'other', 'so', u'not']\n",
      "10\n",
      "[u'not', u'good', u'then', u'even', u'when', 'so', u'here', u'other', u'also', u'differ']\n",
      "[0.72404735956380151, 0.70700627327625354, 0.71615225785121706, 0.69572043045266363, 0.75862725558225175, 0.72200533701172254, 0.75878819429898337, 0.67993472478851136, 0.77246014024129339, 0.76795665602778718]\n"
     ]
    }
   ],
   "source": [
    "#Get average semantic density\n",
    "#avgSD=np.mean([x[1] for x in loTest.getSD(simCount)])\n",
    "#print(avgSD)\n",
    "\n",
    "SD = [x[1] for x in loTest.getSD(simCount)]\n",
    "print(len(SD))\n",
    "print(loTest.keywords)\n",
    "print(SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "###POS Tagging and Judgement Analysis###\n",
    "########################################\n",
    "judgementAvg=list(np.mean(np.array([[x[1],x[2]] for x in loTest.getJudgements()]),axis=0))\n",
    "\n",
    "########################\n",
    "###Sentiment Analysis###\n",
    "########################\n",
    "\n",
    "sentimentList=loTest.sentimentLookup()\n",
    "\n",
    "############################\n",
    "###Network Quantification###\n",
    "############################\n",
    "loTest.setNetwork(netAngle)\n",
    "\n",
    "avgEVC=loTest.evc()\n",
    "\n",
    "endTime=time.time()\n",
    "timeRun=endTime-startTime\n",
    "print('finished running'+'_'.join(groupId)+' in '+str(end-start)+' seconds')\n",
    "sys.stdout.flush()\n",
    "\n",
    "#Append outputs to masterOutput\n",
    "return(['_'.join(groupId)]+[len(subFileList),timeRun]+sentimentList+judgementAvg+[avgSD]+[avgEVC])   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
