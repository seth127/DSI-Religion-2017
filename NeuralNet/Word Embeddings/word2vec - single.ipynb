{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings on single documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from functools import reduce\n",
    "import os\n",
    "from os.path import basename\n",
    "import csv\n",
    "TEXT_DATA_DIR='SingleDocSignals'\n",
    "sentences = []  # list of text articles\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "for fname in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    fpath = os.path.join(TEXT_DATA_DIR, fname)\n",
    "    f = open(fpath)\n",
    "    sentences.append(f.read())\n",
    "    f.close()\n",
    "    labels_index[basename(fname)] = len(labels_index)\n",
    "    labels.append(-1)\n",
    "\n",
    "d = []\n",
    "for i in sentences:\n",
    "    words2 = text_to_word_sequence(i, lower=True, split=\" \")\n",
    "    d.append(words2)\n",
    "    \n",
    "sentences = d\n",
    "vocab = sorted(reduce(lambda x, y: x | y, (set(i) for i in d)))\n",
    "\n",
    "# Reserve 0 for masking via pad_sequences\n",
    "vocab_size = len(vocab) + 1\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "story_maxlen = 16\n",
    "X = []\n",
    "for i in sentences:\n",
    "    x = [word_idx[w] for w in i]\n",
    "    X.append(x)\n",
    "\n",
    "X_train = pad_sequences(X,1000)\n",
    "\n",
    "#load labels\n",
    "filePath='SingleDocSignals.csv'\n",
    "with open(filePath,'r') as intputFile:\n",
    "        reader=csv.reader(intputFile,delimiter=',')\n",
    "        for fname,y in reader:\n",
    "            labels[labels_index[fname+\".txt\"]]=int(y)\n",
    "\n",
    "Categories = labels\n",
    "y = np.zeros(9)\n",
    "outputs = list(set(Categories))\n",
    "Y = []\n",
    "for i in Categories:\n",
    "    y = np.zeros(9)\n",
    "    indexV = outputs.index(i)\n",
    "    y[indexV]=1\n",
    "    Y.append(y)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohammad\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "from os.path import join, exists, split\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def train_word2vec(sentence_matrix, vocabulary_inv,\n",
    "                   num_features, min_word_count=1, context=10):\n",
    "    \"\"\"\n",
    "    Trains, saves, loads Word2Vec model\n",
    "    Returns initial weights for embedding layer.\n",
    "   \n",
    "    inputs:\n",
    "    sentence_matrix # int matrix: num_sentences x max_sentence_len\n",
    "    vocabulary_inv  # dict {str:int}\n",
    "    num_features    # Word vector dimensionality                      \n",
    "    min_word_count  # Minimum word count                        \n",
    "    context         # Context window size \n",
    "    \"\"\"\n",
    "    model_dir = 'word2vec_models'\n",
    "    model_name = \"{:d}features_{:d}minwords_{:d}context\".format(num_features, min_word_count, context)\n",
    "    model_name = join(model_dir, model_name)\n",
    "    if exists(model_name):\n",
    "        embedding_model = word2vec.Word2Vec.load(model_name)\n",
    "        print('Loading existing Word2Vec model \\'%s\\'' % split(model_name)[-1])\n",
    "    else:\n",
    "        # Set values for various parameters\n",
    "        num_workers = 2       # Number of threads to run in parallel\n",
    "        downsampling = 1e-3   # Downsample setting for frequent words\n",
    "        \n",
    "        # Initialize and train the model\n",
    "        print(\"Training Word2Vec model...\")\n",
    "        sentences = [[vocabulary_inv[w] for w in s] for s in sentence_matrix]\n",
    "        embedding_model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "                            size=num_features, min_count = min_word_count, \\\n",
    "                            window = context, sample = downsampling)\n",
    "        \n",
    "        # If we don't plan to train the model any further, calling \n",
    "        # init_sims will make the model much more memory-efficient.\n",
    "        embedding_model.init_sims(replace=True)\n",
    "        \n",
    "        # Saving the model for later use. You can load it later using Word2Vec.load()\n",
    "        if not exists(model_dir):\n",
    "            os.mkdir(model_dir)\n",
    "        print('Saving Word2Vec model \\'%s\\'' % split(model_name)[-1])\n",
    "        embedding_model.save(model_name)\n",
    "    \n",
    "    #  add unknown words\n",
    "    embedding_weights = [np.array([embedding_model[w] if w in embedding_model\\\n",
    "                                                        else np.random.uniform(-0.25,0.25,embedding_model.vector_size)\\\n",
    "                                                        for w in vocabulary_inv])]\n",
    "    return embedding_weights\n",
    "\n",
    "# if __name__=='__main__':\n",
    "#     import data_helpers\n",
    "#     print(\"Loading data...\")\n",
    "#     x, _, _, vocabulary_inv = data_helpers.load_data()\n",
    "#     w = train_word2vec(x, vocabulary_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model variation is CNN-rand\n",
      "Loading data...\n",
      "Vocabulary Size: 67890\n",
      "Train on 229 samples, validate on 113 samples\n",
      "Epoch 1/5\n",
      "229/229 [==============================] - 4s - loss: 0.3987 - acc: 0.8622 - val_loss: 0.2681 - val_acc: 0.9184\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/5\n",
      "229/229 [==============================] - 3s - loss: 0.3104 - acc: 0.8937 - val_loss: 0.2534 - val_acc: 0.9184\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/5\n",
      "229/229 [==============================] - 3s - loss: 0.2484 - acc: 0.9098 - val_loss: 0.2553 - val_acc: 0.9174\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 0s - loss: 0.2570 - acc: 0.9083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/5\n",
      "229/229 [==============================] - 3s - loss: 0.1617 - acc: 0.9398 - val_loss: 0.2779 - val_acc: 0.9115\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/5\n",
      "229/229 [==============================] - 3s - loss: 0.0834 - acc: 0.9704 - val_loss: 0.2909 - val_acc: 0.9154\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import data_helpers\n",
    "# from w2v import train_word2vec \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Input, Merge, Convolution1D, MaxPooling1D\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "# Parameters\n",
    "# ==================================================\n",
    "#\n",
    "# Model Variations. See Kim Yoonâ€™s Convolutional Neural Networks for \n",
    "# Sentence Classification, Section 3 for detail.\n",
    "\n",
    "model_variation = 'CNN-rand'  #  CNN-rand | CNN-non-static | CNN-static\n",
    "print('Model variation is %s' % model_variation)\n",
    "\n",
    "# Model Hyperparameters\n",
    "sequence_length = 1000\n",
    "embedding_dim = 100          \n",
    "filter_sizes = (3, 4)\n",
    "num_filters = 100\n",
    "dropout_prob = (0.25, 0.5)\n",
    "hidden_dims = 100\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 5\n",
    "num_epochs = 5\n",
    "val_split = 0.33\n",
    "\n",
    "# Word2Vec parameters, see train_word2vec\n",
    "min_word_count = 1  # Minimum word count                        \n",
    "context = 10        # Context window size    \n",
    "ACTION = \"train\"\n",
    "weights_file = \"weights_file\"\n",
    "# Data Preparatopn\n",
    "# ==================================================\n",
    "#\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "# x, y, vocabulary, vocabulary_inv = data_helpers.load_data()\n",
    "\n",
    "vocabulary= word_idx\n",
    "vocabulary_inv = vocab \n",
    "vocabulary_inv.append(\"</PAD>\")\n",
    "\n",
    "# Shuffle data\n",
    "shuffle_indices = np.random.permutation(np.arange(len(Y)))\n",
    "x_shuffled = X_train[shuffle_indices]\n",
    "y_shuffled = Y[shuffle_indices].argmax(axis=1)\n",
    "nb_validation_samples = int(val_split * len(x_shuffled))\n",
    "x_train_only = x_shuffled[:-nb_validation_samples]\n",
    "\n",
    "if model_variation=='CNN-non-static' or model_variation=='CNN-static':\n",
    "    embedding_weights = train_word2vec(x_train_only, vocabulary_inv, embedding_dim, min_word_count, context)\n",
    "    if model_variation=='CNN-static':\n",
    "        X_train = embedding_weights[0][x_train_only]\n",
    "elif model_variation=='CNN-rand':\n",
    "    embedding_weights = None\n",
    "else:\n",
    "    raise ValueError('Unknown model variation')    \n",
    "\n",
    "\n",
    "\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocabulary)))\n",
    "\n",
    "# find out how vocab is causing problems\n",
    "\n",
    "\n",
    "# Building model\n",
    "# ==================================================\n",
    "#\n",
    "# graph subnet with one input and one output,\n",
    "# convolutional layers concateneted in parallel\n",
    "graph_in = Input(shape=(sequence_length, embedding_dim))\n",
    "convs = []\n",
    "for fsz in filter_sizes:\n",
    "    conv = Convolution1D(nb_filter=num_filters,\n",
    "                         filter_length=fsz,\n",
    "                         border_mode='valid',\n",
    "                         activation='relu',\n",
    "                         subsample_length=1)(graph_in)\n",
    "    pool = MaxPooling1D(pool_length=2)(conv)\n",
    "    flatten = Flatten()(pool)\n",
    "    convs.append(flatten)\n",
    "\n",
    "if len(filter_sizes) > 1:\n",
    "    out = Merge(mode='concat')(convs)\n",
    "else:\n",
    "    out = convs[0]\n",
    "\n",
    "graph = Model(input=graph_in, output=out)\n",
    "# main sequential model\n",
    "model = Sequential()\n",
    "if not model_variation=='CNN-static':\n",
    "    model.add(Embedding(len(vocabulary_inv),embedding_dim, input_length=sequence_length,\n",
    "                        weights=embedding_weights))\n",
    "\n",
    "model.add(Dropout(dropout_prob[0], input_shape=(sequence_length, embedding_dim)))\n",
    "model.add(graph)\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(dropout_prob[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(9))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop',metrics=['accuracy'])\n",
    "#opt = SGD(lr=0.01, momentum=0.80, decay=1e-6, nesterov=True)\n",
    "#model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "if ACTION == \"predict\" and os.path.exists(weights_file):\n",
    "        model.load_weights(weights_file)\n",
    "else:\n",
    "    #model.fit(x_shuffled, y_shuffled, batch_size=batch_size,\n",
    "     #         nb_epoch=num_epochs, validation_split=val_split, verbose=2)\n",
    "    model.fit(X_train, Y, batch_size=batch_size,nb_epoch=num_epochs, validation_split=val_split)\n",
    "    #print(\"dumping weights to file...\")\n",
    "    #model.save_weights(weights_file, overwrite=True)\n",
    "# Training model\n",
    "# ==================================================\n",
    "#model.fit(X_train, Y, batch_size=batch_size,nb_epoch=num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Word-Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- All Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 342 texts.\n",
      "Training Word2Vec model...\n",
      "Most similar to book:\n",
      "('beginning', 0.8126802444458008)\n",
      "('word', 0.7602472305297852)\n",
      "('view', 0.757227897644043)\n",
      "('kingdom', 0.7565963268280029)\n",
      "('passage', 0.7553075551986694)\n",
      "('heat', 0.7506297826766968)\n",
      "('story', 0.7482398748397827)\n",
      "('torah', 0.7370935678482056)\n",
      "(\"ta'an\", 0.7333469986915588)\n",
      "('revelation', 0.7302749156951904)\n",
      "Most similar to man:\n",
      "('woman', 0.7968037128448486)\n",
      "('brother', 0.685215950012207)\n",
      "('wife', 0.683623194694519)\n",
      "('blessing', 0.6799474954605103)\n",
      "('person', 0.6795306205749512)\n",
      "('he', 0.6542274951934814)\n",
      "('child', 0.6527204513549805)\n",
      "('poor', 0.6390407085418701)\n",
      "('whosoever', 0.6388231515884399)\n",
      "('abraham', 0.6291402578353882)\n",
      "Most similar to woman:\n",
      "('child', 0.8534461259841919)\n",
      "('man', 0.7968037128448486)\n",
      "('daughter', 0.7621140480041504)\n",
      "('baby', 0.7436813116073608)\n",
      "('wife', 0.7347227334976196)\n",
      "('legion', 0.7328832149505615)\n",
      "('palace', 0.7258248329162598)\n",
      "('stranger', 0.7244707942008972)\n",
      "('husband', 0.722589910030365)\n",
      "('shot', 0.7161659598350525)\n",
      "Most similar to we:\n",
      "('us', 0.606343150138855)\n",
      "('christians', 0.6038984060287476)\n",
      "('migration', 0.5657778382301331)\n",
      "('happen', 0.5514730215072632)\n",
      "('desirest', 0.546866774559021)\n",
      "('you', 0.5358926653862)\n",
      "('prop', 0.532975971698761)\n",
      "('ledge', 0.5297672152519226)\n",
      "('behaved', 0.5295829772949219)\n",
      "('our', 0.5239185690879822)\n",
      "Most similar to they:\n",
      "('them', 0.6418329477310181)\n",
      "('rebels', 0.6249809265136719)\n",
      "('robbers', 0.6181111931800842)\n",
      "('people', 0.6149054765701294)\n",
      "(\"they'\", 0.6053966283798218)\n",
      "('misgivings', 0.6011759638786316)\n",
      "('men', 0.5936856865882874)\n",
      "('sweets', 0.5926682949066162)\n",
      "('christians', 0.5849591493606567)\n",
      "('abortions', 0.5846662521362305)\n",
      "Distance between 'us' and 'them': 0.501437826233\n",
      "Distance between 'our' and 'their': 0.613397313452\n",
      "Distance between 'we' and 'they': 0.540870101514\n",
      "Distance between 'i' and 'they': 0.590802168373\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import word2vec\n",
    "import data_helpers\n",
    "import numpy as np \n",
    "# Set values for various parameters\n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "num_features=300\n",
    "min_word_count=5\n",
    "context=10\n",
    "\n",
    "TEXT_DATA_DIR='SingleDocSignals'\n",
    "sentences = []  # list of text articles\n",
    "for fname in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    fpath = os.path.join(TEXT_DATA_DIR, fname)\n",
    "    f = open(fpath)\n",
    "    sentences.append(f.read())\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "sentences = [s.strip() for s in sentences]\n",
    "x_text = [data_helpers.clean_str(sent) for sent in sentences]\n",
    "x_text = [s.split(\" \") for s in x_text]\n",
    "    \n",
    "print('Found %s texts.' % len(x_text))\n",
    "# Initialize and train the model\n",
    "print(\"Training Word2Vec model...\")\n",
    "x,  vocabulary, vocabulary_inv =data_helpers.load_data(x_text)\n",
    "sentences = [[vocabulary_inv[w] for w in s] for s in x]\n",
    "embedding_model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "                    size=num_features, min_count = min_word_count, \\\n",
    "                    window = context, sample = downsampling)\n",
    " \n",
    "# If we don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "embedding_model.init_sims(replace=True)\n",
    "words=['book','man','woman','we','they']\n",
    "for word in words:\n",
    "    print ('Most similar to %s:' % word)\n",
    "    sim=embedding_model.most_similar(word,topn=10)\n",
    "    for w_sim in sim:\n",
    "        print (w_sim)\n",
    "print (\"Distance between 'us' and 'them':\", (1-embedding_model.wv.similarity('us', 'them')))\n",
    "print (\"Distance between 'our' and 'their':\", (1-embedding_model.wv.similarity('our', 'their')))\n",
    "print (\"Distance between 'we' and 'they':\", (1-embedding_model.wv.similarity('we', 'they')))\n",
    "print (\"Distance between 'i' and 'they':\", (1-embedding_model.wv.similarity('i', 'they')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between 'us' and 'them': 0.29255531341\n",
      "Distance between 'our' and 'their': 0.482712232815\n",
      "Distance between 'we' and 'they': 0.351189502355\n",
      "Distance between 'i' and 'they': 0.786774077005\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model_name='GoogleNews-vectors-negative300.bin'\n",
    "embedding_model = Word2Vec.load_word2vec_format(model_name, binary=True)\n",
    "print (\"Distance between 'us' and 'them':\", (1-embedding_model.wv.similarity('us', 'them')))\n",
    "print (\"Distance between 'our' and 'their':\", (1-embedding_model.wv.similarity('our', 'their')))\n",
    "print (\"Distance between 'we' and 'they':\", (1-embedding_model.wv.similarity('we', 'they')))\n",
    "print (\"Distance between 'i' and 'they':\", (1-embedding_model.wv.similarity('i', 'they')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Liberal Judaism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34 texts.\n",
      "Training Word2Vec model...\n",
      "Most similar to book:\n",
      "('being', 0.999659538269043)\n",
      "('towards', 0.9996157884597778)\n",
      "('take', 0.9996099472045898)\n",
      "('also', 0.9996005296707153)\n",
      "('human', 0.9995778799057007)\n",
      "('makes', 0.9995735883712769)\n",
      "('torah', 0.9995177388191223)\n",
      "('clear', 0.9995163679122925)\n",
      "('within', 0.9994983673095703)\n",
      "('more', 0.9994863867759705)\n",
      "Most similar to man:\n",
      "('an', 0.9995979070663452)\n",
      "('when', 0.9994972944259644)\n",
      "('about', 0.9994536638259888)\n",
      "('or', 0.9994368553161621)\n",
      "('life', 0.9993894696235657)\n",
      "('even', 0.9993335604667664)\n",
      "('future', 0.99932461977005)\n",
      "('which', 0.9993187189102173)\n",
      "('humanity', 0.9993013739585876)\n",
      "('person', 0.9992953538894653)\n",
      "Most similar to woman:\n",
      "('behalf', 0.9969239234924316)\n",
      "('person', 0.9967086315155029)\n",
      "('just', 0.9966903328895569)\n",
      "('would', 0.9964863061904907)\n",
      "('there', 0.9964463710784912)\n",
      "('or', 0.996443510055542)\n",
      "('team', 0.9964284896850586)\n",
      "('why', 0.9964030981063843)\n",
      "('very', 0.99639892578125)\n",
      "('they', 0.9963756203651428)\n",
      "Most similar to we:\n",
      "('be', 0.9980192184448242)\n",
      "('i', 0.9979609251022339)\n",
      "('you', 0.9966896772384644)\n",
      "('not', 0.9960704445838928)\n",
      "('know', 0.9960492253303528)\n",
      "('it', 0.9954832792282104)\n",
      "('but', 0.9948976039886475)\n",
      "('closer', 0.994325578212738)\n",
      "('inevitably', 0.9930291771888733)\n",
      "('step', 0.9929853081703186)\n",
      "Most similar to they:\n",
      "('would', 0.9995485544204712)\n",
      "('just', 0.9995078444480896)\n",
      "('been', 0.9994871616363525)\n",
      "('when', 0.9994625449180603)\n",
      "('even', 0.9993895888328552)\n",
      "('say', 0.999356746673584)\n",
      "('person', 0.9993491172790527)\n",
      "('often', 0.9993338584899902)\n",
      "('there', 0.9993144273757935)\n",
      "('where', 0.9992473125457764)\n",
      "Distance between 'us' and 'them': 0.00219731017456\n",
      "Distance between 'our' and 'their': 0.0155386446754\n",
      "Distance between 'we' and 'they': 0.0433900242986\n",
      "Distance between 'i' and 'they': 0.0370294725182\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import word2vec\n",
    "import data_helpers\n",
    "import numpy as np \n",
    "# Set values for various parameters\n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "num_features=50\n",
    "min_word_count=5\n",
    "context=4\n",
    "\n",
    "TEXT_DATA_DIR='SingleDocSignals.LiberalJudaism'\n",
    "sentences = []  # list of text articles\n",
    "for fname in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    fpath = os.path.join(TEXT_DATA_DIR, fname)\n",
    "    f = open(fpath)\n",
    "    sentences.append(f.read())\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "sentences = [s.strip() for s in sentences]\n",
    "x_text = [data_helpers.clean_str(sent) for sent in sentences]\n",
    "x_text = [s.split(\" \") for s in x_text]\n",
    "    \n",
    "print('Found %s texts.' % len(x_text))\n",
    "# Initialize and train the model\n",
    "print(\"Training Word2Vec model...\")\n",
    "x,  vocabulary, vocabulary_inv =data_helpers.load_data(x_text)\n",
    "sentences = [[vocabulary_inv[w] for w in s] for s in x]\n",
    "embedding_model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "                    size=num_features, min_count = min_word_count, \\\n",
    "                    window = context, sample = downsampling)\n",
    " \n",
    "# If we don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "embedding_model.init_sims(replace=True)\n",
    "words=['book','man','woman' ,'we','they']\n",
    "for word in words:\n",
    "    print ('Most similar to %s:' % word)\n",
    "    if word in vocabulary:\n",
    "        sim=embedding_model.most_similar(word,topn=10)\n",
    "        for w_sim in sim:\n",
    "            print (w_sim)\n",
    "    else:\n",
    "        print (\"Not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- ISIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 texts.\n",
      "Training Word2Vec model...\n",
      "Most similar to book:\n",
      "('ta', 0.9889437556266785)\n",
      "('follow', 0.9885311126708984)\n",
      "('make', 0.9885040521621704)\n",
      "('one', 0.988458514213562)\n",
      "('has', 0.9884455800056458)\n",
      "('no', 0.9884402751922607)\n",
      "('whose', 0.9883753061294556)\n",
      "('us', 0.9883221983909607)\n",
      "('if', 0.9882023930549622)\n",
      "('them', 0.9881460666656494)\n",
      "Most similar to man:\n",
      "('ummah', 0.9987025260925293)\n",
      "('allah', 0.998604953289032)\n",
      "('she', 0.9985135197639465)\n",
      "('within', 0.9984798431396484)\n",
      "('jihad', 0.9983980655670166)\n",
      "('by', 0.9983532428741455)\n",
      "('towards', 0.9983308911323547)\n",
      "('islam', 0.9983193278312683)\n",
      "('may', 0.998298168182373)\n",
      "('position', 0.9982853531837463)\n",
      "Most similar to we:\n",
      "('page', 0.9995814561843872)\n",
      "('at', 0.999549388885498)\n",
      "('you', 0.999499499797821)\n",
      "('l', 0.999442994594574)\n",
      "('have', 0.9993689060211182)\n",
      "('he', 0.9993428587913513)\n",
      "('my', 0.9993402361869812)\n",
      "('other', 0.9993234872817993)\n",
      "('were', 0.9991870522499084)\n",
      "('hid', 0.9989795684814453)\n",
      "Most similar to they:\n",
      "('one', 0.999672532081604)\n",
      "('an', 0.9996317625045776)\n",
      "('people', 0.9996235966682434)\n",
      "('or', 0.9996224641799927)\n",
      "('against', 0.999598503112793)\n",
      "('then', 0.9995970726013184)\n",
      "('those', 0.9995813369750977)\n",
      "('were', 0.9995664954185486)\n",
      "('on', 0.9995375871658325)\n",
      "('if', 0.9995316863059998)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import word2vec\n",
    "import data_helpers\n",
    "import numpy as np \n",
    "# Set values for various parameters\n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "num_features=50\n",
    "min_word_count=5\n",
    "context=4\n",
    "\n",
    "TEXT_DATA_DIR='SingleDocSignals.ISIS'\n",
    "sentences = []  # list of text articles\n",
    "for fname in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    fpath = os.path.join(TEXT_DATA_DIR, fname)\n",
    "    f = open(fpath)\n",
    "    sentences.append(f.read())\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "sentences = [s.strip() for s in sentences]\n",
    "x_text = [data_helpers.clean_str(sent) for sent in sentences]\n",
    "x_text = [s.split(\" \") for s in x_text]\n",
    "    \n",
    "print('Found %s texts.' % len(x_text))\n",
    "# Initialize and train the model\n",
    "print(\"Training Word2Vec model...\")\n",
    "x,  vocabulary, vocabulary_inv =data_helpers.load_data(x_text)\n",
    "sentences = [[vocabulary_inv[w] for w in s] for s in x]\n",
    "embedding_model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "                    size=num_features, min_count = min_word_count, \\\n",
    "                    window = context, sample = downsampling)\n",
    " \n",
    "# If we don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "embedding_model.init_sims(replace=True)\n",
    "words=['book','man','we','they']\n",
    "for word in words:\n",
    "    print ('Most similar to %s:' % word)\n",
    "    sim=embedding_model.most_similar(word,topn=10)\n",
    "    for w_sim in sim:\n",
    "        print (w_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Dorothy Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 texts.\n",
      "Training Word2Vec model...\n",
      "Most similar to book:\n",
      "('when', 0.9988095164299011)\n",
      "('on', 0.9987618923187256)\n",
      "('had', 0.9987297654151917)\n",
      "('our', 0.9986756443977356)\n",
      "('baby', 0.9986304044723511)\n",
      "('was', 0.9986129403114319)\n",
      "('place', 0.9985895752906799)\n",
      "('many', 0.9985389709472656)\n",
      "('a', 0.998504638671875)\n",
      "('three', 0.9984842538833618)\n",
      "Most similar to man:\n",
      "('are', 0.9988906383514404)\n",
      "('is', 0.9986475706100464)\n",
      "('remember', 0.998629629611969)\n",
      "('through', 0.9983686208724976)\n",
      "('to', 0.9980978965759277)\n",
      "('without', 0.9980942010879517)\n",
      "('worker', 0.9978844523429871)\n",
      "('let', 0.9976675510406494)\n",
      "('own', 0.9975814819335938)\n",
      "('any', 0.9974715709686279)\n",
      "Most similar to woman:\n",
      "('asked', 0.9927756786346436)\n",
      "('battle', 0.9917311072349548)\n",
      "('faith', 0.991574764251709)\n",
      "('best', 0.9906504154205322)\n",
      "('without', 0.9905869364738464)\n",
      "('dead', 0.9903661012649536)\n",
      "('religion', 0.9902663230895996)\n",
      "('each', 0.9902605414390564)\n",
      "('kitchen', 0.9901933073997498)\n",
      "('apostolate', 0.9900656938552856)\n",
      "Most similar to we:\n",
      "('who', 0.9997252225875854)\n",
      "('all', 0.9996834993362427)\n",
      "('have', 0.9996803998947144)\n",
      "('could', 0.9996551275253296)\n",
      "('this', 0.9996088147163391)\n",
      "('her', 0.9995864629745483)\n",
      "('were', 0.9995795488357544)\n",
      "('not', 0.9995739459991455)\n",
      "('been', 0.9995671510696411)\n",
      "('them', 0.9995661377906799)\n",
      "Most similar to they:\n",
      "('by', 0.9995452165603638)\n",
      "('two', 0.9992057085037231)\n",
      "('at', 0.999117374420166)\n",
      "('will', 0.9990106821060181)\n",
      "('out', 0.9988404512405396)\n",
      "('down', 0.9986932873725891)\n",
      "('very', 0.9986919164657593)\n",
      "('be', 0.9986005425453186)\n",
      "('ddlw', 0.9985743761062622)\n",
      "('six', 0.9980535507202148)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import word2vec\n",
    "import data_helpers\n",
    "import numpy as np \n",
    "# Set values for various parameters\n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "num_features=50\n",
    "min_word_count=5\n",
    "context=4\n",
    "\n",
    "TEXT_DATA_DIR='SingleDocSignals.DorothyDay'\n",
    "sentences = []  # list of text articles\n",
    "for fname in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    fpath = os.path.join(TEXT_DATA_DIR, fname)\n",
    "    f = open(fpath)\n",
    "    sentences.append(f.read())\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "sentences = [s.strip() for s in sentences]\n",
    "x_text = [data_helpers.clean_str(sent) for sent in sentences]\n",
    "x_text = [s.split(\" \") for s in x_text]\n",
    "    \n",
    "print('Found %s texts.' % len(x_text))\n",
    "# Initialize and train the model\n",
    "print(\"Training Word2Vec model...\")\n",
    "x,  vocabulary, vocabulary_inv =data_helpers.load_data(x_text)\n",
    "sentences = [[vocabulary_inv[w] for w in s] for s in x]\n",
    "embedding_model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "                    size=num_features, min_count = min_word_count, \\\n",
    "                    window = context, sample = downsampling)\n",
    " \n",
    "# If we don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "embedding_model.init_sims(replace=True)\n",
    "words=['book','man','woman','we','they']\n",
    "for word in words:\n",
    "    print ('Most similar to %s:' % word)\n",
    "    sim=embedding_model.most_similar(word,topn=10)\n",
    "    for w_sim in sim:\n",
    "        print (w_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 342 texts.\n",
      "Training Word2Vec model...\n",
      "Saving Word2Vec model 'singleDocFiles.model'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import word2vec\n",
    "import data_helpers\n",
    "import numpy as np\n",
    "from os.path import basename\n",
    "# Set values for various parameters\n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "num_features=300\n",
    "min_word_count=5\n",
    "context=4\n",
    "\n",
    "TEXT_DATA_DIR='SingleDocSignals'\n",
    "sentences = []  # list of text articles\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "for fname in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    fpath = os.path.join(TEXT_DATA_DIR, fname)\n",
    "    f = open(fpath)\n",
    "    sentences.append(f.read())\n",
    "    f.close()\n",
    "    labels_index[basename(fname)] = len(labels_index)\n",
    "    labels.append(-1)\n",
    "    \n",
    "\n",
    "#load labels\n",
    "filePath='SingleDocSignals.csv'\n",
    "with open(filePath,'r') as intputFile:\n",
    "        reader=csv.reader(intputFile,delimiter=',')\n",
    "        for fname,y in reader:\n",
    "            labels[labels_index[fname+\".txt\"]]=int(y)\n",
    "\n",
    "Categories = labels\n",
    "y = np.zeros(9)\n",
    "outputs = list(set(Categories))\n",
    "Y = []\n",
    "for i in Categories:\n",
    "    y = np.zeros(9)\n",
    "    indexV = outputs.index(i)\n",
    "    y[indexV]=1\n",
    "    Y.append(y)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "sentences = [s.strip() for s in sentences]\n",
    "x_text = [data_helpers.clean_str(sent) for sent in sentences]\n",
    "x_text = [s.split(\" \") for s in x_text]\n",
    "    \n",
    "print('Found %s texts.' % len(x_text))\n",
    "# Initialize and train the model\n",
    "print(\"Training Word2Vec model...\")\n",
    "x,  vocabulary, vocabulary_inv =data_helpers.load_data(x_text)\n",
    "sentences = [[vocabulary_inv[w] for w in s] for s in x]\n",
    "embedding_model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "                    size=num_features, min_count = min_word_count, \\\n",
    "                    window = context, sample = downsampling)\n",
    "\n",
    "# add unknown words\n",
    "embedding_weights = [np.array([embedding_model[w] if w in embedding_model else np.random.uniform(-0.25, 0.25, embedding_model.vector_size) for w in vocabulary_inv])]\n",
    "    \n",
    "# If we don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "embedding_model.init_sims(replace=True)\n",
    "\n",
    "model_name='singleDocFiles.model'\n",
    "# Saving the model for later use. You can load it later using Word2Vec.load()\n",
    "print('Saving Word2Vec model \\'%s\\'' % model_name)\n",
    "embedding_model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6f964388f041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_model' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kingdom', 0.943721354007721),\n",
       " ('dimension', 0.9416903853416443),\n",
       " ('view', 0.9359270930290222),\n",
       " ('generation', 0.9345726370811462),\n",
       " ('version', 0.9285362958908081),\n",
       " ('age', 0.92758709192276),\n",
       " ('creation', 0.925341784954071),\n",
       " ('root', 0.9246485829353333),\n",
       " ('parashah', 0.9170214533805847),\n",
       " ('story', 0.9161022901535034)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('book',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "Found 342 texts.\n",
      "Found 42662 unique tokens.\n",
      "Shape of data tensor: (342, 1000)\n",
      "Shape of label tensor: (342, 10)\n",
      "Training model.\n",
      "Train on 230 samples, validate on 112 samples\n",
      "Epoch 1/5\n",
      "230/230 [==============================] - 4s - loss: 2.1726 - acc: 0.2043 - val_loss: 1.9192 - val_acc: 0.2768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/5\n",
      "230/230 [==============================] - 0s - loss: 1.8120 - acc: 0.2913 - val_loss: 1.8117 - val_acc: 0.2768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/5\n",
      "230/230 [==============================] - 0s - loss: 1.6901 - acc: 0.2913 - val_loss: 1.8006 - val_acc: 0.2768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/5\n",
      "230/230 [==============================] - 0s - loss: 1.6689 - acc: 0.3000 - val_loss: 1.8247 - val_acc: 0.2857\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/5\n",
      "230/230 [==============================] - 0s - loss: 1.5552 - acc: 0.2957 - val_loss: 1.9620 - val_acc: 0.2768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Ø¢', 0.6506636738777161),\n",
       " ('response', 0.6387784481048584),\n",
       " ('sinlessly', 0.6278092861175537),\n",
       " ('inviti', 0.6270052194595337),\n",
       " ('currents', 0.6263452172279358),\n",
       " ('blasphemed', 0.6253533363342285),\n",
       " ('attempts', 0.6243857145309448),\n",
       " ('daniel', 0.6224669218063354),\n",
       " ('beyond', 0.6223004460334778),\n",
       " ('num', 0.6203035116195679)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import csv\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "import sys\n",
    "from os.path import basename\n",
    "\n",
    "\n",
    "TEXT_DATA_DIR =  'SingleDocSignals/'\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.33\n",
    "\n",
    "\n",
    "# second, prepare text samples and their labels\n",
    "print('Processing text dataset')\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "for fname in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    fpath = os.path.join(TEXT_DATA_DIR, fname)\n",
    "    f = open(fpath)\n",
    "    texts.append(f.read().replace(u'\\xa0', u' ').replace('Ã¢â‚¬â€', ' '))\n",
    "    f.close()\n",
    "    labels_index[basename(fname)] = len(labels_index)\n",
    "    labels.append(-1)\n",
    "        \n",
    "#load labels\n",
    "filePath='SingleDocSignals.csv'\n",
    "with open(filePath,'r') as intputFile:\n",
    "        reader=csv.reader(intputFile,delimiter=',')\n",
    "        for fname,y in reader:\n",
    "            labels[labels_index[fname+\".txt\"]]=int(y)\n",
    "print('Found %s texts.' % len(texts))\n",
    "\n",
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "# random embeddings\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,weights=None)\n",
    "print('Training model.')\n",
    "\n",
    "# train a 1D convnet with global maxpooling\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "nb_epoch=5, batch_size=50)\n",
    "\n",
    "# save embeddings\n",
    "embedding_matrix=embedding_layer.get_weights()\n",
    "gensim_first_line = \"{} {}\".format(len(word_index), EMBEDDING_DIM)\n",
    "outfile='rand.word2vec'\n",
    "with open(outfile, 'w', encoding=\"utf-8\") as fout:\n",
    "    fout.write(gensim_first_line + \"\\n\")\n",
    "    for word, i in word_index.items():\n",
    "        fout.write(word)\n",
    "        for j in range(0,EMBEDDING_DIM):\n",
    "            fout.write(' %s' % embedding_matrix[0][i][j])\n",
    "        fout.write(\"\\n\")\n",
    "#load embeddings            \n",
    "from gensim.models import Word2Vec\n",
    "embedding_model = Word2Vec.load_word2vec_format(outfile, binary=False)\n",
    "# most 10 similar words to the word 'book'\n",
    "embedding_model.most_similar_cosmul('book',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('violence', 0.665867805480957),\n",
       " (\"'throwØ¢\", 0.6421400308609009),\n",
       " ('consciously', 0.6359326839447021),\n",
       " ('feel', 0.6338539123535156),\n",
       " ('your', 0.6337871551513672),\n",
       " ('morning', 0.6304329633712769),\n",
       " ('breathed', 0.6295568346977234),\n",
       " ('actions', 0.6288840174674988),\n",
       " ('they', 0.6282011270523071),\n",
       " ('stand', 0.6273394227027893)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('man',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nightfall', 0.6332570314407349),\n",
       " ('appetite', 0.6195552349090576),\n",
       " ('crust', 0.6119269132614136),\n",
       " ('bowels', 0.6077731847763062),\n",
       " ('jewØ¢', 0.6070542335510254),\n",
       " ('ix', 0.6067355275154114),\n",
       " ('denver', 0.6042133569717407),\n",
       " ('suspects', 0.6040248870849609),\n",
       " ('marriagesØ¢', 0.6031985282897949),\n",
       " ('aides', 0.6017439365386963)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('woman',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flesh', 0.6550628542900085),\n",
       " ('Ø¢', 0.6417675614356995),\n",
       " ('byØ¢', 0.6339598298072815),\n",
       " ('ibni', 0.6297734975814819),\n",
       " ('1948', 0.6257246732711792),\n",
       " ('entirely', 0.6203641295433044),\n",
       " ('email', 0.618442952632904),\n",
       " ('glass', 0.6177000999450684),\n",
       " ('6Ø¢', 0.6164621114730835),\n",
       " ('Ã¢â‚¬Å“his', 0.6163970232009888)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('jesus',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acco', 0.6343716979026794),\n",
       " ('coca', 0.6144696474075317),\n",
       " ('negedØ¢', 0.6138964295387268),\n",
       " ('readilyØ¢', 0.610345721244812),\n",
       " ('syllable', 0.6074628233909607),\n",
       " ('severally', 0.6067753434181213),\n",
       " ('rightÃ¢â‚¬Ú¯Ø¢', 0.605021595954895),\n",
       " ('thedivision', 0.6049138903617859),\n",
       " ('neutralminds', 0.6042855381965637),\n",
       " ('theÃ¯ØŸÂ½', 0.6035443544387817)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('mohammed',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ø¢', 0.6764749884605408),\n",
       " ('next', 0.6575506329536438),\n",
       " ('back', 0.6467560529708862),\n",
       " ('anØ¢', 0.643717885017395),\n",
       " ('help', 0.6398844718933105),\n",
       " ('donÃ¢â‚¬â„¢t', 0.6339726448059082),\n",
       " ('archive', 0.6333904266357422),\n",
       " ('pinsky', 0.6330230832099915),\n",
       " ('shallØ¢', 0.632656991481781),\n",
       " ('Ã¢â‚¬Å“hijrah', 0.6311987638473511)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('moses',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"banayah'sØ¢\", 0.606346607208252),\n",
       " ('rememberedØ¢', 0.6051273345947266),\n",
       " ('lowest', 0.6040823459625244),\n",
       " ('danger', 0.6037077903747559),\n",
       " (\"on't\", 0.603002667427063),\n",
       " ('sabilul', 0.6029256582260132),\n",
       " ('cereÃ¢â€°', 0.6026865243911743),\n",
       " ('reports', 0.6023576259613037),\n",
       " ('hoped', 0.6020148992538452),\n",
       " ('sometime', 0.6003500819206238)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('he',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('babylonian', 0.6147109270095825),\n",
       " ('xavier', 0.6138967275619507),\n",
       " ('preservedØ¢', 0.6111739277839661),\n",
       " ('altered', 0.6089919805526733),\n",
       " ('indicator', 0.6057310104370117),\n",
       " ('virginityØ¢', 0.6046385765075684),\n",
       " ('1924', 0.6045945286750793),\n",
       " ('showingØ¢', 0.604421854019165),\n",
       " ('feasible', 0.603298008441925),\n",
       " ('dislikes', 0.6011598706245422)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('she',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('righteousness', 0.6688905954360962),\n",
       " ('hour', 0.6494762301445007),\n",
       " ('their', 0.64928138256073),\n",
       " ('pass', 0.6465709805488586),\n",
       " ('divines', 0.6446990966796875),\n",
       " ('empathy', 0.6414486765861511),\n",
       " ('most', 0.6389785408973694),\n",
       " ('joy', 0.6383558511734009),\n",
       " ('true', 0.636271595954895),\n",
       " ('violence', 0.6355735063552856)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('they',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ø¢', 0.6394946575164795),\n",
       " ('expressed', 0.6346575617790222),\n",
       " ('winter', 0.6327550411224365),\n",
       " ('misplaced', 0.6315436363220215),\n",
       " ('knocking', 0.6237603425979614),\n",
       " ('grabbed', 0.6199920177459717),\n",
       " ('5Ø¢', 0.6193772554397583),\n",
       " ('stars', 0.6191325783729553),\n",
       " ('venture', 0.616796612739563),\n",
       " ('pranayama', 0.6164901256561279)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar_cosmul('we',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ranked': <gensim.models.word2vec.Vocab at 0x263d1d6f98>,\n",
       " 'friendships': <gensim.models.word2vec.Vocab at 0x263ce8bba8>,\n",
       " 'borders': <gensim.models.word2vec.Vocab at 0x263bd13208>,\n",
       " 'rafidah': <gensim.models.word2vec.Vocab at 0x263cfa9320>,\n",
       " 'lettersØ¢': <gensim.models.word2vec.Vocab at 0x263cfa9390>,\n",
       " 'wearing': <gensim.models.word2vec.Vocab at 0x263cfa9588>,\n",
       " 'touchdown': <gensim.models.word2vec.Vocab at 0x263cfa9080>,\n",
       " 'achinery': <gensim.models.word2vec.Vocab at 0x263cfa9198>,\n",
       " 'genealogically': <gensim.models.word2vec.Vocab at 0x263e4ddc18>,\n",
       " \"'anger\": <gensim.models.word2vec.Vocab at 0x263cfa94e0>,\n",
       " 'bitul': <gensim.models.word2vec.Vocab at 0x263cfa95c0>,\n",
       " 'inertness': <gensim.models.word2vec.Vocab at 0x263cfa9128>,\n",
       " 'synagogues': <gensim.models.word2vec.Vocab at 0x263cfa99e8>,\n",
       " 'el': <gensim.models.word2vec.Vocab at 0x263cfa9518>,\n",
       " 'separate': <gensim.models.word2vec.Vocab at 0x263cfa9a58>,\n",
       " 'eyeØ­Â¾Ø¢': <gensim.models.word2vec.Vocab at 0x267027ea20>,\n",
       " \"'everyØ¢\": <gensim.models.word2vec.Vocab at 0x263cfa9400>,\n",
       " 'jefferson': <gensim.models.word2vec.Vocab at 0x263e589e48>,\n",
       " 'neverthelessØ¢': <gensim.models.word2vec.Vocab at 0x263e5ca208>,\n",
       " 'commendable': <gensim.models.word2vec.Vocab at 0x263cfa9a20>,\n",
       " 'desertØ¢': <gensim.models.word2vec.Vocab at 0x263e776588>,\n",
       " 'hauling': <gensim.models.word2vec.Vocab at 0x263cfa9be0>,\n",
       " 'forthrightly': <gensim.models.word2vec.Vocab at 0x263e735b70>,\n",
       " 'benÃ¢â‚¬Ú¯ammi': <gensim.models.word2vec.Vocab at 0x263cfa9d68>,\n",
       " 'pruned': <gensim.models.word2vec.Vocab at 0x263cfa9d30>,\n",
       " 'alabama': <gensim.models.word2vec.Vocab at 0x263cfaa198>,\n",
       " 'almighty': <gensim.models.word2vec.Vocab at 0x263cfa9f28>,\n",
       " 'instancesØ¢': <gensim.models.word2vec.Vocab at 0x263cfa9e10>,\n",
       " 'antiquity': <gensim.models.word2vec.Vocab at 0x26701e1630>,\n",
       " 'hasakah': <gensim.models.word2vec.Vocab at 0x263cfaa0b8>,\n",
       " 'disperse': <gensim.models.word2vec.Vocab at 0x26701f2f28>,\n",
       " 'assuredØ¢': <gensim.models.word2vec.Vocab at 0x263cfaa2b0>,\n",
       " 'comprehendedØ¢': <gensim.models.word2vec.Vocab at 0x263cfaa5c0>,\n",
       " 'rishis': <gensim.models.word2vec.Vocab at 0x263e5ca668>,\n",
       " 'outnumbers': <gensim.models.word2vec.Vocab at 0x263cfaa2e8>,\n",
       " 'adamatif': <gensim.models.word2vec.Vocab at 0x263cfaa588>,\n",
       " 'dayØ¢': <gensim.models.word2vec.Vocab at 0x263cfaa278>,\n",
       " '315Ø¢': <gensim.models.word2vec.Vocab at 0x263cfaa240>,\n",
       " 'weekØ¢': <gensim.models.word2vec.Vocab at 0x263e9bbf98>,\n",
       " 'sisters': <gensim.models.word2vec.Vocab at 0x263cfaa358>,\n",
       " 'tremendously': <gensim.models.word2vec.Vocab at 0x263cfaa4a8>,\n",
       " 'vindication': <gensim.models.word2vec.Vocab at 0x263cfaa6a0>,\n",
       " 'tiger': <gensim.models.word2vec.Vocab at 0x26700d5f28>,\n",
       " 'assuredly': <gensim.models.word2vec.Vocab at 0x263cfaa7b8>,\n",
       " 'slavemaster': <gensim.models.word2vec.Vocab at 0x2670330898>,\n",
       " 'ingØ¢': <gensim.models.word2vec.Vocab at 0x263cfd2320>,\n",
       " 'impliedØ¢': <gensim.models.word2vec.Vocab at 0x263cfaa5f8>,\n",
       " 'sourcesØ¢': <gensim.models.word2vec.Vocab at 0x26701af438>,\n",
       " 'luther': <gensim.models.word2vec.Vocab at 0x263cfaa6d8>,\n",
       " 'thighÃ¢â‚¬Ú¯bone': <gensim.models.word2vec.Vocab at 0x26702177f0>,\n",
       " '7a': <gensim.models.word2vec.Vocab at 0x263cfaaa20>,\n",
       " 'formalitiesØ¢': <gensim.models.word2vec.Vocab at 0x2670186400>,\n",
       " 'backs': <gensim.models.word2vec.Vocab at 0x263cfaaa58>,\n",
       " 'underrate': <gensim.models.word2vec.Vocab at 0x263cfaacf8>,\n",
       " 'pondÃ¢â‚¬\\u200c': <gensim.models.word2vec.Vocab at 0x263cfaab00>,\n",
       " 'collapse': <gensim.models.word2vec.Vocab at 0x263cfaae10>,\n",
       " 'piercingØ¢': <gensim.models.word2vec.Vocab at 0x263cfaaac8>,\n",
       " 'Ã¢â‚¬Å“harvestÃ¢â‚¬\\u200c': <gensim.models.word2vec.Vocab at 0x263cfaac88>,\n",
       " 'messianicØ¢': <gensim.models.word2vec.Vocab at 0x263cfaae80>,\n",
       " 'deepens': <gensim.models.word2vec.Vocab at 0x263cfaadd8>,\n",
       " 'corØ¢\\xad': <gensim.models.word2vec.Vocab at 0x263cfaac50>,\n",
       " 'motto': <gensim.models.word2vec.Vocab at 0x263cfaaef0>,\n",
       " 'maintainingØ¢': <gensim.models.word2vec.Vocab at 0x263cfaaeb8>,\n",
       " 'biblebased': <gensim.models.word2vec.Vocab at 0x263cfaada0>,\n",
       " \"meÃ¢â‚¬Ú¯'olam\": <gensim.models.word2vec.Vocab at 0x267030e898>,\n",
       " 'blondest': <gensim.models.word2vec.Vocab at 0x263cfaaf28>,\n",
       " 'makest': <gensim.models.word2vec.Vocab at 0x263cf705f8>,\n",
       " 'interest': <gensim.models.word2vec.Vocab at 0x263cfaaf98>,\n",
       " '108aØ¢': <gensim.models.word2vec.Vocab at 0x263cf62358>,\n",
       " 'strangers': <gensim.models.word2vec.Vocab at 0x263cf62860>,\n",
       " 'stalled': <gensim.models.word2vec.Vocab at 0x263cf0d390>,\n",
       " '117Ø¢': <gensim.models.word2vec.Vocab at 0x263cf59128>,\n",
       " 'kingØ¢': <gensim.models.word2vec.Vocab at 0x263cf55f98>,\n",
       " 'renounce': <gensim.models.word2vec.Vocab at 0x263cf59a58>,\n",
       " 'diagrams': <gensim.models.word2vec.Vocab at 0x263cf59ef0>,\n",
       " 'orthodoxy': <gensim.models.word2vec.Vocab at 0x263e647ac8>,\n",
       " 'writers': <gensim.models.word2vec.Vocab at 0x263cf63160>,\n",
       " 'kØ¤Ù¾na': <gensim.models.word2vec.Vocab at 0x263d01e550>,\n",
       " 'perceiving': <gensim.models.word2vec.Vocab at 0x263cf55860>,\n",
       " 'overlookØ¢': <gensim.models.word2vec.Vocab at 0x263ea84b38>,\n",
       " 'directs': <gensim.models.word2vec.Vocab at 0x26701af668>,\n",
       " '488': <gensim.models.word2vec.Vocab at 0x263cf46198>,\n",
       " '60': <gensim.models.word2vec.Vocab at 0x263cf494e0>,\n",
       " 'witherÃ¢â‚¬Â¦if': <gensim.models.word2vec.Vocab at 0x263cf49b00>,\n",
       " 'cannonball': <gensim.models.word2vec.Vocab at 0x263d0a26d8>,\n",
       " 'pursuit': <gensim.models.word2vec.Vocab at 0x263d0a2908>,\n",
       " 'Ã¢â‚¬Å“awakening': <gensim.models.word2vec.Vocab at 0x263d0a2828>,\n",
       " 'seizedØ¢': <gensim.models.word2vec.Vocab at 0x263eab2438>,\n",
       " '135': <gensim.models.word2vec.Vocab at 0x263d0a2e10>,\n",
       " '232Ø¢': <gensim.models.word2vec.Vocab at 0x26702dc908>,\n",
       " 'terrestialØ¢': <gensim.models.word2vec.Vocab at 0x263cf407f0>,\n",
       " 'literallyâ€“only': <gensim.models.word2vec.Vocab at 0x263d0a2b00>,\n",
       " 'alÃ¢â‚¬Ú¯tashheth': <gensim.models.word2vec.Vocab at 0x263d0a2518>,\n",
       " 'usion': <gensim.models.word2vec.Vocab at 0x26702f5320>,\n",
       " 'iÃ¢â‚¬â„¢ve': <gensim.models.word2vec.Vocab at 0x263cf40048>,\n",
       " 'pourethØ¢': <gensim.models.word2vec.Vocab at 0x267028d400>,\n",
       " 'jalaluddin': <gensim.models.word2vec.Vocab at 0x263d0a2fd0>,\n",
       " 'rodriguez': <gensim.models.word2vec.Vocab at 0x263cfa4978>,\n",
       " 'partially': <gensim.models.word2vec.Vocab at 0x263cfa4a90>,\n",
       " 'endØ¢': <gensim.models.word2vec.Vocab at 0x263cfa4a58>,\n",
       " 'roth': <gensim.models.word2vec.Vocab at 0x263cfa4908>,\n",
       " 'sangam': <gensim.models.word2vec.Vocab at 0x263cfa4e48>,\n",
       " 'preface': <gensim.models.word2vec.Vocab at 0x2670281080>,\n",
       " '549': <gensim.models.word2vec.Vocab at 0x263cfa4f98>,\n",
       " 'obje': <gensim.models.word2vec.Vocab at 0x2670214f60>,\n",
       " '81': <gensim.models.word2vec.Vocab at 0x263cfa4ba8>,\n",
       " 'beraØ¢': <gensim.models.word2vec.Vocab at 0x263cfa4eb8>,\n",
       " 'meron': <gensim.models.word2vec.Vocab at 0x263cfa4048>,\n",
       " 'row': <gensim.models.word2vec.Vocab at 0x263cfa4080>,\n",
       " 'multiply': <gensim.models.word2vec.Vocab at 0x263cfa4518>,\n",
       " 'eliØ¢': <gensim.models.word2vec.Vocab at 0x26702d3dd8>,\n",
       " 'aks': <gensim.models.word2vec.Vocab at 0x263cfa41d0>,\n",
       " 'discretionØ¢': <gensim.models.word2vec.Vocab at 0x263cfa4320>,\n",
       " 'revoltedØ¢': <gensim.models.word2vec.Vocab at 0x263cfa46d8>,\n",
       " 'phicolØ¢': <gensim.models.word2vec.Vocab at 0x263cfa4550>,\n",
       " 'hidØ¤Â«n': <gensim.models.word2vec.Vocab at 0x263cfa4588>,\n",
       " 'sahih': <gensim.models.word2vec.Vocab at 0x2666929198>,\n",
       " '85b': <gensim.models.word2vec.Vocab at 0x263d09a940>,\n",
       " 'tarantum': <gensim.models.word2vec.Vocab at 0x263cfa4160>,\n",
       " 'departure': <gensim.models.word2vec.Vocab at 0x26700de160>,\n",
       " 'underneath': <gensim.models.word2vec.Vocab at 0x263cfa40b8>,\n",
       " 'recognizeth': <gensim.models.word2vec.Vocab at 0x263cfd2978>,\n",
       " 'undergone': <gensim.models.word2vec.Vocab at 0x26701af908>,\n",
       " 'vimeo': <gensim.models.word2vec.Vocab at 0x263d0191d0>,\n",
       " 'Ã¢â‚¬Ú©and': <gensim.models.word2vec.Vocab at 0x263cfa4780>,\n",
       " 'fragment': <gensim.models.word2vec.Vocab at 0x263d019320>,\n",
       " 'gamhiri': <gensim.models.word2vec.Vocab at 0x263d019160>,\n",
       " 'analysis': <gensim.models.word2vec.Vocab at 0x263d0192e8>,\n",
       " 'citta': <gensim.models.word2vec.Vocab at 0x263d019358>,\n",
       " 'shokenehemØ¢': <gensim.models.word2vec.Vocab at 0x263d019668>,\n",
       " 'award': <gensim.models.word2vec.Vocab at 0x263e776be0>,\n",
       " 'ning': <gensim.models.word2vec.Vocab at 0x263d019438>,\n",
       " 'nineØ¢': <gensim.models.word2vec.Vocab at 0x263d019550>,\n",
       " 'exhorting': <gensim.models.word2vec.Vocab at 0x263d019898>,\n",
       " 'thursday': <gensim.models.word2vec.Vocab at 0x263d0192b0>,\n",
       " 'singing': <gensim.models.word2vec.Vocab at 0x263d019630>,\n",
       " 'Ã¢â‚¬Å“product': <gensim.models.word2vec.Vocab at 0x263eae8908>,\n",
       " 'cyrene': <gensim.models.word2vec.Vocab at 0x263d019748>,\n",
       " 'datesØ¢': <gensim.models.word2vec.Vocab at 0x263d019940>,\n",
       " 'menting': <gensim.models.word2vec.Vocab at 0x263d019860>,\n",
       " 'thread': <gensim.models.word2vec.Vocab at 0x263cfd2b00>,\n",
       " 'pe': <gensim.models.word2vec.Vocab at 0x263d019b38>,\n",
       " 'ookings': <gensim.models.word2vec.Vocab at 0x263d0b9898>,\n",
       " 'manureØ¢': <gensim.models.word2vec.Vocab at 0x263d0198d0>,\n",
       " 'achieved': <gensim.models.word2vec.Vocab at 0x263d019ac8>,\n",
       " 'induce': <gensim.models.word2vec.Vocab at 0x263d019a90>,\n",
       " 'arbor': <gensim.models.word2vec.Vocab at 0x263d019c88>,\n",
       " 'afarØ¢': <gensim.models.word2vec.Vocab at 0x263e776c88>,\n",
       " '129': <gensim.models.word2vec.Vocab at 0x263d019e10>,\n",
       " 'brotherhoodØ¢': <gensim.models.word2vec.Vocab at 0x263cfd2b70>,\n",
       " 'afflictedØ¢': <gensim.models.word2vec.Vocab at 0x26701af9e8>,\n",
       " 'aspirin': <gensim.models.word2vec.Vocab at 0x263d019d30>,\n",
       " 'acceptability': <gensim.models.word2vec.Vocab at 0x263d019da0>,\n",
       " 'waw': <gensim.models.word2vec.Vocab at 0x263d019400>,\n",
       " 'henua': <gensim.models.word2vec.Vocab at 0x263d019f98>,\n",
       " 'confinement': <gensim.models.word2vec.Vocab at 0x263d011a90>,\n",
       " 'mysticalØ¢': <gensim.models.word2vec.Vocab at 0x263d019f60>,\n",
       " 'coun': <gensim.models.word2vec.Vocab at 0x263d019f28>,\n",
       " 'netherÃ¢â‚¬Ú¯worldØ¢': <gensim.models.word2vec.Vocab at 0x263d019048>,\n",
       " 'contributions': <gensim.models.word2vec.Vocab at 0x263d019080>,\n",
       " 'santu': <gensim.models.word2vec.Vocab at 0x263cf9b9e8>,\n",
       " 'jewishness': <gensim.models.word2vec.Vocab at 0x263cf9be10>,\n",
       " 'familyÃ¢â‚¬â„¢s': <gensim.models.word2vec.Vocab at 0x2670314a20>,\n",
       " 'illicit': <gensim.models.word2vec.Vocab at 0x263cf9bc50>,\n",
       " 'gods': <gensim.models.word2vec.Vocab at 0x263cf9bc18>,\n",
       " 'centralized': <gensim.models.word2vec.Vocab at 0x263e504b70>,\n",
       " 'flag': <gensim.models.word2vec.Vocab at 0x263cf9bd68>,\n",
       " 'benefitsâ€”': <gensim.models.word2vec.Vocab at 0x263cf9be48>,\n",
       " 'persistedØ¢': <gensim.models.word2vec.Vocab at 0x263cf9b080>,\n",
       " 'fulfilment': <gensim.models.word2vec.Vocab at 0x263cf9b240>,\n",
       " 'reply': <gensim.models.word2vec.Vocab at 0x263cf9b198>,\n",
       " 'luxuriously': <gensim.models.word2vec.Vocab at 0x263cf9b128>,\n",
       " 'manØ¢': <gensim.models.word2vec.Vocab at 0x263cf9b0b8>,\n",
       " 'acked': <gensim.models.word2vec.Vocab at 0x263cf9b208>,\n",
       " 'hammad': <gensim.models.word2vec.Vocab at 0x263cf9b2b0>,\n",
       " 'sanctified': <gensim.models.word2vec.Vocab at 0x263cf9b358>,\n",
       " 'televangelists': <gensim.models.word2vec.Vocab at 0x263cf9b4e0>,\n",
       " 'becomesØ¢': <gensim.models.word2vec.Vocab at 0x263cf9b3c8>,\n",
       " 'prosy': <gensim.models.word2vec.Vocab at 0x263cf9b588>,\n",
       " 'captains': <gensim.models.word2vec.Vocab at 0x26701afb38>,\n",
       " 'trustØ¢': <gensim.models.word2vec.Vocab at 0x263cf9b6a0>,\n",
       " 'love': <gensim.models.word2vec.Vocab at 0x263cf9b5f8>,\n",
       " '1s': <gensim.models.word2vec.Vocab at 0x263cf9b400>,\n",
       " 'uja': <gensim.models.word2vec.Vocab at 0x263cf9b710>,\n",
       " 'forrepeating': <gensim.models.word2vec.Vocab at 0x263cf9b748>,\n",
       " 'feel': <gensim.models.word2vec.Vocab at 0x263e9df668>,\n",
       " 'riverÃ¢â‚¬Ú¯Ø¢': <gensim.models.word2vec.Vocab at 0x263cf9b668>,\n",
       " 'dalet': <gensim.models.word2vec.Vocab at 0x263cf9b780>,\n",
       " 'thatâ„¢s': <gensim.models.word2vec.Vocab at 0x263d01a278>,\n",
       " 'doctrines': <gensim.models.word2vec.Vocab at 0x263d01a160>,\n",
       " 'toes': <gensim.models.word2vec.Vocab at 0x263d01a198>,\n",
       " 'abund': <gensim.models.word2vec.Vocab at 0x263d01a358>,\n",
       " 'bodies': <gensim.models.word2vec.Vocab at 0x263d01a400>,\n",
       " 'ruptured': <gensim.models.word2vec.Vocab at 0x263d01a2e8>,\n",
       " 'kindergarten': <gensim.models.word2vec.Vocab at 0x263d01a0f0>,\n",
       " 'firstborn': <gensim.models.word2vec.Vocab at 0x263d01a470>,\n",
       " 'administrative': <gensim.models.word2vec.Vocab at 0x263d01a3c8>,\n",
       " 'c': <gensim.models.word2vec.Vocab at 0x263d01a2b0>,\n",
       " 'amazes': <gensim.models.word2vec.Vocab at 0x263d01a668>,\n",
       " 'mayim': <gensim.models.word2vec.Vocab at 0x263d01a748>,\n",
       " 'port': <gensim.models.word2vec.Vocab at 0x263d01a710>,\n",
       " 'refusingØ¢': <gensim.models.word2vec.Vocab at 0x263d01a7f0>,\n",
       " 'Ã¢â‚¬Å“piked': <gensim.models.word2vec.Vocab at 0x2670224208>,\n",
       " 'appreciateØ¢': <gensim.models.word2vec.Vocab at 0x2670156b70>,\n",
       " 'inducted': <gensim.models.word2vec.Vocab at 0x267031bda0>,\n",
       " 'constructed': <gensim.models.word2vec.Vocab at 0x263d01a6d8>,\n",
       " 'championing': <gensim.models.word2vec.Vocab at 0x263d01a630>,\n",
       " 'sermonsØ¢': <gensim.models.word2vec.Vocab at 0x263d01a908>,\n",
       " 'impose': <gensim.models.word2vec.Vocab at 0x263d01a9e8>,\n",
       " 'chicanery': <gensim.models.word2vec.Vocab at 0x263d01a9b0>,\n",
       " 'life': <gensim.models.word2vec.Vocab at 0x263d01ac88>,\n",
       " 'satchidanandaÃ¢â‚¬â„¢s': <gensim.models.word2vec.Vocab at 0x263d01aa58>,\n",
       " 'loom': <gensim.models.word2vec.Vocab at 0x267035a710>,\n",
       " 'jabbØ¤Ù¾r': <gensim.models.word2vec.Vocab at 0x263cfdeb70>,\n",
       " 'delightsØ¢': <gensim.models.word2vec.Vocab at 0x263d01ae10>,\n",
       " 'ali': <gensim.models.word2vec.Vocab at 0x263d01a588>,\n",
       " 'gap': <gensim.models.word2vec.Vocab at 0x263d01aef0>,\n",
       " 'wallsØ¢': <gensim.models.word2vec.Vocab at 0x263d01ad30>,\n",
       " 'forgave': <gensim.models.word2vec.Vocab at 0x263d01acf8>,\n",
       " 'mushrik': <gensim.models.word2vec.Vocab at 0x263cf1e358>,\n",
       " 'gallons': <gensim.models.word2vec.Vocab at 0x263cf378d0>,\n",
       " 'advanced': <gensim.models.word2vec.Vocab at 0x263cec2c50>,\n",
       " 'playedØ¢': <gensim.models.word2vec.Vocab at 0x263cec02e8>,\n",
       " 'claspsØ¢': <gensim.models.word2vec.Vocab at 0x263cf1e978>,\n",
       " 'jericho': <gensim.models.word2vec.Vocab at 0x263ceda6d8>,\n",
       " 'trampling': <gensim.models.word2vec.Vocab at 0x263e79a5f8>,\n",
       " 'waken': <gensim.models.word2vec.Vocab at 0x263cf5d198>,\n",
       " 'engulf': <gensim.models.word2vec.Vocab at 0x263cf5de10>,\n",
       " 'ies': <gensim.models.word2vec.Vocab at 0x263d021438>,\n",
       " 'smearing': <gensim.models.word2vec.Vocab at 0x2670234940>,\n",
       " 'nnnØ¢': <gensim.models.word2vec.Vocab at 0x263d0215f8>,\n",
       " 'actuall': <gensim.models.word2vec.Vocab at 0x263d021588>,\n",
       " 'Ø¢Â»': <gensim.models.word2vec.Vocab at 0x263d0214e0>,\n",
       " 'uselessØ¢': <gensim.models.word2vec.Vocab at 0x263d021550>,\n",
       " 'enjoyedØ¢': <gensim.models.word2vec.Vocab at 0x263d0215c0>,\n",
       " 'kingdomØ¢': <gensim.models.word2vec.Vocab at 0x263d021470>,\n",
       " 'condemning': <gensim.models.word2vec.Vocab at 0x263d021940>,\n",
       " 'shew': <gensim.models.word2vec.Vocab at 0x263d0217b8>,\n",
       " 'shortage': <gensim.models.word2vec.Vocab at 0x263d021748>,\n",
       " 'discharging': <gensim.models.word2vec.Vocab at 0x263d021898>,\n",
       " 'platonic': <gensim.models.word2vec.Vocab at 0x263d0218d0>,\n",
       " 'stalin': <gensim.models.word2vec.Vocab at 0x263d0216a0>,\n",
       " 'tribulations': <gensim.models.word2vec.Vocab at 0x263d021978>,\n",
       " 'ethnic': <gensim.models.word2vec.Vocab at 0x263d021b70>,\n",
       " 'possesÃ¢â€°': <gensim.models.word2vec.Vocab at 0x263d021c50>,\n",
       " 'assessments': <gensim.models.word2vec.Vocab at 0x263d021a58>,\n",
       " 'endangering': <gensim.models.word2vec.Vocab at 0x263d021b00>,\n",
       " 'mhoØ¢': <gensim.models.word2vec.Vocab at 0x263d0219b0>,\n",
       " 'philemon': <gensim.models.word2vec.Vocab at 0x263d021cf8>,\n",
       " 'primarily': <gensim.models.word2vec.Vocab at 0x263d021d30>,\n",
       " 'scattering': <gensim.models.word2vec.Vocab at 0x263d021ac8>,\n",
       " 'anita': <gensim.models.word2vec.Vocab at 0x263d0ac748>,\n",
       " 'Ø¢Â»Ø¢': <gensim.models.word2vec.Vocab at 0x2670275198>,\n",
       " '491': <gensim.models.word2vec.Vocab at 0x263d021a20>,\n",
       " 'â€œteresa': <gensim.models.word2vec.Vocab at 0x263d021a90>,\n",
       " 'cized': <gensim.models.word2vec.Vocab at 0x26702e2860>,\n",
       " 'colm': <gensim.models.word2vec.Vocab at 0x263d021eb8>,\n",
       " 'unworthy': <gensim.models.word2vec.Vocab at 0x263d021dd8>,\n",
       " 'uniqueness': <gensim.models.word2vec.Vocab at 0x263d021da0>,\n",
       " 'insignificance': <gensim.models.word2vec.Vocab at 0x263e7964a8>,\n",
       " 'Ã¢â‚¬Å“healthÃ¢â‚¬\\u200c': <gensim.models.word2vec.Vocab at 0x263d021f98>,\n",
       " 'rebelled': <gensim.models.word2vec.Vocab at 0x263d0212e8>,\n",
       " 'lÃ¢â‚¬â„¢kha': <gensim.models.word2vec.Vocab at 0x263d021f28>,\n",
       " 'missionary': <gensim.models.word2vec.Vocab at 0x263d021e10>,\n",
       " 'keturahØ¢': <gensim.models.word2vec.Vocab at 0x26701f5550>,\n",
       " 'existence': <gensim.models.word2vec.Vocab at 0x263d0210b8>,\n",
       " 'eclipsesØ¢': <gensim.models.word2vec.Vocab at 0x263d021f60>,\n",
       " 'saying': <gensim.models.word2vec.Vocab at 0x263d0210f0>,\n",
       " 'hemingways': <gensim.models.word2vec.Vocab at 0x263d021fd0>,\n",
       " 'cheerfully': <gensim.models.word2vec.Vocab at 0x263d021048>,\n",
       " 'hijack': <gensim.models.word2vec.Vocab at 0x263d021240>,\n",
       " 'sukkotØ¢': <gensim.models.word2vec.Vocab at 0x263d021198>,\n",
       " 'concubineØ¢': <gensim.models.word2vec.Vocab at 0x263e778390>,\n",
       " 'meshach': <gensim.models.word2vec.Vocab at 0x263cf65ba8>,\n",
       " 'houseØ¢': <gensim.models.word2vec.Vocab at 0x26701affd0>,\n",
       " 'ural': <gensim.models.word2vec.Vocab at 0x263ceb6c18>,\n",
       " 'clauses': <gensim.models.word2vec.Vocab at 0x263ceb79b0>,\n",
       " 'escortØ¢': <gensim.models.word2vec.Vocab at 0x263cf12c18>,\n",
       " 'insult': <gensim.models.word2vec.Vocab at 0x266fdcf4a8>,\n",
       " 'diminution': <gensim.models.word2vec.Vocab at 0x263cf574e0>,\n",
       " 'bethØ¢': <gensim.models.word2vec.Vocab at 0x266fdcf710>,\n",
       " 'hananelØ¢': <gensim.models.word2vec.Vocab at 0x263cf64b38>,\n",
       " 'solutely': <gensim.models.word2vec.Vocab at 0x263cf64a58>,\n",
       " 'clusion': <gensim.models.word2vec.Vocab at 0x2670116da0>,\n",
       " 'raise': <gensim.models.word2vec.Vocab at 0x263cf64518>,\n",
       " 'ruptures': <gensim.models.word2vec.Vocab at 0x263cf2cb00>,\n",
       " 'editor': <gensim.models.word2vec.Vocab at 0x26701b20f0>,\n",
       " 'pakistan': <gensim.models.word2vec.Vocab at 0x263cf2c828>,\n",
       " 'pregnant': <gensim.models.word2vec.Vocab at 0x263cf64e80>,\n",
       " 'consolidating': <gensim.models.word2vec.Vocab at 0x263cf2f908>,\n",
       " 'grit': <gensim.models.word2vec.Vocab at 0x263cf2ffd0>,\n",
       " 'ambiguity': <gensim.models.word2vec.Vocab at 0x263cf5f0f0>,\n",
       " 'siddiqui': <gensim.models.word2vec.Vocab at 0x263cf64d30>,\n",
       " 'unitarians': <gensim.models.word2vec.Vocab at 0x263d060898>,\n",
       " 'vav': <gensim.models.word2vec.Vocab at 0x263cf5f198>,\n",
       " 'indignation': <gensim.models.word2vec.Vocab at 0x266fdc3048>,\n",
       " '114a': <gensim.models.word2vec.Vocab at 0x263cfce6a0>,\n",
       " 'berevealed': <gensim.models.word2vec.Vocab at 0x263cf985f8>,\n",
       " 'Ã¢â‚¬Å“homicideÃ¢â‚¬\\u200c': <gensim.models.word2vec.Vocab at 0x263cfceda0>,\n",
       " 'mullas': <gensim.models.word2vec.Vocab at 0x263cf9e7b8>,\n",
       " 'conversionâ€': <gensim.models.word2vec.Vocab at 0x263cf9e8d0>,\n",
       " 'jfna': <gensim.models.word2vec.Vocab at 0x263cf9ecc0>,\n",
       " 'yond': <gensim.models.word2vec.Vocab at 0x263bda8a58>,\n",
       " 'frowning': <gensim.models.word2vec.Vocab at 0x263d0719e8>,\n",
       " 'Ã¢â‚¬Å“sweet': <gensim.models.word2vec.Vocab at 0x263cf9ecf8>,\n",
       " 'million': <gensim.models.word2vec.Vocab at 0x263d071630>,\n",
       " 'envelope': <gensim.models.word2vec.Vocab at 0x263e99ce48>,\n",
       " 'searcheth': <gensim.models.word2vec.Vocab at 0x263d071208>,\n",
       " 'ins': <gensim.models.word2vec.Vocab at 0x263d071160>,\n",
       " 'abort': <gensim.models.word2vec.Vocab at 0x263d071898>,\n",
       " 'patientsÃ¢â‚¬\\u200c': <gensim.models.word2vec.Vocab at 0x263d071518>,\n",
       " 'illustratedØ¢': <gensim.models.word2vec.Vocab at 0x263d071320>,\n",
       " 'Ã¢â‚¬Å“laterÃ¢â‚¬\\u200c': <gensim.models.word2vec.Vocab at 0x26668ddba8>,\n",
       " 'zabdiØ¢': <gensim.models.word2vec.Vocab at 0x263d071390>,\n",
       " 'soulsØ¢': <gensim.models.word2vec.Vocab at 0x26700f7908>,\n",
       " 'cohabitationØ¢': <gensim.models.word2vec.Vocab at 0x263d071d30>,\n",
       " 'president': <gensim.models.word2vec.Vocab at 0x263d071c50>,\n",
       " 'inning': <gensim.models.word2vec.Vocab at 0x263d07e358>,\n",
       " 'australia': <gensim.models.word2vec.Vocab at 0x26716a54e0>,\n",
       " 'furrowsØ¢': <gensim.models.word2vec.Vocab at 0x263d07e470>,\n",
       " 'libi': <gensim.models.word2vec.Vocab at 0x263d07e198>,\n",
       " 'worshippedØ¢': <gensim.models.word2vec.Vocab at 0x263d07e7f0>,\n",
       " 'wildernessÃ¢â‚¬\\u200c': <gensim.models.word2vec.Vocab at 0x263d07e1d0>,\n",
       " 'predictions': <gensim.models.word2vec.Vocab at 0x263d07e400>,\n",
       " 'awaits': <gensim.models.word2vec.Vocab at 0x263d07eb38>,\n",
       " 'unidentified': <gensim.models.word2vec.Vocab at 0x263e9a48d0>,\n",
       " 'inbox': <gensim.models.word2vec.Vocab at 0x263d07ecf8>,\n",
       " 'Ã¢â‚¬Å“preserving': <gensim.models.word2vec.Vocab at 0x2670337f60>,\n",
       " 'sheâ„¢ll': <gensim.models.word2vec.Vocab at 0x263d060a90>,\n",
       " 'tenthØ¢': <gensim.models.word2vec.Vocab at 0x263d07eda0>,\n",
       " 'crafts': <gensim.models.word2vec.Vocab at 0x26701b2358>,\n",
       " 'selvesØ¢': <gensim.models.word2vec.Vocab at 0x26701f2a58>,\n",
       " 'brief': <gensim.models.word2vec.Vocab at 0x263e95e2e8>,\n",
       " 'animates': <gensim.models.word2vec.Vocab at 0x263d0b3780>,\n",
       " 'parlance': <gensim.models.word2vec.Vocab at 0x266693f358>,\n",
       " 'zedek': <gensim.models.word2vec.Vocab at 0x263d086ac8>,\n",
       " '12Ã¢â‚¬Ú¯14Ø¢': <gensim.models.word2vec.Vocab at 0x263d086860>,\n",
       " 'overt': <gensim.models.word2vec.Vocab at 0x263d086a20>,\n",
       " 'myrrh': <gensim.models.word2vec.Vocab at 0x263d086358>,\n",
       " 'eared': <gensim.models.word2vec.Vocab at 0x263d086b70>,\n",
       " 'besought': <gensim.models.word2vec.Vocab at 0x263d0864a8>,\n",
       " 'ripenØ¢': <gensim.models.word2vec.Vocab at 0x263d086eb8>,\n",
       " 'representaØ¢\\xad': <gensim.models.word2vec.Vocab at 0x263d086e48>,\n",
       " 'anyway': <gensim.models.word2vec.Vocab at 0x263d086d30>,\n",
       " 'inspires': <gensim.models.word2vec.Vocab at 0x263e778668>,\n",
       " 'jew': <gensim.models.word2vec.Vocab at 0x263d0d00b8>,\n",
       " \"repelled'Ø¢\": <gensim.models.word2vec.Vocab at 0x263d0d0f28>,\n",
       " \"tree'Ø¢\": <gensim.models.word2vec.Vocab at 0x263d0d0080>,\n",
       " 'segment': <gensim.models.word2vec.Vocab at 0x263d0d0b70>,\n",
       " 'clarifies': <gensim.models.word2vec.Vocab at 0x263d0d0ef0>,\n",
       " 'portable': <gensim.models.word2vec.Vocab at 0x263d0d0320>,\n",
       " 'christ': <gensim.models.word2vec.Vocab at 0x263d0d0a90>,\n",
       " \"messiah'sØ¢\": <gensim.models.word2vec.Vocab at 0x263d0d0198>,\n",
       " 'consideringØ¢': <gensim.models.word2vec.Vocab at 0x263cf11e80>,\n",
       " 'restraints': <gensim.models.word2vec.Vocab at 0x263d0d03c8>,\n",
       " 'clarkÃ¢â‚¬â„¢s': <gensim.models.word2vec.Vocab at 0x263d0d0358>,\n",
       " 'deserts': <gensim.models.word2vec.Vocab at 0x263d0d0630>,\n",
       " 'analytics': <gensim.models.word2vec.Vocab at 0x263d0d02e8>,\n",
       " 'indignant': <gensim.models.word2vec.Vocab at 0x263d0d0470>,\n",
       " 'foiled': <gensim.models.word2vec.Vocab at 0x263d0d01d0>,\n",
       " 'exacerbated': <gensim.models.word2vec.Vocab at 0x263d0d04e0>,\n",
       " '177': <gensim.models.word2vec.Vocab at 0x267034dd68>,\n",
       " 'luis': <gensim.models.word2vec.Vocab at 0x263d0d0550>,\n",
       " 'thankingØ¢': <gensim.models.word2vec.Vocab at 0x263d0d0780>,\n",
       " 'begin': <gensim.models.word2vec.Vocab at 0x263d0d05f8>,\n",
       " 'weddings': <gensim.models.word2vec.Vocab at 0x26716a55c0>,\n",
       " 'visaged': <gensim.models.word2vec.Vocab at 0x263d0d0668>,\n",
       " 'meir': <gensim.models.word2vec.Vocab at 0x263d0d07b8>,\n",
       " 'dying': <gensim.models.word2vec.Vocab at 0x263d0d0710>,\n",
       " 'torporØ¢': <gensim.models.word2vec.Vocab at 0x263d0d0748>,\n",
       " 'numericalØ¢': <gensim.models.word2vec.Vocab at 0x263d0d08d0>,\n",
       " 'talmud': <gensim.models.word2vec.Vocab at 0x263d0d0898>,\n",
       " 'immune': <gensim.models.word2vec.Vocab at 0x263d0d0860>,\n",
       " 'postures': <gensim.models.word2vec.Vocab at 0x263eab5128>,\n",
       " 'hikrib': <gensim.models.word2vec.Vocab at 0x263d0d0c50>,\n",
       " '9Ã¢â‚¬Ú¯ioØ¢': <gensim.models.word2vec.Vocab at 0x263d0d0a20>,\n",
       " 'exonerated': <gensim.models.word2vec.Vocab at 0x2670123198>,\n",
       " 'appertures': <gensim.models.word2vec.Vocab at 0x263d0d0b00>,\n",
       " 'expectations': <gensim.models.word2vec.Vocab at 0x263d0d0d30>,\n",
       " '113Ø¢': <gensim.models.word2vec.Vocab at 0x263d0d0ac8>,\n",
       " 'any': <gensim.models.word2vec.Vocab at 0x263e772320>,\n",
       " 'fisher': <gensim.models.word2vec.Vocab at 0x263d0bac88>,\n",
       " 'givesinstructions': <gensim.models.word2vec.Vocab at 0x263cfa12e8>,\n",
       " 'ilaiØ¢': <gensim.models.word2vec.Vocab at 0x263cfa1240>,\n",
       " 'smaragd': <gensim.models.word2vec.Vocab at 0x263d060ba8>,\n",
       " \"'orlatho\": <gensim.models.word2vec.Vocab at 0x267028b940>,\n",
       " 'wholly': <gensim.models.word2vec.Vocab at 0x263cfa1630>,\n",
       " 'scientific': <gensim.models.word2vec.Vocab at 0x263e5cd898>,\n",
       " 'ercy': <gensim.models.word2vec.Vocab at 0x263cfa15c0>,\n",
       " 'phelps': <gensim.models.word2vec.Vocab at 0x263cfa1780>,\n",
       " 'marching': <gensim.models.word2vec.Vocab at 0x263cfa1710>,\n",
       " 'seaØ­Â¾Ø¢': <gensim.models.word2vec.Vocab at 0x263cfa1748>,\n",
       " 'hearty': <gensim.models.word2vec.Vocab at 0x263cfa16a0>,\n",
       " 'femalechromosomes': <gensim.models.word2vec.Vocab at 0x263cfa1860>,\n",
       " 'halt': <gensim.models.word2vec.Vocab at 0x26701abfd0>,\n",
       " 'girlÃ¢â‚¬\\u200c': <gensim.models.word2vec.Vocab at 0x263cfa17b8>,\n",
       " \"girl's\": <gensim.models.word2vec.Vocab at 0x263cfa1978>,\n",
       " 'mainly': <gensim.models.word2vec.Vocab at 0x263cfa19b0>,\n",
       " 'spondØ¢': <gensim.models.word2vec.Vocab at 0x263cfa1be0>,\n",
       " 'herbert': <gensim.models.word2vec.Vocab at 0x263cfa1ba8>,\n",
       " 'kvell': <gensim.models.word2vec.Vocab at 0x263cfa1e48>,\n",
       " '50km': <gensim.models.word2vec.Vocab at 0x263cfa1c50>,\n",
       " 'Ã¢â‚¬Ú©he': <gensim.models.word2vec.Vocab at 0x263cfa1cf8>,\n",
       " \"ass'\": <gensim.models.word2vec.Vocab at 0x263e9a97f0>,\n",
       " 'debating': <gensim.models.word2vec.Vocab at 0x263cfa1e10>,\n",
       " \"'human\": <gensim.models.word2vec.Vocab at 0x263cfa1f28>,\n",
       " 'mingling': <gensim.models.word2vec.Vocab at 0x263cfa1da0>,\n",
       " 'Ã¢â‚¬Å“out': <gensim.models.word2vec.Vocab at 0x263cfa1f60>,\n",
       " 'twinkling': <gensim.models.word2vec.Vocab at 0x263cfa1160>,\n",
       " 'triggered': <gensim.models.word2vec.Vocab at 0x263cfa1ef0>,\n",
       " 'maÃ¢â‚¬â„¢rØ¥Â«f': <gensim.models.word2vec.Vocab at 0x263e6fb710>,\n",
       " 'cats': <gensim.models.word2vec.Vocab at 0x263cf54d30>,\n",
       " 'workers': <gensim.models.word2vec.Vocab at 0x263cfa1128>,\n",
       " 'shebetØ¢': <gensim.models.word2vec.Vocab at 0x263d01e048>,\n",
       " 'repining': <gensim.models.word2vec.Vocab at 0x263d01e128>,\n",
       " 'defenses': <gensim.models.word2vec.Vocab at 0x263d060eb8>,\n",
       " 'studio': <gensim.models.word2vec.Vocab at 0x26701b5e48>,\n",
       " 'ta': <gensim.models.word2vec.Vocab at 0x263d01e080>,\n",
       " 'tection': <gensim.models.word2vec.Vocab at 0x263cfd8cf8>,\n",
       " 'supplications': <gensim.models.word2vec.Vocab at 0x263d01e3c8>,\n",
       " 'Ã¢â‚¬Å“youÃ¢â‚¬â„¢ll': <gensim.models.word2vec.Vocab at 0x263d01e438>,\n",
       " 'â€œfriends': <gensim.models.word2vec.Vocab at 0x263d01e588>,\n",
       " 'ugliness': <gensim.models.word2vec.Vocab at 0x263e5775c0>,\n",
       " 'outlawed': <gensim.models.word2vec.Vocab at 0x263d01e780>,\n",
       " 'kneeling': <gensim.models.word2vec.Vocab at 0x263d01e668>,\n",
       " 'burneth': <gensim.models.word2vec.Vocab at 0x263d01e630>,\n",
       " 'derelicts': <gensim.models.word2vec.Vocab at 0x263d004860>,\n",
       " 'spatteredØ¢': <gensim.models.word2vec.Vocab at 0x263d004978>,\n",
       " \"prison'Ø¢\": <gensim.models.word2vec.Vocab at 0x263d01e400>,\n",
       " 'repulsion': <gensim.models.word2vec.Vocab at 0x263d01e5f8>,\n",
       " 'wrongs': <gensim.models.word2vec.Vocab at 0x263d01e518>,\n",
       " 'inØ¢\\xad': <gensim.models.word2vec.Vocab at 0x263d01e978>,\n",
       " 'enemies': <gensim.models.word2vec.Vocab at 0x26703446d8>,\n",
       " 'afte': <gensim.models.word2vec.Vocab at 0x263d01e6a0>,\n",
       " 'unkind': <gensim.models.word2vec.Vocab at 0x263d01e908>,\n",
       " 'shaÃ¢â‚¬â„¢allah': <gensim.models.word2vec.Vocab at 0x263d01e860>,\n",
       " 'collectiveÃ¢â€°': <gensim.models.word2vec.Vocab at 0x263d01e9b0>,\n",
       " 'coquette': <gensim.models.word2vec.Vocab at 0x263d01e9e8>,\n",
       " 'husbanding': <gensim.models.word2vec.Vocab at 0x263d01e828>,\n",
       " 'appreciates': <gensim.models.word2vec.Vocab at 0x263d01eba8>,\n",
       " 'aro': <gensim.models.word2vec.Vocab at 0x263d01ea20>,\n",
       " 'arrested': <gensim.models.word2vec.Vocab at 0x263d01eb70>,\n",
       " 'pishon': <gensim.models.word2vec.Vocab at 0x263d01eb00>,\n",
       " 'revelationØ¢': <gensim.models.word2vec.Vocab at 0x263d01ea58>,\n",
       " 'Ã¢â‚¬Å“badÃ¢â‚¬\\u200c': <gensim.models.word2vec.Vocab at 0x263d01ec18>,\n",
       " 'path': <gensim.models.word2vec.Vocab at 0x263d01ecf8>,\n",
       " \"ahaziah's\": <gensim.models.word2vec.Vocab at 0x263bd594a8>,\n",
       " 'uÃ¢â‚¬Ú¯fohØ¢': <gensim.models.word2vec.Vocab at 0x263d01ecc0>,\n",
       " 'expectationØ¢': <gensim.models.word2vec.Vocab at 0x2670372358>,\n",
       " 'knowØ¢\\xadledge': <gensim.models.word2vec.Vocab at 0x263d01ee48>,\n",
       " 'belongØ¢': <gensim.models.word2vec.Vocab at 0x263d01eda0>,\n",
       " 'compliance': <gensim.models.word2vec.Vocab at 0x263bd59978>,\n",
       " 'asphaltØ¢': <gensim.models.word2vec.Vocab at 0x26701a35f8>,\n",
       " 'novitiates': <gensim.models.word2vec.Vocab at 0x263d01ed68>,\n",
       " 'raid': <gensim.models.word2vec.Vocab at 0x26701e9320>,\n",
       " 'liberality': <gensim.models.word2vec.Vocab at 0x263d01edd8>,\n",
       " 'speak': <gensim.models.word2vec.Vocab at 0x263d01ef60>,\n",
       " 'evident': <gensim.models.word2vec.Vocab at 0x263d01ef98>,\n",
       " 'heÃ¢â‚¬â„¢s': <gensim.models.word2vec.Vocab at 0x2670142588>,\n",
       " 'removed': <gensim.models.word2vec.Vocab at 0x263d01eeb8>,\n",
       " 'zabda': <gensim.models.word2vec.Vocab at 0x263e9bbcf8>,\n",
       " 'bmw': <gensim.models.word2vec.Vocab at 0x263e778b00>,\n",
       " 'lakish': <gensim.models.word2vec.Vocab at 0x263cfcb358>,\n",
       " '16Ã¢â‚¬Ú¯17': <gensim.models.word2vec.Vocab at 0x263cfcb160>,\n",
       " \"se'ethØ¢\": <gensim.models.word2vec.Vocab at 0x263cfcb400>,\n",
       " 'entally': <gensim.models.word2vec.Vocab at 0x263cfcb470>,\n",
       " 'berathaØ¢': <gensim.models.word2vec.Vocab at 0x26701b2ac8>,\n",
       " 'eds': <gensim.models.word2vec.Vocab at 0x263cfcb2b0>,\n",
       " 'slosser': <gensim.models.word2vec.Vocab at 0x263cfcb438>,\n",
       " 'transgression': <gensim.models.word2vec.Vocab at 0x263cfcb630>,\n",
       " 'iradØ¢': <gensim.models.word2vec.Vocab at 0x263cfcb6d8>,\n",
       " 'rainsØ¢': <gensim.models.word2vec.Vocab at 0x263cfcb588>,\n",
       " 'bidden': <gensim.models.word2vec.Vocab at 0x263cfcb748>,\n",
       " 'upholdØ¢': <gensim.models.word2vec.Vocab at 0x263cfcb898>,\n",
       " 'â€˜forgive': <gensim.models.word2vec.Vocab at 0x26716a3c18>,\n",
       " 'irfan': <gensim.models.word2vec.Vocab at 0x263cff45c0>,\n",
       " 'vocationalchange': <gensim.models.word2vec.Vocab at 0x263cfcb668>,\n",
       " 'deftly': <gensim.models.word2vec.Vocab at 0x263cfcba20>,\n",
       " 'maharaj': <gensim.models.word2vec.Vocab at 0x263d0903c8>,\n",
       " 'tawassul': <gensim.models.word2vec.Vocab at 0x263cfcb9b0>,\n",
       " 'nancial': <gensim.models.word2vec.Vocab at 0x263cfcbc88>,\n",
       " 'erience': <gensim.models.word2vec.Vocab at 0x263cfcbbe0>,\n",
       " 'meunites': <gensim.models.word2vec.Vocab at 0x263cfcbcf8>,\n",
       " '00': <gensim.models.word2vec.Vocab at 0x263cfcba58>,\n",
       " 'sounds': <gensim.models.word2vec.Vocab at 0x267017c470>,\n",
       " 'tohuØ¢': <gensim.models.word2vec.Vocab at 0x263cfcbb70>,\n",
       " 'sky': <gensim.models.word2vec.Vocab at 0x263cfcbc18>,\n",
       " 'fooled': <gensim.models.word2vec.Vocab at 0x263cfcbd30>,\n",
       " 'tyrant': <gensim.models.word2vec.Vocab at 0x263cfcbef0>,\n",
       " 'wisconsin': <gensim.models.word2vec.Vocab at 0x263d090400>,\n",
       " 'rebuking': <gensim.models.word2vec.Vocab at 0x263cfcbeb8>,\n",
       " 'upØ­Â¾Ø¢': <gensim.models.word2vec.Vocab at 0x263cfcbdd8>,\n",
       " 'revengeful': <gensim.models.word2vec.Vocab at 0x263cfcc978>,\n",
       " 'artsØ¢': <gensim.models.word2vec.Vocab at 0x263cfcbe80>,\n",
       " 'artwork': <gensim.models.word2vec.Vocab at 0x263cfccbe0>,\n",
       " \"'driveØ¢\": <gensim.models.word2vec.Vocab at 0x267025cc50>,\n",
       " 'favour': <gensim.models.word2vec.Vocab at 0x263cfccb38>,\n",
       " 'raga': <gensim.models.word2vec.Vocab at 0x263cfcce48>,\n",
       " 'upasni': <gensim.models.word2vec.Vocab at 0x263cfccba8>,\n",
       " 'emmanuel': <gensim.models.word2vec.Vocab at 0x263cfccb00>,\n",
       " 'stationedØ¢': <gensim.models.word2vec.Vocab at 0x263eab5518>,\n",
       " 'sakhØ¤Ù¾wØ¤Â«': <gensim.models.word2vec.Vocab at 0x263cfcccf8>,\n",
       " 'muttering': <gensim.models.word2vec.Vocab at 0x263e778c88>,\n",
       " 'intercession': <gensim.models.word2vec.Vocab at 0x263cfccc50>,\n",
       " 'pursuedØ¢': <gensim.models.word2vec.Vocab at 0x263cfcce80>,\n",
       " 'sullivan': <gensim.models.word2vec.Vocab at 0x263cfcce10>,\n",
       " 'turnedØ¢': <gensim.models.word2vec.Vocab at 0x263cfcc128>,\n",
       " 'Ã¢â‚¬Ú©abbasi': <gensim.models.word2vec.Vocab at 0x263cfccef0>,\n",
       " 'worldwide': <gensim.models.word2vec.Vocab at 0x263cfccfd0>,\n",
       " 'families': <gensim.models.word2vec.Vocab at 0x263cfcc2b0>,\n",
       " 'proofs': <gensim.models.word2vec.Vocab at 0x263cfccf98>,\n",
       " 'lungs': <gensim.models.word2vec.Vocab at 0x263cfcc208>,\n",
       " 'accusation': <gensim.models.word2vec.Vocab at 0x263cfcc0b8>,\n",
       " 'standards': <gensim.models.word2vec.Vocab at 0x263cfcc518>,\n",
       " 'which': <gensim.models.word2vec.Vocab at 0x263cfcc6d8>,\n",
       " 'typesetter': <gensim.models.word2vec.Vocab at 0x263cfcc390>,\n",
       " 'unitsØ¢': <gensim.models.word2vec.Vocab at 0x263cfcc550>,\n",
       " 'stewards': <gensim.models.word2vec.Vocab at 0x263cfcc780>,\n",
       " 'cautionØ¢': <gensim.models.word2vec.Vocab at 0x263cfcc4e0>,\n",
       " 'temperamentally': <gensim.models.word2vec.Vocab at 0x263cfcc898>,\n",
       " 'dies': <gensim.models.word2vec.Vocab at 0x263cfcc908>,\n",
       " 'desirable': <gensim.models.word2vec.Vocab at 0x263cfcc630>,\n",
       " 'dancing': <gensim.models.word2vec.Vocab at 0x263cfcc5f8>,\n",
       " 'stuffØ¢': <gensim.models.word2vec.Vocab at 0x263cfcc7f0>,\n",
       " 'guest': <gensim.models.word2vec.Vocab at 0x263cfcc940>,\n",
       " 'illustrates': <gensim.models.word2vec.Vocab at 0x263cfcc8d0>,\n",
       " 'hoofing': <gensim.models.word2vec.Vocab at 0x263cfc8400>,\n",
       " 'gotten': <gensim.models.word2vec.Vocab at 0x263cfbc710>,\n",
       " 'earthquake': <gensim.models.word2vec.Vocab at 0x263cfbc6d8>,\n",
       " 'assumes': <gensim.models.word2vec.Vocab at 0x263cfbc860>,\n",
       " 'gla': <gensim.models.word2vec.Vocab at 0x263cfbc588>,\n",
       " 'executions': <gensim.models.word2vec.Vocab at 0x263cfbc7b8>,\n",
       " 'ninetyØ¢': <gensim.models.word2vec.Vocab at 0x263cfbc278>,\n",
       " 'masihim': <gensim.models.word2vec.Vocab at 0x26701b2ef0>,\n",
       " 'those': <gensim.models.word2vec.Vocab at 0x263cfbc7f0>,\n",
       " 'twentyÃ¢â‚¬Ú¯third': <gensim.models.word2vec.Vocab at 0x267038de80>,\n",
       " '32': <gensim.models.word2vec.Vocab at 0x26702d0b38>,\n",
       " '77Ø¢': <gensim.models.word2vec.Vocab at 0x263cfbcba8>,\n",
       " 'ocial': <gensim.models.word2vec.Vocab at 0x263cfbc898>,\n",
       " 'posterityØ¢': <gensim.models.word2vec.Vocab at 0x263cfbcb00>,\n",
       " 'drawnØ¢': <gensim.models.word2vec.Vocab at 0x263e778f28>,\n",
       " 'quiet': <gensim.models.word2vec.Vocab at 0x263cfbcd30>,\n",
       " 'formØ¢â€”the': <gensim.models.word2vec.Vocab at 0x263cfbcc18>,\n",
       " 'assail': <gensim.models.word2vec.Vocab at 0x263cfbcd68>,\n",
       " 'incited': <gensim.models.word2vec.Vocab at 0x263eac1710>,\n",
       " 'agedØ¢': <gensim.models.word2vec.Vocab at 0x263cfbcdd8>,\n",
       " 'serial': <gensim.models.word2vec.Vocab at 0x263cfbcc50>,\n",
       " 'sissyÙ¹but': <gensim.models.word2vec.Vocab at 0x263cfbccf8>,\n",
       " 'colony': <gensim.models.word2vec.Vocab at 0x26701bbd30>,\n",
       " 'marketing': <gensim.models.word2vec.Vocab at 0x263cfbce10>,\n",
       " 'asablanca': <gensim.models.word2vec.Vocab at 0x263cfbc048>,\n",
       " 'involve': <gensim.models.word2vec.Vocab at 0x263cfbcef0>,\n",
       " 'freeslahi': <gensim.models.word2vec.Vocab at 0x263cfbccc0>,\n",
       " 'pect': <gensim.models.word2vec.Vocab at 0x263cfbc1d0>,\n",
       " 'failing': <gensim.models.word2vec.Vocab at 0x263cfbc240>,\n",
       " \"'set'\": <gensim.models.word2vec.Vocab at 0x263cfbc438>,\n",
       " 'johnson': <gensim.models.word2vec.Vocab at 0x263cfbc3c8>,\n",
       " 'mali': <gensim.models.word2vec.Vocab at 0x263d0242e8>,\n",
       " 'compartmentsØ¢': <gensim.models.word2vec.Vocab at 0x2670161828>,\n",
       " 'dehumanization': <gensim.models.word2vec.Vocab at 0x263e77cb38>,\n",
       " 'sotloff': <gensim.models.word2vec.Vocab at 0x263d024390>,\n",
       " \"banai'sØ¢\": <gensim.models.word2vec.Vocab at 0x263cfbc320>,\n",
       " 'countryØ¢': <gensim.models.word2vec.Vocab at 0x263cfbc470>,\n",
       " 'enlargeØ¢': <gensim.models.word2vec.Vocab at 0x263d0241d0>,\n",
       " 'profiting': <gensim.models.word2vec.Vocab at 0x26702d3358>,\n",
       " 'cowherd': <gensim.models.word2vec.Vocab at 0x263d024438>,\n",
       " 'swarmØ¢': <gensim.models.word2vec.Vocab at 0x26701b50b8>,\n",
       " 'Ã¢â‚¬Å“kalimat': <gensim.models.word2vec.Vocab at 0x263d024240>,\n",
       " 'lifeØ£Â³not': <gensim.models.word2vec.Vocab at 0x263d024160>,\n",
       " '109Ø¢': <gensim.models.word2vec.Vocab at 0x263d024208>,\n",
       " 'giveaways': <gensim.models.word2vec.Vocab at 0x263cfea0f0>,\n",
       " 'moise': <gensim.models.word2vec.Vocab at 0x263d0244e0>,\n",
       " 'mccain': <gensim.models.word2vec.Vocab at 0x263e516be0>,\n",
       " 'lid': <gensim.models.word2vec.Vocab at 0x263d024588>,\n",
       " 'exponent': <gensim.models.word2vec.Vocab at 0x263d024898>,\n",
       " 'bouquet': <gensim.models.word2vec.Vocab at 0x263d0246a0>,\n",
       " 'calamities': <gensim.models.word2vec.Vocab at 0x263e778fd0>,\n",
       " 'walØ¤Â«': <gensim.models.word2vec.Vocab at 0x263d0247b8>,\n",
       " 'church': <gensim.models.word2vec.Vocab at 0x263d024908>,\n",
       " 'nekubaw': <gensim.models.word2vec.Vocab at 0x263d024a20>,\n",
       " 'greenwood': <gensim.models.word2vec.Vocab at 0x263d0249e8>,\n",
       " 'entertainment': <gensim.models.word2vec.Vocab at 0x263d024ac8>,\n",
       " 'knowÃ¢â‚¬Ú¯Ø¢': <gensim.models.word2vec.Vocab at 0x263d024b00>,\n",
       " 'incongruous': <gensim.models.word2vec.Vocab at 0x263d024a58>,\n",
       " 'entanglement': <gensim.models.word2vec.Vocab at 0x2670130da0>,\n",
       " 'abØ¢': <gensim.models.word2vec.Vocab at 0x263d024c88>,\n",
       " 'xxxrv': <gensim.models.word2vec.Vocab at 0x263d024128>,\n",
       " 'consumedØ¢': <gensim.models.word2vec.Vocab at 0x263d024e80>,\n",
       " 'sakeØ¢': <gensim.models.word2vec.Vocab at 0x263d024f28>,\n",
       " 'herekahØ¢': <gensim.models.word2vec.Vocab at 0x263d024b38>,\n",
       " 'goesØ¢': <gensim.models.word2vec.Vocab at 0x263d0240f0>,\n",
       " 'detached': <gensim.models.word2vec.Vocab at 0x263d024e48>,\n",
       " 'quit': <gensim.models.word2vec.Vocab at 0x263d024eb8>,\n",
       " 'saltyØ¢': <gensim.models.word2vec.Vocab at 0x263d024dd8>,\n",
       " 'hedgehog': <gensim.models.word2vec.Vocab at 0x263d0240b8>,\n",
       " 'point': <gensim.models.word2vec.Vocab at 0x263d024f98>,\n",
       " 'riverØ¢': <gensim.models.word2vec.Vocab at 0x263d024fd0>,\n",
       " 'cubits': <gensim.models.word2vec.Vocab at 0x263d090b00>,\n",
       " 'threatenØ¢': <gensim.models.word2vec.Vocab at 0x263d024f60>,\n",
       " 'intel': <gensim.models.word2vec.Vocab at 0x263d010160>,\n",
       " 'huddled': <gensim.models.word2vec.Vocab at 0x263d0100b8>,\n",
       " 'foe': <gensim.models.word2vec.Vocab at 0x263d010358>,\n",
       " 'unbroken': <gensim.models.word2vec.Vocab at 0x263d010208>,\n",
       " 'aids': <gensim.models.word2vec.Vocab at 0x263d010278>,\n",
       " 'shown': <gensim.models.word2vec.Vocab at 0x263d0104e0>,\n",
       " 'xv': <gensim.models.word2vec.Vocab at 0x26701996a0>,\n",
       " 'pashu': <gensim.models.word2vec.Vocab at 0x263d010400>,\n",
       " 'aridities': <gensim.models.word2vec.Vocab at 0x263d010390>,\n",
       " 'andage': <gensim.models.word2vec.Vocab at 0x263d0101d0>,\n",
       " 'bahØ£ØŒÃ¢â‚¬â„¢uÃ¢â‚¬â„¢llØ£ØŒh': <gensim.models.word2vec.Vocab at 0x263d0104a8>,\n",
       " 'lotus': <gensim.models.word2vec.Vocab at 0x263d0103c8>,\n",
       " 'indulged': <gensim.models.word2vec.Vocab at 0x263e748ac8>,\n",
       " 'covertly': <gensim.models.word2vec.Vocab at 0x263d010710>,\n",
       " '339': <gensim.models.word2vec.Vocab at 0x263d010908>,\n",
       " 'unashamed': <gensim.models.word2vec.Vocab at 0x2670288b38>,\n",
       " 'statuteØ¢': <gensim.models.word2vec.Vocab at 0x263d0106d8>,\n",
       " \"israelites'\": <gensim.models.word2vec.Vocab at 0x263d0108d0>,\n",
       " 'ancaster': <gensim.models.word2vec.Vocab at 0x263d010780>,\n",
       " 'missions': <gensim.models.word2vec.Vocab at 0x263d010978>,\n",
       " 'realmØ¢': <gensim.models.word2vec.Vocab at 0x26701b53c8>,\n",
       " 'arÃ¢â€°': <gensim.models.word2vec.Vocab at 0x263d010940>,\n",
       " 'mishap': <gensim.models.word2vec.Vocab at 0x263d010a58>,\n",
       " 'nied': <gensim.models.word2vec.Vocab at 0x263d0109e8>,\n",
       " 'improvesØ¢': <gensim.models.word2vec.Vocab at 0x263d0109b0>,\n",
       " 'darshan': <gensim.models.word2vec.Vocab at 0x263e77c320>,\n",
       " 'deviated': <gensim.models.word2vec.Vocab at 0x263d010a20>,\n",
       " 'seekers': <gensim.models.word2vec.Vocab at 0x2670257588>,\n",
       " 'mineral': <gensim.models.word2vec.Vocab at 0x263d010ba8>,\n",
       " 'yogaville': <gensim.models.word2vec.Vocab at 0x263d010b38>,\n",
       " 'intimation': <gensim.models.word2vec.Vocab at 0x263d010be0>,\n",
       " 'â€œother': <gensim.models.word2vec.Vocab at 0x263d010c50>,\n",
       " 'handmaid': <gensim.models.word2vec.Vocab at 0x263d0909e8>,\n",
       " 'introduceØ¢': <gensim.models.word2vec.Vocab at 0x263d010c88>,\n",
       " 'sealedØ¢': <gensim.models.word2vec.Vocab at 0x263d010ef0>,\n",
       " 'pallas': <gensim.models.word2vec.Vocab at 0x2670217fd0>,\n",
       " 'observed': <gensim.models.word2vec.Vocab at 0x263d010eb8>,\n",
       " 'whereforeØ¢': <gensim.models.word2vec.Vocab at 0x263d010f28>,\n",
       " 'nehemiah': <gensim.models.word2vec.Vocab at 0x263d010e10>,\n",
       " 'winning': <gensim.models.word2vec.Vocab at 0x263d010f60>,\n",
       " 'materialØ¢': <gensim.models.word2vec.Vocab at 0x263cfd79e8>,\n",
       " 'ittha': <gensim.models.word2vec.Vocab at 0x263d010dd8>,\n",
       " 'yes': <gensim.models.word2vec.Vocab at 0x263d025be0>,\n",
       " 'audio': <gensim.models.word2vec.Vocab at 0x263d025dd8>,\n",
       " 'capable': <gensim.models.word2vec.Vocab at 0x263d025c50>,\n",
       " 'corruptlyØ¢': <gensim.models.word2vec.Vocab at 0x263eab5cf8>,\n",
       " 'expressing': <gensim.models.word2vec.Vocab at 0x263e6098d0>,\n",
       " 'damnable': <gensim.models.word2vec.Vocab at 0x26701b5048>,\n",
       " 'digging': <gensim.models.word2vec.Vocab at 0x263d025da0>,\n",
       " 'lakota': <gensim.models.word2vec.Vocab at 0x263d025160>,\n",
       " 'ads': <gensim.models.word2vec.Vocab at 0x263d025d30>,\n",
       " 'xxviØ¢': <gensim.models.word2vec.Vocab at 0x263d025128>,\n",
       " \"enemies'Ø¢\": <gensim.models.word2vec.Vocab at 0x263d025080>,\n",
       " 'climaxed': <gensim.models.word2vec.Vocab at 0x263d025e80>,\n",
       " 'denouncing': <gensim.models.word2vec.Vocab at 0x263d025e48>,\n",
       " 'dishonoursØ¢': <gensim.models.word2vec.Vocab at 0x26701b2860>,\n",
       " 'remainedØ¢': <gensim.models.word2vec.Vocab at 0x263d025fd0>,\n",
       " 'faiths': <gensim.models.word2vec.Vocab at 0x263d025ef0>,\n",
       " 'greets': <gensim.models.word2vec.Vocab at 0x263d0250f0>,\n",
       " 'words': <gensim.models.word2vec.Vocab at 0x263d090c88>,\n",
       " 'quote': <gensim.models.word2vec.Vocab at 0x263d025358>,\n",
       " 'lese': <gensim.models.word2vec.Vocab at 0x263d0253c8>,\n",
       " 'kayyah': <gensim.models.word2vec.Vocab at 0x26701f2c18>,\n",
       " 'scattersØ¢': <gensim.models.word2vec.Vocab at 0x2670367eb8>,\n",
       " \"eve's\": <gensim.models.word2vec.Vocab at 0x263d025470>,\n",
       " 'ceasing': <gensim.models.word2vec.Vocab at 0x263d0255c0>,\n",
       " \"palmÃ¢â‚¬Ú¯tree'Ø¢\": <gensim.models.word2vec.Vocab at 0x263d090d30>,\n",
       " 'upsetsØ¢': <gensim.models.word2vec.Vocab at 0x263d0256d8>,\n",
       " 'ingly': <gensim.models.word2vec.Vocab at 0x263d025710>,\n",
       " 'io4Ø¢': <gensim.models.word2vec.Vocab at 0x263d0256a0>,\n",
       " 'perch': <gensim.models.word2vec.Vocab at 0x263d025550>,\n",
       " 'performed': <gensim.models.word2vec.Vocab at 0x263d025668>,\n",
       " 'impairedØ¢': <gensim.models.word2vec.Vocab at 0x263d0257f0>,\n",
       " 'mazga': <gensim.models.word2vec.Vocab at 0x26701b5748>,\n",
       " 'proof': <gensim.models.word2vec.Vocab at 0x263d090e80>,\n",
       " 'inde': <gensim.models.word2vec.Vocab at 0x263d0258d0>,\n",
       " 'movies': <gensim.models.word2vec.Vocab at 0x263d025748>,\n",
       " 'truest': <gensim.models.word2vec.Vocab at 0x263d09acf8>,\n",
       " 'governorship': <gensim.models.word2vec.Vocab at 0x263d09ab70>,\n",
       " 'occupying': <gensim.models.word2vec.Vocab at 0x263d09ad30>,\n",
       " 'punish': <gensim.models.word2vec.Vocab at 0x263d09ac50>,\n",
       " 'maghar': <gensim.models.word2vec.Vocab at 0x263d09abe0>,\n",
       " 'diamond': <gensim.models.word2vec.Vocab at 0x263d09ad68>,\n",
       " 'armenian': <gensim.models.word2vec.Vocab at 0x263d09aeb8>,\n",
       " 'congregationalØ¢': <gensim.models.word2vec.Vocab at 0x263d09ada0>,\n",
       " 'intendØ¢': <gensim.models.word2vec.Vocab at 0x263d09af60>,\n",
       " 'expressive': <gensim.models.word2vec.Vocab at 0x263e77c5c0>,\n",
       " 'mission': <gensim.models.word2vec.Vocab at 0x263d09a438>,\n",
       " 'goldsmith': <gensim.models.word2vec.Vocab at 0x263d09afd0>,\n",
       " 'liiØ¢': <gensim.models.word2vec.Vocab at 0x263d09add8>,\n",
       " 'abortionsØ¢': <gensim.models.word2vec.Vocab at 0x263d09a048>,\n",
       " 'interview': <gensim.models.word2vec.Vocab at 0x263d09a0b8>,\n",
       " 'neighborÃ¢â‚¬â„¢s': <gensim.models.word2vec.Vocab at 0x263d09a128>,\n",
       " 'riots': <gensim.models.word2vec.Vocab at 0x26701b59b0>,\n",
       " 'texas': <gensim.models.word2vec.Vocab at 0x263d09a2b0>,\n",
       " 'arking': <gensim.models.word2vec.Vocab at 0x263e98d5c0>,\n",
       " 'slyly': <gensim.models.word2vec.Vocab at 0x263d09a080>,\n",
       " 'dressing': <gensim.models.word2vec.Vocab at 0x26701b5940>,\n",
       " 'identÃ¢â€°': <gensim.models.word2vec.Vocab at 0x263d09a4e0>,\n",
       " '10th': <gensim.models.word2vec.Vocab at 0x263eab5f60>,\n",
       " 'tortures': <gensim.models.word2vec.Vocab at 0x26701b58d0>,\n",
       " 'ster': <gensim.models.word2vec.Vocab at 0x263d09a1d0>,\n",
       " 'brown': <gensim.models.word2vec.Vocab at 0x263d09a470>,\n",
       " '5a': <gensim.models.word2vec.Vocab at 0x263d09a668>,\n",
       " 'unloved': <gensim.models.word2vec.Vocab at 0x263d09a630>,\n",
       " 'masterpiece': <gensim.models.word2vec.Vocab at 0x263d09a6d8>,\n",
       " 'instead': <gensim.models.word2vec.Vocab at 0x263d09a780>,\n",
       " 'crying': <gensim.models.word2vec.Vocab at 0x263d09a710>,\n",
       " 'weightierØ¢': <gensim.models.word2vec.Vocab at 0x263d09aa20>,\n",
       " 'frustrations': <gensim.models.word2vec.Vocab at 0x263d09a9e8>,\n",
       " 'sanvat': <gensim.models.word2vec.Vocab at 0x263d09a860>,\n",
       " 'Ã¢â‚¬Å“managing': <gensim.models.word2vec.Vocab at 0x263d09a7f0>,\n",
       " \"'behold'\": <gensim.models.word2vec.Vocab at 0x263d09aa58>,\n",
       " 'debar': <gensim.models.word2vec.Vocab at 0x263d09a898>,\n",
       " 'realizes': <gensim.models.word2vec.Vocab at 0x263d09aac8>,\n",
       " 'meander': <gensim.models.word2vec.Vocab at 0x26668d7c50>,\n",
       " 'gore': <gensim.models.word2vec.Vocab at 0x263d09a828>,\n",
       " 'knowethØ¢': <gensim.models.word2vec.Vocab at 0x263d09a8d0>,\n",
       " 'particle': <gensim.models.word2vec.Vocab at 0x263d092080>,\n",
       " 'observingØ¢': <gensim.models.word2vec.Vocab at 0x263d0922b0>,\n",
       " '39Ø¢': <gensim.models.word2vec.Vocab at 0x263d0920b8>,\n",
       " 'fled': <gensim.models.word2vec.Vocab at 0x263d092320>,\n",
       " 'instructor': <gensim.models.word2vec.Vocab at 0x263d092160>,\n",
       " 'vayera': <gensim.models.word2vec.Vocab at 0x267169bb70>,\n",
       " 'bui': <gensim.models.word2vec.Vocab at 0x263d092208>,\n",
       " 'livingØ¢': <gensim.models.word2vec.Vocab at 0x263d0923c8>,\n",
       " 'portends': <gensim.models.word2vec.Vocab at 0x263d092400>,\n",
       " 'harshlyØ¢': <gensim.models.word2vec.Vocab at 0x263d0921d0>,\n",
       " \"soul'\": <gensim.models.word2vec.Vocab at 0x2670323908>,\n",
       " 'thrown': <gensim.models.word2vec.Vocab at 0x263d092390>,\n",
       " 'uage': <gensim.models.word2vec.Vocab at 0x263d092278>,\n",
       " 'shutØ¢': <gensim.models.word2vec.Vocab at 0x263d092240>,\n",
       " 'goodÃ¢â‚¬\\u200c': <gensim.models.word2vec.Vocab at 0x263d092438>,\n",
       " 'teenagers': <gensim.models.word2vec.Vocab at 0x263d092470>,\n",
       " 'philoØ¢\\xad': <gensim.models.word2vec.Vocab at 0x263d0924a8>,\n",
       " 'Ã¢â‚¬Å“cleanses': <gensim.models.word2vec.Vocab at 0x263d092630>,\n",
       " 'ascend': <gensim.models.word2vec.Vocab at 0x263d092518>,\n",
       " '208': <gensim.models.word2vec.Vocab at 0x263d092710>,\n",
       " 'blake': <gensim.models.word2vec.Vocab at 0x263d092828>,\n",
       " '326Ø¢': <gensim.models.word2vec.Vocab at 0x2670129748>,\n",
       " 'visualizing': <gensim.models.word2vec.Vocab at 0x263d0926d8>,\n",
       " 'sinØ­Â¾Ø¢': <gensim.models.word2vec.Vocab at 0x263d092748>,\n",
       " 'withØ¢': <gensim.models.word2vec.Vocab at 0x263d092668>,\n",
       " 'prophetess': <gensim.models.word2vec.Vocab at 0x263d092588>,\n",
       " 'uur': <gensim.models.word2vec.Vocab at 0x263d092a20>,\n",
       " 'quesØ¢\\xadtion': <gensim.models.word2vec.Vocab at 0x263d092908>,\n",
       " 'intriguing': <gensim.models.word2vec.Vocab at 0x263d0929b0>,\n",
       " 'kadÃ¢â‚¬Ú¯Ø¢': <gensim.models.word2vec.Vocab at 0x263eaa3438>,\n",
       " 'frogs': <gensim.models.word2vec.Vocab at 0x263d092940>,\n",
       " 'prophetically': <gensim.models.word2vec.Vocab at 0x263e72ca58>,\n",
       " 'decreedØ¢': <gensim.models.word2vec.Vocab at 0x263d092860>,\n",
       " 'exceededØ¢': <gensim.models.word2vec.Vocab at 0x263d0929e8>,\n",
       " 'cry': <gensim.models.word2vec.Vocab at 0x263d092978>,\n",
       " 'conception': <gensim.models.word2vec.Vocab at 0x263d092c50>,\n",
       " 'Ã¢â‚¬Å“reason': <gensim.models.word2vec.Vocab at 0x263d0cb9b0>,\n",
       " 'tips': <gensim.models.word2vec.Vocab at 0x26700e9390>,\n",
       " 'pressures': <gensim.models.word2vec.Vocab at 0x263d096828>,\n",
       " 'contemplating': <gensim.models.word2vec.Vocab at 0x263d092b00>,\n",
       " 'beÃ¢â‚¬Ú¯jahØ¢': <gensim.models.word2vec.Vocab at 0x263d092be0>,\n",
       " 'irreplaceable': <gensim.models.word2vec.Vocab at 0x263d092a58>,\n",
       " '04': <gensim.models.word2vec.Vocab at 0x263d092e80>,\n",
       " 'our': <gensim.models.word2vec.Vocab at 0x263d092dd8>,\n",
       " 'latinos': <gensim.models.word2vec.Vocab at 0x263d092ef0>,\n",
       " 'stupefaction': <gensim.models.word2vec.Vocab at 0x263d092e10>,\n",
       " 'Ã¢â‚¬Å“aba': <gensim.models.word2vec.Vocab at 0x263d092f28>,\n",
       " 'herselfØ¢': <gensim.models.word2vec.Vocab at 0x26716a31d0>,\n",
       " 'wouldstØ¢': <gensim.models.word2vec.Vocab at 0x263d096860>,\n",
       " 'imrah': <gensim.models.word2vec.Vocab at 0x263d092fd0>,\n",
       " 'expressionsØ¢': <gensim.models.word2vec.Vocab at 0x263d092d68>,\n",
       " 'preserver': <gensim.models.word2vec.Vocab at 0x263d092da0>,\n",
       " 'sundays': <gensim.models.word2vec.Vocab at 0x263d092cc0>,\n",
       " 'foetus': <gensim.models.word2vec.Vocab at 0x263d097080>,\n",
       " '7Ã¢â‚¬Ú¯io': <gensim.models.word2vec.Vocab at 0x263d0972b0>,\n",
       " 'forgive': <gensim.models.word2vec.Vocab at 0x263d0971d0>,\n",
       " 'mricans': <gensim.models.word2vec.Vocab at 0x263d097160>,\n",
       " 'jargon': <gensim.models.word2vec.Vocab at 0x263d097240>,\n",
       " 'mizraimahØ¢': <gensim.models.word2vec.Vocab at 0x263d0967f0>,\n",
       " 'ks': <gensim.models.word2vec.Vocab at 0x26701b5d30>,\n",
       " 'lighted': <gensim.models.word2vec.Vocab at 0x263d097358>,\n",
       " 'minas': <gensim.models.word2vec.Vocab at 0x263d097438>,\n",
       " 'dedicaÃ¢â€°': <gensim.models.word2vec.Vocab at 0x263d097518>,\n",
       " 'xiii': <gensim.models.word2vec.Vocab at 0x263eab9438>,\n",
       " 'cordyene': <gensim.models.word2vec.Vocab at 0x26668da3c8>,\n",
       " 'reclaim': <gensim.models.word2vec.Vocab at 0x263d097630>,\n",
       " 'Ã¢â‚¬Å“spiritual': <gensim.models.word2vec.Vocab at 0x263eaf87b8>,\n",
       " 'terminationØ¢': <gensim.models.word2vec.Vocab at 0x26701b5dd8>,\n",
       " 'gangs': <gensim.models.word2vec.Vocab at 0x263d0974a8>,\n",
       " 'amounts': <gensim.models.word2vec.Vocab at 0x263d0975c0>,\n",
       " 'parrot': <gensim.models.word2vec.Vocab at 0x263d0976d8>,\n",
       " '156a': <gensim.models.word2vec.Vocab at 0x263d0977b8>,\n",
       " 'basis': <gensim.models.word2vec.Vocab at 0x263d097860>,\n",
       " 'threwØ¢': <gensim.models.word2vec.Vocab at 0x263d097828>,\n",
       " 'devourØ¢': <gensim.models.word2vec.Vocab at 0x263d097780>,\n",
       " \"'rollØ¢\": <gensim.models.word2vec.Vocab at 0x263d097908>,\n",
       " 'babylonØ¢': <gensim.models.word2vec.Vocab at 0x263d097898>,\n",
       " 'residenceØ¢': <gensim.models.word2vec.Vocab at 0x263e983278>,\n",
       " 'mekawim': <gensim.models.word2vec.Vocab at 0x263d097a20>,\n",
       " 'spendØ¢': <gensim.models.word2vec.Vocab at 0x263d0979e8>,\n",
       " 'hese': <gensim.models.word2vec.Vocab at 0x263d0979b0>,\n",
       " 'frankly': <gensim.models.word2vec.Vocab at 0x263d097ba8>,\n",
       " 'aka': <gensim.models.word2vec.Vocab at 0x263d097b70>,\n",
       " 'shipÃ¢â‚¬\\u200c': <gensim.models.word2vec.Vocab at 0x263d097be0>,\n",
       " 'genii': <gensim.models.word2vec.Vocab at 0x263d097b38>,\n",
       " 'sixth': <gensim.models.word2vec.Vocab at 0x263e77c9b0>,\n",
       " 'deedØ¢': <gensim.models.word2vec.Vocab at 0x263d097c50>,\n",
       " 'pleadØ¢': <gensim.models.word2vec.Vocab at 0x263d097ac8>,\n",
       " 'tra': <gensim.models.word2vec.Vocab at 0x263d097c18>,\n",
       " 'hazizØ¢': <gensim.models.word2vec.Vocab at 0x263d097e80>,\n",
       " 'hypnosis': <gensim.models.word2vec.Vocab at 0x263d097d68>,\n",
       " 'educations': <gensim.models.word2vec.Vocab at 0x263d096ac8>,\n",
       " '12Ã¢â‚¬Ú¯14': <gensim.models.word2vec.Vocab at 0x263d097e10>,\n",
       " 'aught': <gensim.models.word2vec.Vocab at 0x263d097a90>,\n",
       " 'mulctØ¢': <gensim.models.word2vec.Vocab at 0x263d097ef0>,\n",
       " 'together': <gensim.models.word2vec.Vocab at 0x263d097dd8>,\n",
       " 'qualifiedØ¢': <gensim.models.word2vec.Vocab at 0x263d097da0>,\n",
       " 'zeal': <gensim.models.word2vec.Vocab at 0x263d097f60>,\n",
       " 'citizenship': <gensim.models.word2vec.Vocab at 0x263d097eb8>,\n",
       " 'calleth': <gensim.models.word2vec.Vocab at 0x263d098748>,\n",
       " 'remind': <gensim.models.word2vec.Vocab at 0x263d098828>,\n",
       " 'countries': <gensim.models.word2vec.Vocab at 0x263d0988d0>,\n",
       " 'distressing': <gensim.models.word2vec.Vocab at 0x263d098908>,\n",
       " 'camelÃ¢â‚¬Ú¯Ø¢': <gensim.models.word2vec.Vocab at 0x263d02a898>,\n",
       " 'visitation': <gensim.models.word2vec.Vocab at 0x263d098780>,\n",
       " 'hukka': <gensim.models.word2vec.Vocab at 0x263d0989e8>,\n",
       " 'disheartened': <gensim.models.word2vec.Vocab at 0x263e77cbe0>,\n",
       " 'booth': <gensim.models.word2vec.Vocab at 0x263d098978>,\n",
       " 'blamed': <gensim.models.word2vec.Vocab at 0x263d098a90>,\n",
       " 'infirmities': <gensim.models.word2vec.Vocab at 0x263d098b38>,\n",
       " 'prehensible': <gensim.models.word2vec.Vocab at 0x263d098b00>,\n",
       " 'weÃ¢â‚¬Ú¯ki': <gensim.models.word2vec.Vocab at 0x263cfdf9e8>,\n",
       " 'indoors': <gensim.models.word2vec.Vocab at 0x263d098c18>,\n",
       " 'zimri': <gensim.models.word2vec.Vocab at 0x263d098cc0>,\n",
       " 'accommodate': <gensim.models.word2vec.Vocab at 0x263d098d30>,\n",
       " 'settingsØ¢': <gensim.models.word2vec.Vocab at 0x26701b5fd0>,\n",
       " 'secluded': <gensim.models.word2vec.Vocab at 0x263d098cf8>,\n",
       " 'zØ¢': <gensim.models.word2vec.Vocab at 0x263d098c50>,\n",
       " 'lgbt': <gensim.models.word2vec.Vocab at 0x263d098ef0>,\n",
       " 'chastisement': <gensim.models.word2vec.Vocab at 0x263d098eb8>,\n",
       " 'hukkat': <gensim.models.word2vec.Vocab at 0x263d098f28>,\n",
       " 'sewØ¢': <gensim.models.word2vec.Vocab at 0x263d098e48>,\n",
       " 'mankindØ¢': <gensim.models.word2vec.Vocab at 0x263d098e80>,\n",
       " 'temporary': <gensim.models.word2vec.Vocab at 0x263d098e10>,\n",
       " 'slept': <gensim.models.word2vec.Vocab at 0x263d098f60>,\n",
       " 'Ã¢â‚¬Ú¯i': <gensim.models.word2vec.Vocab at 0x263d0980f0>,\n",
       " 'xxxvi': <gensim.models.word2vec.Vocab at 0x263d098160>,\n",
       " 'committeeÃ¢â‚¬â„¢s': <gensim.models.word2vec.Vocab at 0x263ea78860>,\n",
       " 'reestablished': <gensim.models.word2vec.Vocab at 0x263d098fd0>,\n",
       " 'troopship': <gensim.models.word2vec.Vocab at 0x263d00e748>,\n",
       " \"sela'\": <gensim.models.word2vec.Vocab at 0x263d0987b8>,\n",
       " 'egyptiansØ¢': <gensim.models.word2vec.Vocab at 0x263d0982e8>,\n",
       " 'negotiate': <gensim.models.word2vec.Vocab at 0x263d098358>,\n",
       " '521': <gensim.models.word2vec.Vocab at 0x263d00e278>,\n",
       " 'choke': <gensim.models.word2vec.Vocab at 0x263d0986a0>,\n",
       " 'entered': <gensim.models.word2vec.Vocab at 0x263e77ccc0>,\n",
       " 'ilunia': <gensim.models.word2vec.Vocab at 0x263d0983c8>,\n",
       " 'doestØ¢': <gensim.models.word2vec.Vocab at 0x263d0985f8>,\n",
       " 'satisfy': <gensim.models.word2vec.Vocab at 0x263d0985c0>,\n",
       " 'stresses': <gensim.models.word2vec.Vocab at 0x263d098438>,\n",
       " 'deprecating': <gensim.models.word2vec.Vocab at 0x263d0984a8>,\n",
       " 'lawyer': <gensim.models.word2vec.Vocab at 0x263d098470>,\n",
       " 'foolØ¢': <gensim.models.word2vec.Vocab at 0x263d0984e0>,\n",
       " 'onest': <gensim.models.word2vec.Vocab at 0x263d098518>,\n",
       " 'endure': <gensim.models.word2vec.Vocab at 0x267021e860>,\n",
       " 'nativityØ¢': <gensim.models.word2vec.Vocab at 0x263cfd65f8>,\n",
       " 'ranks': <gensim.models.word2vec.Vocab at 0x263d098588>,\n",
       " 'â€œlove': <gensim.models.word2vec.Vocab at 0x263d0b9080>,\n",
       " 'slants': <gensim.models.word2vec.Vocab at 0x263d098550>,\n",
       " 'homemaker': <gensim.models.word2vec.Vocab at 0x263e6afda0>,\n",
       " 'Ã¢â‚¬Å“nada': <gensim.models.word2vec.Vocab at 0x263d0b92b0>,\n",
       " 'jabotinsky': <gensim.models.word2vec.Vocab at 0x263d0b9320>,\n",
       " 'Ã¢â‚¬Å“inspection': <gensim.models.word2vec.Vocab at 0x263d0b9240>,\n",
       " 'abiatharØ¢': <gensim.models.word2vec.Vocab at 0x263d096d30>,\n",
       " 'hpØ¢': <gensim.models.word2vec.Vocab at 0x263d0b9358>,\n",
       " 'tumble': <gensim.models.word2vec.Vocab at 0x263cf42d68>,\n",
       " 'napoleon': <gensim.models.word2vec.Vocab at 0x263d0b9198>,\n",
       " 'todayof': <gensim.models.word2vec.Vocab at 0x263cedc978>,\n",
       " 'fledØ¢': <gensim.models.word2vec.Vocab at 0x263d0b9438>,\n",
       " 'extraneous': <gensim.models.word2vec.Vocab at 0x263d0b93c8>,\n",
       " 'ponderedØ¢': <gensim.models.word2vec.Vocab at 0x263d0b9278>,\n",
       " 'aimlessness': <gensim.models.word2vec.Vocab at 0x263d0b9668>,\n",
       " 'perched': <gensim.models.word2vec.Vocab at 0x263d0b9400>,\n",
       " 'agricultureØ­Â¾Ø¢': <gensim.models.word2vec.Vocab at 0x263d0b95f8>,\n",
       " \"weaver's\": <gensim.models.word2vec.Vocab at 0x263d0b9630>,\n",
       " 'pragmatism': <gensim.models.word2vec.Vocab at 0x263eaab940>,\n",
       " '53': <gensim.models.word2vec.Vocab at 0x263d0b91d0>,\n",
       " 'upaÃ¢â€°': <gensim.models.word2vec.Vocab at 0x263d0b97b8>,\n",
       " 'arabØ¢': <gensim.models.word2vec.Vocab at 0x263d096cc0>,\n",
       " 'falseØ¢': <gensim.models.word2vec.Vocab at 0x263d0b96a0>,\n",
       " \"johanan'sØ¢\": <gensim.models.word2vec.Vocab at 0x263d0b98d0>,\n",
       " 'ps': <gensim.models.word2vec.Vocab at 0x26701a3160>,\n",
       " 'singular': <gensim.models.word2vec.Vocab at 0x263d0b9518>,\n",
       " 'fairsØ¢': <gensim.models.word2vec.Vocab at 0x263d0b9748>,\n",
       " 'blankets': <gensim.models.word2vec.Vocab at 0x263d0b9860>,\n",
       " 'neshamah': <gensim.models.word2vec.Vocab at 0x266690ba20>,\n",
       " 'riding': <gensim.models.word2vec.Vocab at 0x263d0b9940>,\n",
       " 'jay': <gensim.models.word2vec.Vocab at 0x263d096eb8>,\n",
       " 'miners': <gensim.models.word2vec.Vocab at 0x263d0b99e8>,\n",
       " 'facilitate': <gensim.models.word2vec.Vocab at 0x263d0b9ba8>,\n",
       " 'gateØ¢': <gensim.models.word2vec.Vocab at 0x263d088748>,\n",
       " 'espiedØ¢': <gensim.models.word2vec.Vocab at 0x263d0b9c50>,\n",
       " 'wrongÃ¯ØŸÂ½': <gensim.models.word2vec.Vocab at 0x263d0b9b38>,\n",
       " 'youÃ¢â‚¬â„¢re': <gensim.models.word2vec.Vocab at 0x263d0b9eb8>,\n",
       " 'lawmakers': <gensim.models.word2vec.Vocab at 0x263d0b9c88>,\n",
       " 'coin': <gensim.models.word2vec.Vocab at 0x263d0b9a90>,\n",
       " 'poterium': <gensim.models.word2vec.Vocab at 0x263eab9a58>,\n",
       " \"'bringØ¢\": <gensim.models.word2vec.Vocab at 0x263d0b9e10>,\n",
       " 'trap': <gensim.models.word2vec.Vocab at 0x263d0b9f28>,\n",
       " 'whomesoever': <gensim.models.word2vec.Vocab at 0x2670241940>,\n",
       " 'reproductive': <gensim.models.word2vec.Vocab at 0x267011ef60>,\n",
       " 'needle': <gensim.models.word2vec.Vocab at 0x263d0b9ef0>,\n",
       " '563': <gensim.models.word2vec.Vocab at 0x263d0b9f60>,\n",
       " 'wvr': <gensim.models.word2vec.Vocab at 0x263cff9f28>,\n",
       " 'bondmaid': <gensim.models.word2vec.Vocab at 0x263cff9470>,\n",
       " 'abha': <gensim.models.word2vec.Vocab at 0x263e75ac18>,\n",
       " 'othersÃ¢â‚¬\\u200c': <gensim.models.word2vec.Vocab at 0x263cff9ac8>,\n",
       " 'leadsØ¢': <gensim.models.word2vec.Vocab at 0x263cff95c0>,\n",
       " \"'ej\": <gensim.models.word2vec.Vocab at 0x263cff96d8>,\n",
       " 'unseen': <gensim.models.word2vec.Vocab at 0x263cff9a58>,\n",
       " 'grateful': <gensim.models.word2vec.Vocab at 0x263cff9518>,\n",
       " 'interpret': <gensim.models.word2vec.Vocab at 0x263cff9f60>,\n",
       " 'collectingØ¢': <gensim.models.word2vec.Vocab at 0x263cff9d30>,\n",
       " 'conversations': <gensim.models.word2vec.Vocab at 0x263cfc1240>,\n",
       " 'nimrodØ¢': <gensim.models.word2vec.Vocab at 0x263d096470>,\n",
       " 'haÃ¢â‚¬Ú¯minØ¢': <gensim.models.word2vec.Vocab at 0x263cfc1668>,\n",
       " \"tower'\": <gensim.models.word2vec.Vocab at 0x263cfc15c0>,\n",
       " 'sayinÃ¢â‚¬â„¢Ã¢â‚¬Â¦': <gensim.models.word2vec.Vocab at 0x263cfc1940>,\n",
       " 'malcolm': <gensim.models.word2vec.Vocab at 0x263cfc16a0>,\n",
       " 'falls': <gensim.models.word2vec.Vocab at 0x263cfc1a58>,\n",
       " 'waswritten': <gensim.models.word2vec.Vocab at 0x263cfc19e8>,\n",
       " 'says': <gensim.models.word2vec.Vocab at 0x263e77f0f0>,\n",
       " 'smacking': <gensim.models.word2vec.Vocab at 0x263cfc1be0>,\n",
       " 'sighted': <gensim.models.word2vec.Vocab at 0x263cfc1a90>,\n",
       " 'bringethØ¢': <gensim.models.word2vec.Vocab at 0x263cfc1c50>,\n",
       " 'eyestrain': <gensim.models.word2vec.Vocab at 0x263cfc1a20>,\n",
       " 'barsel': <gensim.models.word2vec.Vocab at 0x263cfc1d30>,\n",
       " 'nazirite': <gensim.models.word2vec.Vocab at 0x263cfc1b00>,\n",
       " '11': <gensim.models.word2vec.Vocab at 0x263cfc11d0>,\n",
       " '438Ø¢': <gensim.models.word2vec.Vocab at 0x267017c6d8>,\n",
       " 'relies': <gensim.models.word2vec.Vocab at 0x263cfc1320>,\n",
       " 'shreeji': <gensim.models.word2vec.Vocab at 0x263cfc1358>,\n",
       " 'deliberately': <gensim.models.word2vec.Vocab at 0x263ea21a20>,\n",
       " 'wavers': <gensim.models.word2vec.Vocab at 0x263cfc12e8>,\n",
       " '466': <gensim.models.word2vec.Vocab at 0x263cfc14a8>,\n",
       " 'folksâ„¢': <gensim.models.word2vec.Vocab at 0x263cfed4e0>,\n",
       " 'requesting': <gensim.models.word2vec.Vocab at 0x263cfc1438>,\n",
       " 'fertile': <gensim.models.word2vec.Vocab at 0x263e77f240>,\n",
       " 'adhered': <gensim.models.word2vec.Vocab at 0x263cfc1470>,\n",
       " 'Ã¢â‚¬Å“come': <gensim.models.word2vec.Vocab at 0x263cfc1518>,\n",
       " 'dreamed': <gensim.models.word2vec.Vocab at 0x263e5d35c0>,\n",
       " 'instinctually': <gensim.models.word2vec.Vocab at 0x263d011a20>,\n",
       " 'malikiÃ¢â‚¬â„¢s': <gensim.models.word2vec.Vocab at 0x263d0119e8>,\n",
       " 'priest': <gensim.models.word2vec.Vocab at 0x263d096358>,\n",
       " 'hananiahØ¢': <gensim.models.word2vec.Vocab at 0x263d011be0>,\n",
       " 'declaration': <gensim.models.word2vec.Vocab at 0x263d011c88>,\n",
       " 'fare': <gensim.models.word2vec.Vocab at 0x263d011ac8>,\n",
       " 'intermediateØ¢': <gensim.models.word2vec.Vocab at 0x263d0119b0>,\n",
       " 'understands': <gensim.models.word2vec.Vocab at 0x26700e94a8>,\n",
       " 'cover': <gensim.models.word2vec.Vocab at 0x263d011c50>,\n",
       " 'perfectØ¢': <gensim.models.word2vec.Vocab at 0x267016d5f8>,\n",
       " 'resent': <gensim.models.word2vec.Vocab at 0x263d011da0>,\n",
       " 'renewal': <gensim.models.word2vec.Vocab at 0x263d011e48>,\n",
       " '483': <gensim.models.word2vec.Vocab at 0x263d011320>,\n",
       " 'tracedØ¢': <gensim.models.word2vec.Vocab at 0x263d011cc0>,\n",
       " 'renownedØ¢': <gensim.models.word2vec.Vocab at 0x263d0115f8>,\n",
       " 'field': <gensim.models.word2vec.Vocab at 0x263d011f60>,\n",
       " 'properties': <gensim.models.word2vec.Vocab at 0x263d011dd8>,\n",
       " 'ything': <gensim.models.word2vec.Vocab at 0x263d0111d0>,\n",
       " 'politician': <gensim.models.word2vec.Vocab at 0x263d011780>,\n",
       " 'blackout': <gensim.models.word2vec.Vocab at 0x263d011160>,\n",
       " 'nah': <gensim.models.word2vec.Vocab at 0x263d011630>,\n",
       " 'invariablyØ¢': <gensim.models.word2vec.Vocab at 0x263d0117b8>,\n",
       " 'lasted': <gensim.models.word2vec.Vocab at 0x263d0116a0>,\n",
       " 'robØ¢': <gensim.models.word2vec.Vocab at 0x263d0114a8>,\n",
       " 'semiÃ¢â‚¬Ú¯sacredØ¢': <gensim.models.word2vec.Vocab at 0x263d011828>,\n",
       " 'assaults': <gensim.models.word2vec.Vocab at 0x263d011748>,\n",
       " 'whilst': <gensim.models.word2vec.Vocab at 0x263d011898>,\n",
       " 'differentlyØ¢': <gensim.models.word2vec.Vocab at 0x263d011860>,\n",
       " 'met': <gensim.models.word2vec.Vocab at 0x263cf43160>,\n",
       " 'serviceoriented': <gensim.models.word2vec.Vocab at 0x263cf43080>,\n",
       " 'alternating': <gensim.models.word2vec.Vocab at 0x263cf43128>,\n",
       " 'guruÃ¢â‚¬â„¢s': <gensim.models.word2vec.Vocab at 0x263cf43048>,\n",
       " 'blur': <gensim.models.word2vec.Vocab at 0x263cf43358>,\n",
       " 'specimen': <gensim.models.word2vec.Vocab at 0x263cf435f8>,\n",
       " 'faringØ¢': <gensim.models.word2vec.Vocab at 0x263d096400>,\n",
       " \"'why'\": <gensim.models.word2vec.Vocab at 0x263cfb8d68>,\n",
       " 'awimØ¢': <gensim.models.word2vec.Vocab at 0x263cfa8080>,\n",
       " 'eagerÃ¢â€°': <gensim.models.word2vec.Vocab at 0x263cf43198>,\n",
       " 'discoveries': <gensim.models.word2vec.Vocab at 0x263cf43978>,\n",
       " 'dazzlingØ¢': <gensim.models.word2vec.Vocab at 0x263cf435c0>,\n",
       " 'prosecution': <gensim.models.word2vec.Vocab at 0x263cf43668>,\n",
       " 'ff': <gensim.models.word2vec.Vocab at 0x263cf43860>,\n",
       " 'horses': <gensim.models.word2vec.Vocab at 0x263cf43a20>,\n",
       " 'pederasty': <gensim.models.word2vec.Vocab at 0x263cf43710>,\n",
       " 'gasmileage': <gensim.models.word2vec.Vocab at 0x263cf437b8>,\n",
       " 'popesâ€™': <gensim.models.word2vec.Vocab at 0x263cf43940>,\n",
       " 'hakeseth': <gensim.models.word2vec.Vocab at 0x263cf43748>,\n",
       " 'mysticØ¢': <gensim.models.word2vec.Vocab at 0x263cf436d8>,\n",
       " 'au': <gensim.models.word2vec.Vocab at 0x263cf43cf8>,\n",
       " 'withdrew': <gensim.models.word2vec.Vocab at 0x263cf438d0>,\n",
       " 'queries': <gensim.models.word2vec.Vocab at 0x263cf43a58>,\n",
       " 'poursØ¢': <gensim.models.word2vec.Vocab at 0x263cf43cc0>,\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
